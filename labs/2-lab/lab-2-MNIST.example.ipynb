{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The MNIST Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember that you can connect this notebook to a Google drive using this piece of code:\n",
    "\n",
    "```python\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "```\n",
    "\n",
    "Then you can `import os` and use `os.listdir()`, `os.mkdir()` and `os.chdir()` to point the notebook to the directory you want ([tutorial](https://www.geeksforgeeks.org/os-module-python-examples/))."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Theory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure you understand the second video of 3Blue1Brown's introduction to neural nets, and ask questions if there's anything unclear."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import YouTubeVideo\n",
    "YouTubeVideo('IHZwWFHWa-w', width=853, height=480) # 3Blue1Brown 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Hello world"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's import TensorFlow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's do some preprocessing first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MNIST\n",
    "\n",
    "# load\n",
    "(train_images, train_labels), (test_images, test_labels) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "# preprocess\n",
    "train_images = train_images.reshape((60000, 28 * 28))\n",
    "train_images = train_images.astype('float32') / 255\n",
    "test_images = test_images.reshape((10000, 28 * 28))\n",
    "test_images = test_images.astype('float32') / 255\n",
    "\n",
    "train_labels_one_hot = tf.keras.utils.to_categorical(train_labels)\n",
    "test_labels_one_hot = tf.keras.utils.to_categorical(test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our labels are now encoded as one-hot vectors (a one at the index of the correct class).\n",
    "\n",
    "To see that, try and print out the label at the same index in `train_labels` and `train_labels_one_hot`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label as integer: 5\n",
      "Label as one-hot vector: [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "print(\"Label as integer:\", train_labels[0])\n",
    "print(\"Label as one-hot vector:\", train_labels_one_hot[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build\n",
    "model = tf.keras.models.Sequential()\n",
    "model.add(tf.keras.Input((28 * 28,)))\n",
    "model.add(tf.keras.layers.Dense(12, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(10, activation='softmax'))\n",
    "model.compile(\n",
    "    optimizer='rmsprop',\n",
    "    loss='categorical_crossentropy', \n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How does our 'raw' model perform on our test set?\n",
    "\n",
    "Apply the network's `.evaluate()` method to `test_images` and `test_labels_one_hot`, collect the result into `test_loss` and `test_acc`, and see how well your network performs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 230us/step - accuracy: 0.0935 - loss: 2.4344\n",
      "Loss: 2.43570613861084, accuracy: 0.09560000151395798\n"
     ]
    }
   ],
   "source": [
    "result = model.evaluate(test_images, test_labels_one_hot)\n",
    "print(f\"Loss: {result[0]}, accuracy: {result[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Baseline note**: we have a dataset with the same number of samples per class, therefore our _common sense baseline_ is a random guess, $ \\frac{1}{\\text{n\\_classes}} = \\frac{1}{10} = 0.1$. Our randomly initialised dense yields an accuracy value roughly close to that."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 485us/step - accuracy: 0.6842 - loss: 1.1116\n",
      "Epoch 2/5\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 335us/step - accuracy: 0.9104 - loss: 0.3211\n",
      "Epoch 3/5\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 340us/step - accuracy: 0.9210 - loss: 0.2797\n",
      "Epoch 4/5\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 327us/step - accuracy: 0.9258 - loss: 0.2580\n",
      "Epoch 5/5\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 392us/step - accuracy: 0.9294 - loss: 0.2484\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x16c9f37d0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train\n",
    "model.fit(\n",
    "    train_images,\n",
    "    train_labels_one_hot,\n",
    "    epochs=5,\n",
    "    batch_size=128\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now apply the network's `.evaluate()` method again to `test_images` and `test_labels_one_hot`. Any change?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 229us/step - accuracy: 0.9205 - loss: 0.2792\n",
      "Loss: 0.24617807567119598, accuracy: 0.930400013923645\n"
     ]
    }
   ],
   "source": [
    "result = model.evaluate(test_images,test_labels_one_hot)\n",
    "print(f\"Loss: {result[0]}, accuracy: {result[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our accuracy is $0.93\\ (= 93\\%)$, much higher than our baseline, that's good!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Research"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Add a text cell and comment on network training and test accuracy;\n",
    "- Train for 20 epochs and evaluate. Comment on your findings;\n",
    "- The first layer transforms the 784-element image vector to a 12-dimensional intermediate representation:  \n",
    "  - Experiment with different intermediate dimensions (for instance: what is the smallest number of units needed to reach 100% accuracy in 5 epochs? In 20 epochs?); \n",
    "  - Make a markdown table of network performance on the test set for varying intermediate dimension. \n",
    "  - Comment on your results;\n",
    "- Replace network compilation with:\n",
    "  ```python\n",
    "  model.compile(\n",
    "      optimizer=tf.keras.optimizers.RMSprop(learning_rate=0.001, momentum=0.0),\n",
    "      loss='categorical_crossentropy',\n",
    "      metrics=['accuracy']\n",
    "  )\n",
    "  ```\n",
    "  \n",
    "  The code is exactly equivalent, but we are now able to adjust learning rate and momentum. `learning_rate=0.001` is the default value: experiment with different learning rates. Tabulate your results and interpret.\n",
    "- Experiment with different momentums. Tabulate and interpret."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Two playgrounds to keep in mind"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [TensorFlow playground](https://playground.tensorflow.org/#activation=tanh&batchSize=10&dataset=circle&regDataset=reg-plane&learningRate=0.03&regularizationRate=0&noise=0&networkShape=4,2&seed=0.29184&showTestData=false&discretize=false&percTrainData=50&x=true&y=true&xTimesY=false&xSquared=false&ySquared=false&cosX=false&sinX=false&cosY=false&sinY=false&collectStats=false&problem=classification&initZero=false&hideText=false)\n",
    "- [Why Momentum Really Works](https://distill.pub/2017/momentum/)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiments 1\n",
    "\n",
    "- 20 epochs, varying units in the intermediate layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to facilitate my experiments, I will write a wrapping function allowing me to rerun the code I need while changing the parameters I wish to examine (firs the intermediate dimensions, then the learning rate)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment(units):\n",
    "    # build\n",
    "    model = tf.keras.models.Sequential()\n",
    "    model.add(tf.keras.Input((28 * 28,)))\n",
    "    model.add(tf.keras.layers.Dense(units, activation='relu'))\n",
    "    model.add(tf.keras.layers.Dense(10, activation='softmax'))\n",
    "    model.compile(\n",
    "        optimizer='rmsprop',\n",
    "        loss='categorical_crossentropy', \n",
    "        metrics=['accuracy']\n",
    "    )    \n",
    "    # train\n",
    "    model.fit(\n",
    "        train_images,\n",
    "        train_labels_one_hot,\n",
    "        epochs=20,\n",
    "        batch_size=128,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A model with 12 units seems to be performing already quite well on the MNIST dataset. I am expecting to hit 100% accuracy relatively easily. I will therefore attempt to find the _smallest net_ that reaches 100% accuracy in 20 epochs of training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 428us/step - accuracy: 0.4159 - loss: 1.7527\n",
      "Epoch 2/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 296us/step - accuracy: 0.6890 - loss: 0.9727\n",
      "Epoch 3/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 310us/step - accuracy: 0.7816 - loss: 0.7434\n",
      "Epoch 4/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 311us/step - accuracy: 0.8160 - loss: 0.6533\n",
      "Epoch 5/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 309us/step - accuracy: 0.8292 - loss: 0.6005\n",
      "Epoch 6/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 296us/step - accuracy: 0.8383 - loss: 0.5673\n",
      "Epoch 7/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 288us/step - accuracy: 0.8416 - loss: 0.5573\n",
      "Epoch 8/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 292us/step - accuracy: 0.8425 - loss: 0.5528\n",
      "Epoch 9/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 294us/step - accuracy: 0.8456 - loss: 0.5398\n",
      "Epoch 10/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 377us/step - accuracy: 0.8498 - loss: 0.5296\n",
      "Epoch 11/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 298us/step - accuracy: 0.8453 - loss: 0.5354\n",
      "Epoch 12/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 305us/step - accuracy: 0.8513 - loss: 0.5224\n",
      "Epoch 13/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 303us/step - accuracy: 0.8562 - loss: 0.5108\n",
      "Epoch 14/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 303us/step - accuracy: 0.8514 - loss: 0.5178\n",
      "Epoch 15/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 297us/step - accuracy: 0.8549 - loss: 0.5080\n",
      "Epoch 16/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 330us/step - accuracy: 0.8544 - loss: 0.5039\n",
      "Epoch 17/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 321us/step - accuracy: 0.8565 - loss: 0.5064\n",
      "Epoch 18/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 312us/step - accuracy: 0.8602 - loss: 0.4902\n",
      "Epoch 19/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 305us/step - accuracy: 0.8565 - loss: 0.4951\n",
      "Epoch 20/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 291us/step - accuracy: 0.8562 - loss: 0.4938\n"
     ]
    }
   ],
   "source": [
    "run_experiment(units=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Final results: accuracy: 0.8562 - loss: 0.4938."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 505us/step - accuracy: 0.5680 - loss: 1.3847\n",
      "Epoch 2/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 322us/step - accuracy: 0.8899 - loss: 0.4114\n",
      "Epoch 3/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 304us/step - accuracy: 0.9074 - loss: 0.3382\n",
      "Epoch 4/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 302us/step - accuracy: 0.9113 - loss: 0.3120\n",
      "Epoch 5/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 303us/step - accuracy: 0.9164 - loss: 0.3019\n",
      "Epoch 6/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 305us/step - accuracy: 0.9196 - loss: 0.2914\n",
      "Epoch 7/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 308us/step - accuracy: 0.9226 - loss: 0.2810\n",
      "Epoch 8/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 313us/step - accuracy: 0.9249 - loss: 0.2753\n",
      "Epoch 9/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 311us/step - accuracy: 0.9254 - loss: 0.2685\n",
      "Epoch 10/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 314us/step - accuracy: 0.9274 - loss: 0.2716\n",
      "Epoch 11/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 318us/step - accuracy: 0.9267 - loss: 0.2659\n",
      "Epoch 12/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 306us/step - accuracy: 0.9296 - loss: 0.2535\n",
      "Epoch 13/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 364us/step - accuracy: 0.9304 - loss: 0.2530\n",
      "Epoch 14/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 326us/step - accuracy: 0.9316 - loss: 0.2536\n",
      "Epoch 15/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 312us/step - accuracy: 0.9314 - loss: 0.2519\n",
      "Epoch 16/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 305us/step - accuracy: 0.9311 - loss: 0.2532\n",
      "Epoch 17/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 305us/step - accuracy: 0.9342 - loss: 0.2400\n",
      "Epoch 18/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 307us/step - accuracy: 0.9337 - loss: 0.2408\n",
      "Epoch 19/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 306us/step - accuracy: 0.9343 - loss: 0.2416\n",
      "Epoch 20/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 302us/step - accuracy: 0.9338 - loss: 0.2387\n"
     ]
    }
   ],
   "source": [
    "run_experiment(units=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Final results: accuracy: 0.9338 - loss: 0.2387"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 477us/step - accuracy: 0.6599 - loss: 1.1691\n",
      "Epoch 2/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 404us/step - accuracy: 0.9030 - loss: 0.3460\n",
      "Epoch 3/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 338us/step - accuracy: 0.9188 - loss: 0.2869\n",
      "Epoch 4/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 335us/step - accuracy: 0.9223 - loss: 0.2786\n",
      "Epoch 5/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 339us/step - accuracy: 0.9275 - loss: 0.2606\n",
      "Epoch 6/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 334us/step - accuracy: 0.9305 - loss: 0.2485\n",
      "Epoch 7/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 332us/step - accuracy: 0.9329 - loss: 0.2408\n",
      "Epoch 8/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 335us/step - accuracy: 0.9329 - loss: 0.2406\n",
      "Epoch 9/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 339us/step - accuracy: 0.9354 - loss: 0.2278\n",
      "Epoch 10/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 343us/step - accuracy: 0.9368 - loss: 0.2299\n",
      "Epoch 11/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 346us/step - accuracy: 0.9373 - loss: 0.2282\n",
      "Epoch 12/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 347us/step - accuracy: 0.9390 - loss: 0.2191\n",
      "Epoch 13/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 404us/step - accuracy: 0.9389 - loss: 0.2172\n",
      "Epoch 14/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 340us/step - accuracy: 0.9396 - loss: 0.2142\n",
      "Epoch 15/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 341us/step - accuracy: 0.9418 - loss: 0.2138\n",
      "Epoch 16/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 334us/step - accuracy: 0.9421 - loss: 0.2133\n",
      "Epoch 17/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 338us/step - accuracy: 0.9431 - loss: 0.2052\n",
      "Epoch 18/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 339us/step - accuracy: 0.9409 - loss: 0.2084\n",
      "Epoch 19/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 335us/step - accuracy: 0.9439 - loss: 0.2078\n",
      "Epoch 20/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 337us/step - accuracy: 0.9434 - loss: 0.2035\n"
     ]
    }
   ],
   "source": [
    "run_experiment(units=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Final results: accuracy: 0.9434 - loss: 0.2035"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 452us/step - accuracy: 0.6654 - loss: 1.1565\n",
      "Epoch 2/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 325us/step - accuracy: 0.8994 - loss: 0.3545\n",
      "Epoch 3/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 316us/step - accuracy: 0.9194 - loss: 0.2867\n",
      "Epoch 4/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 311us/step - accuracy: 0.9269 - loss: 0.2545\n",
      "Epoch 5/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 310us/step - accuracy: 0.9316 - loss: 0.2381\n",
      "Epoch 6/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 303us/step - accuracy: 0.9349 - loss: 0.2270\n",
      "Epoch 7/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 308us/step - accuracy: 0.9405 - loss: 0.2099\n",
      "Epoch 8/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 308us/step - accuracy: 0.9413 - loss: 0.2086\n",
      "Epoch 9/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 369us/step - accuracy: 0.9445 - loss: 0.1966\n",
      "Epoch 10/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 321us/step - accuracy: 0.9484 - loss: 0.1874\n",
      "Epoch 11/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 340us/step - accuracy: 0.9468 - loss: 0.1867\n",
      "Epoch 12/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 317us/step - accuracy: 0.9476 - loss: 0.1825\n",
      "Epoch 13/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 310us/step - accuracy: 0.9495 - loss: 0.1773\n",
      "Epoch 14/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 315us/step - accuracy: 0.9503 - loss: 0.1752\n",
      "Epoch 15/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 312us/step - accuracy: 0.9502 - loss: 0.1709\n",
      "Epoch 16/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 311us/step - accuracy: 0.9517 - loss: 0.1749\n",
      "Epoch 17/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 342us/step - accuracy: 0.9510 - loss: 0.1681\n",
      "Epoch 18/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 318us/step - accuracy: 0.9533 - loss: 0.1657\n",
      "Epoch 19/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 325us/step - accuracy: 0.9533 - loss: 0.1644\n",
      "Epoch 20/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 326us/step - accuracy: 0.9551 - loss: 0.1576\n"
     ]
    }
   ],
   "source": [
    "run_experiment(units=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Final results: accuracy: 0.9551 - loss: 0.1576"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 473us/step - accuracy: 0.7251 - loss: 1.0180\n",
      "Epoch 2/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 334us/step - accuracy: 0.9052 - loss: 0.3258\n",
      "Epoch 3/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 333us/step - accuracy: 0.9198 - loss: 0.2872\n",
      "Epoch 4/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 330us/step - accuracy: 0.9274 - loss: 0.2520\n",
      "Epoch 5/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 328us/step - accuracy: 0.9312 - loss: 0.2424\n",
      "Epoch 6/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 326us/step - accuracy: 0.9363 - loss: 0.2258\n",
      "Epoch 7/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 340us/step - accuracy: 0.9382 - loss: 0.2161\n",
      "Epoch 8/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 331us/step - accuracy: 0.9407 - loss: 0.2072\n",
      "Epoch 9/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 336us/step - accuracy: 0.9419 - loss: 0.2005\n",
      "Epoch 10/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 386us/step - accuracy: 0.9450 - loss: 0.1922\n",
      "Epoch 11/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 367us/step - accuracy: 0.9463 - loss: 0.1884\n",
      "Epoch 12/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 332us/step - accuracy: 0.9474 - loss: 0.1858\n",
      "Epoch 13/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 330us/step - accuracy: 0.9471 - loss: 0.1868\n",
      "Epoch 14/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 342us/step - accuracy: 0.9504 - loss: 0.1746\n",
      "Epoch 15/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 338us/step - accuracy: 0.9521 - loss: 0.1703\n",
      "Epoch 16/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 335us/step - accuracy: 0.9505 - loss: 0.1709\n",
      "Epoch 17/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 346us/step - accuracy: 0.9531 - loss: 0.1634\n",
      "Epoch 18/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 337us/step - accuracy: 0.9539 - loss: 0.1625\n",
      "Epoch 19/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 327us/step - accuracy: 0.9535 - loss: 0.1594\n",
      "Epoch 20/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 342us/step - accuracy: 0.9549 - loss: 0.1597\n"
     ]
    }
   ],
   "source": [
    "run_experiment(units=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Final results: accuracy: 0.9549 - loss: 0.1597"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 499us/step - accuracy: 0.7718 - loss: 0.8628\n",
      "Epoch 2/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 339us/step - accuracy: 0.9143 - loss: 0.2993\n",
      "Epoch 3/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 335us/step - accuracy: 0.9286 - loss: 0.2525\n",
      "Epoch 4/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 404us/step - accuracy: 0.9366 - loss: 0.2260\n",
      "Epoch 5/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 344us/step - accuracy: 0.9397 - loss: 0.2143\n",
      "Epoch 6/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 361us/step - accuracy: 0.9449 - loss: 0.1981\n",
      "Epoch 7/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 341us/step - accuracy: 0.9473 - loss: 0.1852\n",
      "Epoch 8/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 339us/step - accuracy: 0.9516 - loss: 0.1689\n",
      "Epoch 9/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 334us/step - accuracy: 0.9545 - loss: 0.1610\n",
      "Epoch 10/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 367us/step - accuracy: 0.9567 - loss: 0.1534\n",
      "Epoch 11/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 346us/step - accuracy: 0.9577 - loss: 0.1451\n",
      "Epoch 12/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 348us/step - accuracy: 0.9589 - loss: 0.1451\n",
      "Epoch 13/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 339us/step - accuracy: 0.9615 - loss: 0.1379\n",
      "Epoch 14/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 339us/step - accuracy: 0.9616 - loss: 0.1385\n",
      "Epoch 15/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 409us/step - accuracy: 0.9636 - loss: 0.1285\n",
      "Epoch 16/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 344us/step - accuracy: 0.9640 - loss: 0.1252\n",
      "Epoch 17/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 339us/step - accuracy: 0.9644 - loss: 0.1226\n",
      "Epoch 18/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 346us/step - accuracy: 0.9667 - loss: 0.1191\n",
      "Epoch 19/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 338us/step - accuracy: 0.9677 - loss: 0.1135\n",
      "Epoch 20/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 344us/step - accuracy: 0.9667 - loss: 0.1156\n"
     ]
    }
   ],
   "source": [
    "run_experiment(units=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Final results: accuracy: 0.9667 - loss: 0.1156"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Preliminary conclusion**\n",
    "\n",
    "Remarkably, I was expecting to hit 100% accuracy earlier, when increasing the number of units linearly.\n",
    "\n",
    "Here is a table with my results for the above experiments (highest accuracy in bold):\n",
    "\n",
    "| units | accuracy | loss |\n",
    "|--- | --- | --- |\n",
    "| 4 | 0.8562 | 0.4938 |\n",
    "| 8 | 0.9338 | 0.2387 |\n",
    "| 10 | 0.9434 | 0.2035 |\n",
    "| 12 | 0.9551 | 0.1576 |\n",
    "| 16 | 0.9549 | 0.1597 |\n",
    "| 20 | **0.9667** | 0.1156 |\n",
    "\n",
    "It seems the case that so far the accuracy steadily increases, in tandem with the number of units in my intermediate layer. I also notice that despite a steep rise in accuracy values at the beginning of training, my runs seem to plateau relatively fast, after only a few epochs."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Experiments 2\n",
    "\n",
    "- finding the smallest number of units reaching 100% accuracy during training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will now try another method: first, attempt to _overshoot_, with a value that I'm expecting will yield 100%, and then manually perform a binary search downward, picking the middle value for my number of units."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8746 - loss: 0.4430\n",
      "Epoch 2/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9653 - loss: 0.1157\n",
      "Epoch 3/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9783 - loss: 0.0708\n",
      "Epoch 4/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9849 - loss: 0.0509\n",
      "Epoch 5/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9892 - loss: 0.0364\n",
      "Epoch 6/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9926 - loss: 0.0274\n",
      "Epoch 7/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9946 - loss: 0.0205\n",
      "Epoch 8/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9960 - loss: 0.0155\n",
      "Epoch 9/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9973 - loss: 0.0113\n",
      "Epoch 10/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9974 - loss: 0.0103\n",
      "Epoch 11/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9986 - loss: 0.0063\n",
      "Epoch 12/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9991 - loss: 0.0045\n",
      "Epoch 13/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9996 - loss: 0.0034\n",
      "Epoch 14/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9994 - loss: 0.0031\n",
      "Epoch 15/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9997 - loss: 0.0016\n",
      "Epoch 16/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9999 - loss: 0.0011\n",
      "Epoch 17/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9999 - loss: 8.0144e-04\n",
      "Epoch 18/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 4.7992e-04\n",
      "Epoch 19/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 3.6920e-04\n",
      "Epoch 20/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 3.8889e-04\n"
     ]
    }
   ],
   "source": [
    "run_experiment(512)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok! $512$ units _does_ reach 100% accuracy, at epoch 18 in this case. Let's search down."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 944us/step - accuracy: 0.8681 - loss: 0.4722\n",
      "Epoch 2/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 875us/step - accuracy: 0.9584 - loss: 0.1456\n",
      "Epoch 3/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 797us/step - accuracy: 0.9740 - loss: 0.0925\n",
      "Epoch 4/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 786us/step - accuracy: 0.9810 - loss: 0.0650\n",
      "Epoch 5/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 810us/step - accuracy: 0.9850 - loss: 0.0521\n",
      "Epoch 6/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 783us/step - accuracy: 0.9891 - loss: 0.0382\n",
      "Epoch 7/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 872us/step - accuracy: 0.9913 - loss: 0.0320\n",
      "Epoch 8/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 805us/step - accuracy: 0.9924 - loss: 0.0276\n",
      "Epoch 9/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 796us/step - accuracy: 0.9943 - loss: 0.0204\n",
      "Epoch 10/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 842us/step - accuracy: 0.9960 - loss: 0.0158\n",
      "Epoch 11/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 793us/step - accuracy: 0.9970 - loss: 0.0121\n",
      "Epoch 12/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 806us/step - accuracy: 0.9973 - loss: 0.0112\n",
      "Epoch 13/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 885us/step - accuracy: 0.9981 - loss: 0.0090\n",
      "Epoch 14/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 812us/step - accuracy: 0.9984 - loss: 0.0071\n",
      "Epoch 15/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 797us/step - accuracy: 0.9990 - loss: 0.0054\n",
      "Epoch 16/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 797us/step - accuracy: 0.9990 - loss: 0.0047\n",
      "Epoch 17/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 783us/step - accuracy: 0.9996 - loss: 0.0032\n",
      "Epoch 18/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 878us/step - accuracy: 0.9997 - loss: 0.0022\n",
      "Epoch 19/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 791us/step - accuracy: 0.9999 - loss: 0.0015\n",
      "Epoch 20/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 827us/step - accuracy: 0.9999 - loss: 0.0013\n"
     ]
    }
   ],
   "source": [
    "run_experiment(256)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We do not hit 100% accuracy in this run, but almost! Let's search upward."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "384"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "256 + (256//2) # mid-point above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8702 - loss: 0.4563\n",
      "Epoch 2/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9632 - loss: 0.1268\n",
      "Epoch 3/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9774 - loss: 0.0773\n",
      "Epoch 4/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9843 - loss: 0.0553\n",
      "Epoch 5/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9886 - loss: 0.0405\n",
      "Epoch 6/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9899 - loss: 0.0325\n",
      "Epoch 7/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9932 - loss: 0.0238\n",
      "Epoch 8/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9952 - loss: 0.0181\n",
      "Epoch 9/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9963 - loss: 0.0141\n",
      "Epoch 10/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9971 - loss: 0.0115\n",
      "Epoch 11/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9981 - loss: 0.0085\n",
      "Epoch 12/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9988 - loss: 0.0070\n",
      "Epoch 13/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9987 - loss: 0.0064\n",
      "Epoch 14/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9993 - loss: 0.0040\n",
      "Epoch 15/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9995 - loss: 0.0028\n",
      "Epoch 16/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9998 - loss: 0.0017\n",
      "Epoch 17/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9999 - loss: 0.0012\n",
      "Epoch 18/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 8.4941e-04\n",
      "Epoch 19/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 6.6371e-04\n",
      "Epoch 20/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 5.3884e-04\n"
     ]
    }
   ],
   "source": [
    "run_experiment(384)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "100% accuracy hit at epoch 18! Let's move down."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "320"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "384 - (384 - 256)//2 # mid-point down"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8677 - loss: 0.4727\n",
      "Epoch 2/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 947us/step - accuracy: 0.9615 - loss: 0.1360\n",
      "Epoch 3/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 962us/step - accuracy: 0.9758 - loss: 0.0840\n",
      "Epoch 4/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 904us/step - accuracy: 0.9821 - loss: 0.0614\n",
      "Epoch 5/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 917us/step - accuracy: 0.9879 - loss: 0.0429\n",
      "Epoch 6/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 923us/step - accuracy: 0.9900 - loss: 0.0348\n",
      "Epoch 7/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9924 - loss: 0.0277\n",
      "Epoch 8/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 896us/step - accuracy: 0.9937 - loss: 0.0228\n",
      "Epoch 9/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 964us/step - accuracy: 0.9952 - loss: 0.0184\n",
      "Epoch 10/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 968us/step - accuracy: 0.9969 - loss: 0.0130\n",
      "Epoch 11/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 903us/step - accuracy: 0.9974 - loss: 0.0110\n",
      "Epoch 12/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 924us/step - accuracy: 0.9980 - loss: 0.0079\n",
      "Epoch 13/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 916us/step - accuracy: 0.9988 - loss: 0.0065\n",
      "Epoch 14/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 917us/step - accuracy: 0.9990 - loss: 0.0050\n",
      "Epoch 15/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 897us/step - accuracy: 0.9992 - loss: 0.0035\n",
      "Epoch 16/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 953us/step - accuracy: 0.9996 - loss: 0.0030\n",
      "Epoch 17/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 880us/step - accuracy: 0.9999 - loss: 0.0017\n",
      "Epoch 18/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 889us/step - accuracy: 0.9999 - loss: 0.0015\n",
      "Epoch 19/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 913us/step - accuracy: 0.9999 - loss: 9.2049e-04\n",
      "Epoch 20/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 975us/step - accuracy: 1.0000 - loss: 7.4287e-04\n"
     ]
    }
   ],
   "source": [
    "run_experiment(320)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hitting 100% accuracy at epoch 20, with one layer and `320` units. Here's the summary for this experiment (lowest-unit model in bold):\n",
    "\n",
    "| units | epoch with 100% acc|\n",
    "| --- | --- |\n",
    "|256 | none|\n",
    "| **320** | 20 |\n",
    "| 384 | 18|\n",
    "| 512 | 18 |\n",
    "\n",
    "\n",
    "I note that even if I could reach 100% accuracy in 20 epochs with only `320` units, I did not exhaust the search. Also, different runs of this experiment yield slightly different results: I would need to create a system that automates this search to the end, and performs it several times, in order to reach a firmer conclusion.\n",
    "\n",
    "Let me outline how I could expand this further:\n",
    "- I could keep on searching in the values between `256` and `320` until I find the lowest point;\n",
    "- I could implement the binary search instead of doing it manually;\n",
    "- I could perhaps search for larger number of units, and more layers, but training only until 5 epochs, so that it saves some time and compute. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Experiments 3\n",
    "\n",
    "- 20 epochs, varying the learning rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This time, I will use the same experimental set-up to see if, given a fixed model, I can find the best learning rate. I will approach the problem using **grid search**, by setting up a range of equally spaced possible values for it, try a run on all of those with all other hyperparameters fixed.\n",
    "\n",
    "Since my initial experiments showed that the best accuracy I obtained was with `512` units, I will choose this as the number of units for this experiment.\n",
    "\n",
    "I found [on the documentation](https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/RMSprop) that the default learning rate for `tf.keras.optimizers.RMSprop` is `0.001`, so I will keep that as the central value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_lr_experiment(learning_rate):\n",
    "    # build\n",
    "    model = tf.keras.models.Sequential()\n",
    "    model.add(tf.keras.Input((28 * 28,)))\n",
    "    model.add(tf.keras.layers.Dense(512, activation='relu'))\n",
    "    model.add(tf.keras.layers.Dense(10, activation='softmax'))\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.RMSprop(learning_rate=learning_rate, momentum=0.0),\n",
    "        loss='categorical_crossentropy', \n",
    "        metrics=['accuracy']\n",
    "    )    \n",
    "    # train\n",
    "    model.fit(\n",
    "        train_images,\n",
    "        train_labels_one_hot,\n",
    "        epochs=20,\n",
    "        batch_size=128,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, to help keep my experiments clean and compact, I will perform them in a loop:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_learning_rates = [0.0001, 0.0005, 0.001, 0.0015, 0.002]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment 1 (learning rate: 0.0001):\n",
      "\n",
      "Epoch 1/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7491 - loss: 1.0822\n",
      "Epoch 2/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9155 - loss: 0.3103\n",
      "Epoch 3/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9319 - loss: 0.2489\n",
      "Epoch 4/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9428 - loss: 0.2117\n",
      "Epoch 5/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9486 - loss: 0.1851\n",
      "Epoch 6/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9553 - loss: 0.1595\n",
      "Epoch 7/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9601 - loss: 0.1454\n",
      "Epoch 8/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9649 - loss: 0.1313\n",
      "Epoch 9/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9670 - loss: 0.1227\n",
      "Epoch 10/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9689 - loss: 0.1131\n",
      "Epoch 11/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9730 - loss: 0.1043\n",
      "Epoch 12/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9746 - loss: 0.0975\n",
      "Epoch 13/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9760 - loss: 0.0903\n",
      "Epoch 14/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9780 - loss: 0.0840\n",
      "Epoch 15/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9780 - loss: 0.0810\n",
      "Epoch 16/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9800 - loss: 0.0739\n",
      "Epoch 17/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9814 - loss: 0.0697\n",
      "Epoch 18/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9823 - loss: 0.0665\n",
      "Epoch 19/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9841 - loss: 0.0616\n",
      "Epoch 20/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9849 - loss: 0.0587\n",
      "\n",
      "--------------------------------------------------------------------------\n",
      "\n",
      "Experiment 2 (learning rate: 0.0005):\n",
      "\n",
      "Epoch 1/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8548 - loss: 0.5554\n",
      "Epoch 2/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9531 - loss: 0.1631\n",
      "Epoch 3/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9691 - loss: 0.1090\n",
      "Epoch 4/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9771 - loss: 0.0811\n",
      "Epoch 5/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9824 - loss: 0.0618\n",
      "Epoch 6/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9856 - loss: 0.0503\n",
      "Epoch 7/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9896 - loss: 0.0402\n",
      "Epoch 8/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9903 - loss: 0.0348\n",
      "Epoch 9/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9921 - loss: 0.0287\n",
      "Epoch 10/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9946 - loss: 0.0228\n",
      "Epoch 11/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9957 - loss: 0.0190\n",
      "Epoch 12/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9964 - loss: 0.0158\n",
      "Epoch 13/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9978 - loss: 0.0122\n",
      "Epoch 14/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9981 - loss: 0.0103\n",
      "Epoch 15/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9986 - loss: 0.0089\n",
      "Epoch 16/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9991 - loss: 0.0068\n",
      "Epoch 17/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9990 - loss: 0.0063\n",
      "Epoch 18/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9995 - loss: 0.0046\n",
      "Epoch 19/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9996 - loss: 0.0042\n",
      "Epoch 20/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9998 - loss: 0.0030\n",
      "\n",
      "--------------------------------------------------------------------------\n",
      "\n",
      "Experiment 3 (learning rate: 0.001):\n",
      "\n",
      "Epoch 1/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8726 - loss: 0.4443\n",
      "Epoch 2/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9670 - loss: 0.1158\n",
      "Epoch 3/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9781 - loss: 0.0747\n",
      "Epoch 4/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9842 - loss: 0.0520\n",
      "Epoch 5/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9892 - loss: 0.0389\n",
      "Epoch 6/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9918 - loss: 0.0291\n",
      "Epoch 7/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9940 - loss: 0.0214\n",
      "Epoch 8/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9958 - loss: 0.0161\n",
      "Epoch 9/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9969 - loss: 0.0118\n",
      "Epoch 10/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9980 - loss: 0.0087\n",
      "Epoch 11/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9984 - loss: 0.0072\n",
      "Epoch 12/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9992 - loss: 0.0045\n",
      "Epoch 13/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9995 - loss: 0.0033\n",
      "Epoch 14/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9994 - loss: 0.0028\n",
      "Epoch 15/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9999 - loss: 0.0015\n",
      "Epoch 16/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 9.4964e-04\n",
      "Epoch 17/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 6.9186e-04\n",
      "Epoch 18/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 5.3231e-04\n",
      "Epoch 19/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.9581e-04\n",
      "Epoch 20/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 3.2228e-04\n",
      "\n",
      "--------------------------------------------------------------------------\n",
      "\n",
      "Experiment 4 (learning rate: 0.0015):\n",
      "\n",
      "Epoch 1/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8809 - loss: 0.3990\n",
      "Epoch 2/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9698 - loss: 0.1007\n",
      "Epoch 3/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9816 - loss: 0.0614\n",
      "Epoch 4/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9876 - loss: 0.0407\n",
      "Epoch 5/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9918 - loss: 0.0281\n",
      "Epoch 6/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9939 - loss: 0.0198\n",
      "Epoch 7/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9947 - loss: 0.0159\n",
      "Epoch 8/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9969 - loss: 0.0111\n",
      "Epoch 9/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9979 - loss: 0.0084\n",
      "Epoch 10/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9983 - loss: 0.0065\n",
      "Epoch 11/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9993 - loss: 0.0035\n",
      "Epoch 12/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9996 - loss: 0.0022\n",
      "Epoch 13/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9999 - loss: 0.0011\n",
      "Epoch 14/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9999 - loss: 6.4657e-04\n",
      "Epoch 15/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.9777e-04\n",
      "Epoch 16/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 2.6787e-04\n",
      "Epoch 17/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 2.1296e-04\n",
      "Epoch 18/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 1.5242e-04\n",
      "Epoch 19/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 1.3803e-04\n",
      "Epoch 20/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 1.1633e-04\n",
      "\n",
      "--------------------------------------------------------------------------\n",
      "\n",
      "Experiment 5 (learning rate: 0.002):\n",
      "\n",
      "Epoch 1/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8738 - loss: 0.4074\n",
      "Epoch 2/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9746 - loss: 0.0855\n",
      "Epoch 3/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9836 - loss: 0.0540\n",
      "Epoch 4/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9881 - loss: 0.0378\n",
      "Epoch 5/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9914 - loss: 0.0272\n",
      "Epoch 6/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9944 - loss: 0.0187\n",
      "Epoch 7/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9959 - loss: 0.0135\n",
      "Epoch 8/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9966 - loss: 0.0112\n",
      "Epoch 9/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9978 - loss: 0.0075\n",
      "Epoch 10/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9989 - loss: 0.0046\n",
      "Epoch 11/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9987 - loss: 0.0038\n",
      "Epoch 12/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9990 - loss: 0.0031\n",
      "Epoch 13/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9997 - loss: 0.0018\n",
      "Epoch 14/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 5.4896e-04\n",
      "Epoch 15/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 2.7071e-04\n",
      "Epoch 16/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 1.1013e-04\n",
      "Epoch 17/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 8.1567e-05\n",
      "Epoch 18/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 6.9138e-05\n",
      "Epoch 19/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 6.5454e-05\n",
      "Epoch 20/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 5.9884e-05\n",
      "\n",
      "--------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i, lr in enumerate(all_learning_rates):\n",
    "    print(f\"Experiment {i+1} (learning rate: {lr}):\")\n",
    "    print()\n",
    "    run_lr_experiment(lr)\n",
    "    print()\n",
    "    print(\"--------------------------------------------------------------------------\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is a summary of the above experiment, extracting the last (which are in this case also the best) values:\n",
    "\n",
    "| lr | accuracy | loss | epoch reaching 100% acc |\n",
    "| --- | --- | --- | --- |\n",
    "| 0.0001 | 0.9849 | 0.0587 | none |\n",
    "| 0.0005 | 0.9998 | 0.0030 | none |\n",
    "| 0.001 | 1.0000 | 3.2228e-04 | 16 |\n",
    "| 0.0015 | 1.0000 | 1.1633e-04 | 14 |\n",
    "| 0.002 | 1.0000 | 5.9884e-05 | 14 |\n",
    "\n",
    "The two learning rate values `0.0015` and `0.002` hit 100% accuracy the earliest. It might be possible to hit the 100% accuracy earlier with an even larger learning rate, but for now, it is possible to distinguish between those two using the loss value. In which case, the value of `0.002` comes out on top, with `5.9884e-05` being the lowest. We will use this and proceed experimenting with various momentum values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Experiments 4\n",
    "\n",
    "- 20 epochs, Varying the momentum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_mom_experiment(momentum):\n",
    "    # build\n",
    "    model = tf.keras.models.Sequential()\n",
    "    model.add(tf.keras.Input((28 * 28,)))\n",
    "    model.add(tf.keras.layers.Dense(512, activation='relu'))\n",
    "    model.add(tf.keras.layers.Dense(10, activation='softmax'))\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.RMSprop(learning_rate=0.002, momentum=momentum),\n",
    "        loss='categorical_crossentropy', \n",
    "        metrics=['accuracy']\n",
    "    )    \n",
    "    # train\n",
    "    model.fit(\n",
    "        train_images,\n",
    "        train_labels_one_hot,\n",
    "        epochs=20,\n",
    "        batch_size=128,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will continue with grid search, testing three momentum values to start with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_momentum_values = [0.7, 0.8, 0.9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment 1 (momentum: 0.7):\n",
      "\n",
      "Epoch 1/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.3693 - loss: 884.0505\n",
      "Epoch 2/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.1578 - loss: 2.3881\n",
      "Epoch 3/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.1806 - loss: 2.4861\n",
      "Epoch 4/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.1738 - loss: 2.3563\n",
      "Epoch 5/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.1937 - loss: 2.3201\n",
      "Epoch 6/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.2268 - loss: 2.2104\n",
      "Epoch 7/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.2517 - loss: 2.2074\n",
      "Epoch 8/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.2501 - loss: 2.4447\n",
      "Epoch 9/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.2380 - loss: 2.1835\n",
      "Epoch 10/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.2627 - loss: 2.1189\n",
      "Epoch 11/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.2645 - loss: 2.2060\n",
      "Epoch 12/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.2877 - loss: 2.1043\n",
      "Epoch 13/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.2779 - loss: 2.2889\n",
      "Epoch 14/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.2471 - loss: 2.3235\n",
      "Epoch 15/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.2612 - loss: 2.2265\n",
      "Epoch 16/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.2791 - loss: 2.2636\n",
      "Epoch 17/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.2836 - loss: 2.3084\n",
      "Epoch 18/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.2939 - loss: 2.0603\n",
      "Epoch 19/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.2980 - loss: 2.0699\n",
      "Epoch 20/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.2773 - loss: 2.0814\n",
      "\n",
      "--------------------------------------------------------------------------\n",
      "\n",
      "Experiment 2 (momentum: 0.8):\n",
      "\n",
      "Epoch 1/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.3545 - loss: 1703.1272\n",
      "Epoch 2/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.1981 - loss: 2.4845\n",
      "Epoch 3/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.2240 - loss: 2.5332\n",
      "Epoch 4/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.2166 - loss: 2.3503\n",
      "Epoch 5/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.2363 - loss: 2.5210\n",
      "Epoch 6/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.2331 - loss: 2.2886\n",
      "Epoch 7/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.2424 - loss: 2.2831\n",
      "Epoch 8/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.2565 - loss: 2.3725\n",
      "Epoch 9/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.2507 - loss: 2.3428\n",
      "Epoch 10/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.2672 - loss: 2.2209\n",
      "Epoch 11/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.2666 - loss: 2.3168\n",
      "Epoch 12/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.2752 - loss: 2.6908\n",
      "Epoch 13/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.2681 - loss: 2.2063\n",
      "Epoch 14/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.2597 - loss: 2.0342\n",
      "Epoch 15/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.2947 - loss: 2.1155\n",
      "Epoch 16/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.2789 - loss: 2.1691\n",
      "Epoch 17/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.2820 - loss: 3.0683\n",
      "Epoch 18/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.2915 - loss: 2.4929\n",
      "Epoch 19/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.2939 - loss: 2.0141\n",
      "Epoch 20/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.2894 - loss: 1.9839\n",
      "\n",
      "--------------------------------------------------------------------------\n",
      "\n",
      "Experiment 3 (momentum: 0.9):\n",
      "\n",
      "Epoch 1/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.4017 - loss: 1810.3062\n",
      "Epoch 2/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.1862 - loss: 2.5914\n",
      "Epoch 3/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.1778 - loss: 2.6241\n",
      "Epoch 4/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.1965 - loss: 2.3004\n",
      "Epoch 5/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.1843 - loss: 2.4385\n",
      "Epoch 6/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1859 - loss: 2.4518\n",
      "Epoch 7/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.2134 - loss: 2.2511\n",
      "Epoch 8/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.2150 - loss: 2.2189\n",
      "Epoch 9/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.1817 - loss: 2.3750\n",
      "Epoch 10/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.2213 - loss: 2.6537\n",
      "Epoch 11/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.2160 - loss: 2.3340\n",
      "Epoch 12/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.2275 - loss: 2.2660\n",
      "Epoch 13/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.2289 - loss: 2.2688\n",
      "Epoch 14/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.2190 - loss: 2.3069\n",
      "Epoch 15/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.2298 - loss: 2.3779\n",
      "Epoch 16/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.2151 - loss: 2.2352\n",
      "Epoch 17/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.2309 - loss: 2.1235\n",
      "Epoch 18/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.2250 - loss: 2.3219\n",
      "Epoch 19/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.2242 - loss: 2.1902\n",
      "Epoch 20/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.2215 - loss: 2.5603\n",
      "\n",
      "--------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i, mom in enumerate(all_momentum_values):\n",
    "    print(f\"Experiment {i+1} (momentum: {mom}):\")\n",
    "    print()\n",
    "    run_lr_experiment(mom)\n",
    "    print()\n",
    "    print(\"--------------------------------------------------------------------------\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are the results of the above experiments:\n",
    "\n",
    "| momentum | accuracy | loss | epoch | \n",
    "| --- | --- | --- | --- |\n",
    "| 0.7 | 0.2980 | 2.0699 | 18 |\n",
    "| 0.8 | 0.2939 | 2.0141 | 19 |\n",
    "|  0.9 | 0.2309 | 2.1235 | 17 |\n",
    "\n",
    "We can note a very strange behaviour in the first epoch of each experiment, yielding the best accuracy of the run before going down and increasing in a stable way, but at a much lower level. The value for the loss in the first epoch is also very large. For those two reasons, they were not selected in the table above when measuring performance.\n",
    "\n",
    "| momentum | accuracy | loss |\n",
    "| --- | --- | --- |\n",
    "| 0.7 | 0.3693 | 884.0505 |\n",
    "| 0.8 | 0.3545 | 1703.1272 |\n",
    "|  0.9 | 0.4017 | 1810.3062 |\n",
    "\n",
    "Remarkably, high momentum values for the `RMSprop` optimizer seem to performs much worse than the default (which is zero)!\n",
    "\n",
    "Just as a sanity check, we can check with low values and zero, to see if it is possible to achieve a higher performance than the default."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_momentum_values = [0., 0.05, 0.1, 0.15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment 1 (momentum: 0.0):\n",
      "\n",
      "Epoch 1/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0917 - loss: 2.3291\n",
      "Epoch 2/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0912 - loss: 2.3282\n",
      "Epoch 3/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0911 - loss: 2.3305\n",
      "Epoch 4/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0907 - loss: 2.3289\n",
      "Epoch 5/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0916 - loss: 2.3276\n",
      "Epoch 6/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0912 - loss: 2.3291\n",
      "Epoch 7/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0914 - loss: 2.3289\n",
      "Epoch 8/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0905 - loss: 2.3304\n",
      "Epoch 9/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0894 - loss: 2.3309\n",
      "Epoch 10/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0910 - loss: 2.3271\n",
      "Epoch 11/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0923 - loss: 2.3262\n",
      "Epoch 12/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0889 - loss: 2.3312\n",
      "Epoch 13/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0909 - loss: 2.3276\n",
      "Epoch 14/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0905 - loss: 2.3281\n",
      "Epoch 15/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0931 - loss: 2.3294\n",
      "Epoch 16/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0925 - loss: 2.3283\n",
      "Epoch 17/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0911 - loss: 2.3301\n",
      "Epoch 18/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0907 - loss: 2.3298\n",
      "Epoch 19/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0912 - loss: 2.3284\n",
      "Epoch 20/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.0907 - loss: 2.3301\n",
      "\n",
      "--------------------------------------------------------------------------\n",
      "\n",
      "Experiment 2 (momentum: 0.05):\n",
      "\n",
      "Epoch 1/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7981 - loss: 5.9791\n",
      "Epoch 2/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9297 - loss: 0.3584\n",
      "Epoch 3/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9406 - loss: 0.3023\n",
      "Epoch 4/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9472 - loss: 0.2853\n",
      "Epoch 5/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9514 - loss: 0.2561\n",
      "Epoch 6/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9537 - loss: 0.2508\n",
      "Epoch 7/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9546 - loss: 0.2609\n",
      "Epoch 8/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9586 - loss: 0.2336\n",
      "Epoch 9/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9598 - loss: 0.2124\n",
      "Epoch 10/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9632 - loss: 0.2105\n",
      "Epoch 11/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9639 - loss: 0.2067\n",
      "Epoch 12/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9670 - loss: 0.1963\n",
      "Epoch 13/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9654 - loss: 0.1925\n",
      "Epoch 14/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9663 - loss: 0.1841\n",
      "Epoch 15/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9681 - loss: 0.1744\n",
      "Epoch 16/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9695 - loss: 0.1665\n",
      "Epoch 17/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9705 - loss: 0.1666\n",
      "Epoch 18/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9710 - loss: 0.1627\n",
      "Epoch 19/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9721 - loss: 0.1536\n",
      "Epoch 20/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9732 - loss: 0.1519\n",
      "\n",
      "--------------------------------------------------------------------------\n",
      "\n",
      "Experiment 3 (momentum: 0.1):\n",
      "\n",
      "Epoch 1/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7468 - loss: 23.6567\n",
      "Epoch 2/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8818 - loss: 0.5990\n",
      "Epoch 3/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8901 - loss: 0.5678\n",
      "Epoch 4/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9017 - loss: 0.5266\n",
      "Epoch 5/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9085 - loss: 0.5080\n",
      "Epoch 6/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9096 - loss: 0.4813\n",
      "Epoch 7/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9088 - loss: 0.4777\n",
      "Epoch 8/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9054 - loss: 0.4658\n",
      "Epoch 9/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9208 - loss: 0.4273\n",
      "Epoch 10/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9166 - loss: 0.4409\n",
      "Epoch 11/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9206 - loss: 0.3915\n",
      "Epoch 12/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9293 - loss: 0.3961\n",
      "Epoch 13/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9288 - loss: 0.3598\n",
      "Epoch 14/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9298 - loss: 0.3561\n",
      "Epoch 15/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9325 - loss: 0.3732\n",
      "Epoch 16/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9340 - loss: 0.3487\n",
      "Epoch 17/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9335 - loss: 0.3501\n",
      "Epoch 18/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9316 - loss: 0.3409\n",
      "Epoch 19/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9324 - loss: 0.3379\n",
      "Epoch 20/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9321 - loss: 0.3588\n",
      "\n",
      "--------------------------------------------------------------------------\n",
      "\n",
      "Experiment 4 (momentum: 0.15):\n",
      "\n",
      "Epoch 1/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.6834 - loss: 55.9315\n",
      "Epoch 2/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8025 - loss: 0.9542\n",
      "Epoch 3/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8187 - loss: 0.8427\n",
      "Epoch 4/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8351 - loss: 0.7958\n",
      "Epoch 5/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8428 - loss: 0.7540\n",
      "Epoch 6/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8421 - loss: 0.7088\n",
      "Epoch 7/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8519 - loss: 0.7117\n",
      "Epoch 8/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8470 - loss: 0.6989\n",
      "Epoch 9/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8539 - loss: 0.6917\n",
      "Epoch 10/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8619 - loss: 0.6684\n",
      "Epoch 11/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8646 - loss: 0.6571\n",
      "Epoch 12/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8736 - loss: 0.6106\n",
      "Epoch 13/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8662 - loss: 0.6020\n",
      "Epoch 14/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8749 - loss: 0.6108\n",
      "Epoch 15/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8745 - loss: 0.6277\n",
      "Epoch 16/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8800 - loss: 0.5780\n",
      "Epoch 17/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8815 - loss: 0.5488\n",
      "Epoch 18/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8824 - loss: 0.5574\n",
      "Epoch 19/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8812 - loss: 0.5396\n",
      "Epoch 20/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8803 - loss: 0.5613\n",
      "\n",
      "--------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i, mom in enumerate(all_momentum_values):\n",
    "    print(f\"Experiment {i+1} (momentum: {mom}):\")\n",
    "    print()\n",
    "    run_lr_experiment(mom)\n",
    "    print()\n",
    "    print(\"--------------------------------------------------------------------------\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are the results for the above experiments:\n",
    "\n",
    "| momentum | accuracy | loss | epoch | \n",
    "| --- | --- | --- | --- |\n",
    "| 0.0 | 0.0931 | loss: 2.3294 | 15 |\n",
    "| 0.05 | **0.9732** | 0.1519  | 20 |\n",
    "| 0.1 | 0.9340   | 0.3487 | 16 |\n",
    "| 0.15 | 0.8824 | 0.5574 |  18 |\n",
    "\n",
    "It is possible to note an expected behaviour in the first run, with momentum `0.0`: the loss and accuracy values are stagnating, as if no learning was in fact happening?! It is something that would be worth looking into, since we haven't seen such behaviour in other runs, even if `0.0` is actually used as the default.\n",
    "\n",
    "Otherwise, it is possible to conclude that a momentum of `0.05` is the best value of this set, yielding a maximum accuracy of `0.9732`.\n",
    "\n",
    "It is quite surprising to note that even if we used the same learning rate as our best run above, tweaking the momentum value did not yield 100% accuracy before the 20th epoch as previously.\n",
    "\n",
    "The values for accuracy and loss seem to improve overall, but it is not a straightforward progression as in the first experiments: that means it takes a while to search for the highest values in the list, and can lead to errors. It would be good to be able to automate the process. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 4. Extra: use your model\n",
    "\n",
    "Can you select an image from the training set, display it using `plt.imshow()` (you need to do `import matplotlib as plt` before that)?\n",
    "\n",
    "Can you then use the same image (don't forget it should be of shape [1, 784], the 1 being the batch size), pass it to `model.predict()`, collect the predictions, and find which class was predicted using the `.argmax()` method? Note again the shape of the prediction tensor: it contains a batch dimension at the front!\n",
    "\n",
    "Try with different images, or even take a picture of a number you've drawn, open it in Python, resize it to 28x28 (using pillow for instance), and try the network on it!."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing on training set images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8786 - loss: 0.3986\n",
      "Epoch 2/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9724 - loss: 0.0900\n",
      "Epoch 3/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9834 - loss: 0.0539\n",
      "Epoch 4/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9886 - loss: 0.0360\n",
      "Epoch 5/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9916 - loss: 0.0247\n",
      "Epoch 6/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9938 - loss: 0.0199\n",
      "Epoch 7/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9954 - loss: 0.0145\n",
      "Epoch 8/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9967 - loss: 0.0109\n",
      "Epoch 9/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9971 - loss: 0.0085\n",
      "Epoch 10/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9982 - loss: 0.0062\n",
      "Epoch 11/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9989 - loss: 0.0035\n",
      "Epoch 12/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9994 - loss: 0.0026\n",
      "Epoch 13/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9998 - loss: 0.0012\n",
      "Epoch 14/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9998 - loss: 0.0011\n",
      "Epoch 15/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9999 - loss: 4.4663e-04\n",
      "Epoch 16/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 2.8462e-04\n",
      "Epoch 17/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 8.0269e-05\n",
      "Epoch 18/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 6.8660e-05\n",
      "Epoch 19/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 5.8782e-05\n",
      "Epoch 20/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 5.4109e-05\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x310dfa2d0>"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = tf.keras.models.Sequential()\n",
    "model.add(tf.keras.Input((28 * 28,)))\n",
    "model.add(tf.keras.layers.Dense(512, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(10, activation='softmax'))\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.RMSprop(learning_rate=0.002),\n",
    "    loss='categorical_crossentropy', \n",
    "    metrics=['accuracy']\n",
    ")    \n",
    "# train\n",
    "model.fit(\n",
    "    train_images,\n",
    "    train_labels_one_hot,\n",
    "    epochs=20,\n",
    "    batch_size=128,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(784,)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images[3].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "The model prediction for this image is: 1\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(train_images[3].reshape((28,28)), cmap=\"gray\")\n",
    "probs = model.predict(train_images[3:4]) # that way, I keep the batch dimension\n",
    "pred = np.argmax(probs)\n",
    "print(f\"The model prediction for this image is: {pred}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model predicted this one correctly!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing on manually drawn images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(216, 234)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<PIL.PngImagePlugin.PngImageFile image mode=RGBA size=216x234>"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = Image.open(\"tests/3.png\")\n",
    "print(img.size)\n",
    "img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will need to invert the colours, in order to be more similar to the dataset!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 28)"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_resized = img.resize((28, 28))\n",
    "img_resized.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 28, 4)"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_arr = 1 - np.array(img_resized).astype(\"float32\")\n",
    "img_arr.shape # our image has four channels, we only want one!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "# taking the mean across all channels\n",
    "# -> shape (28, 28), then reshaping\n",
    "# casting to float32, and rescaling to numbers from 0 to 1\n",
    "img_flat = img_arr.mean(axis=-1).reshape((1, 28*28)).astype(\"float32\") / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
      "Probabilities: [[3.9300800e-38 9.9951577e-01 0.0000000e+00 0.0000000e+00 1.7106959e-14\n",
      "  4.5718349e-04 1.0389939e-17 2.7079050e-05 0.0000000e+00 1.8516357e-16]]\n",
      "The model prediction for this image is: 1\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(img_flat.reshape((28,28)), cmap=\"gray\")\n",
    "probs = model.predict(img_flat) # that way, I keep the batch dimension\n",
    "pred = np.argmax(probs)\n",
    "print(\"Probabilities:\", probs)\n",
    "print(f\"The model prediction for this image is: {pred}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This one failed!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
      "Probabilities: [[1.77327567e-03 8.02445337e-02 6.89289570e-01 1.01669036e-01\n",
      "  2.99483701e-03 5.12384297e-03 2.51960475e-03 6.68142214e-02\n",
      "  4.88877855e-02 6.83364400e-04]]\n",
      "The model prediction for this image is: 2\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "img = Image.open(\"tests/7.png\")\n",
    "img = 1 - np.array(img.resize((28, 28))).astype(\"float32\").mean(axis=-1).reshape((1, 28*28)) / 255\n",
    "plt.imshow(img.reshape((28,28)), cmap=\"gray\")\n",
    "probs = model.predict(img) # that way, I keep the batch dimension\n",
    "pred = np.argmax(probs)\n",
    "print(\"Probabilities:\", probs)\n",
    "print(f\"The model prediction for this image is: {pred}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fail again!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "Probabilities: [[0.00668765 0.00070152 0.05863287 0.15659164 0.00103417 0.04155923\n",
      "  0.02252625 0.0179642  0.688285   0.00601748]]\n",
      "The model prediction for this image is: 8\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "img = Image.open(\"tests/8.png\")\n",
    "img = 1 - np.array(img.resize((28, 28))).mean(axis=-1).reshape((1, 28*28)) / 255\n",
    "plt.imshow(img.reshape((28,28)), cmap=\"gray\")\n",
    "probs = model.predict(img) # that way, I keep the batch dimension\n",
    "pred = np.argmax(probs)\n",
    "print(\"Probabilities:\", probs)\n",
    "print(f\"The model prediction for this image is: {pred}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Phew! This one succeeded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "Probabilities: [[6.92608118e-01 2.28205114e-03 1.16214484e-01 3.37083451e-02\n",
      "  1.72007582e-04 6.48065880e-02 3.65178275e-04 1.89519245e-02\n",
      "  8.73681530e-03 6.21543936e-02]]\n",
      "The model prediction for this image is: 0\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "img = Image.open(\"tests/0.png\")\n",
    "img = 1 - np.array(img.resize((28, 28))).astype(\"float32\").mean(axis=-1).reshape((1, 28*28)) / 255\n",
    "plt.imshow(img.reshape((28,28)), cmap=\"gray\")\n",
    "probs = model.predict(img) # that way, I keep the batch dimension\n",
    "pred = np.argmax(probs)\n",
    "print(\"Probabilities:\", probs)\n",
    "print(f\"The model prediction for this image is: {pred}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This one worked as well, yay!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Saving/Reloading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can save and reload your model like so:\n",
    "\n",
    "```python\n",
    "model.save(\"dense.mnist.keras\")\n",
    "network_reloaded = tf.keras.models.load_model(\"dense.mnist.keras\")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"dense.mnist.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "network_reloaded = tf.keras.models.load_model(\"dense.mnist.keras\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is possible to call `fit()` on the loaded model and continue training.\n",
    "\n",
    "```python\n",
    "network_reloaded.fit(train_images, train_labels_one_hot, epochs=5, batch_size=128)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 5.0322e-05\n",
      "Epoch 2/5\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 4.7214e-05\n",
      "Epoch 3/5\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 4.2838e-05\n",
      "Epoch 4/5\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 4.2344e-05\n",
      "Epoch 5/5\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 4.0662e-05\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x314adb0e0>"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network_reloaded.fit(train_images, train_labels_one_hot, epochs=5, batch_size=128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Completely overkill in this case, but the reloading and further training works!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reminder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check out the numerical dojo if you haven't done so:\n",
    "- #### [`1.first-steps-tensorflow.ipynb`](https://github.com/jchwenger/AI/blob/main/labs/1-lab/1.first-steps-tensorflow.ipynb)\n",
    "- #### [`1.first-steps-tensorflow.QUIZ.ipynb`](https://github.com/jchwenger/AI/blob/main/labs/1-lab/1.first-steps-tensorflow.QUIZ.ipynb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
