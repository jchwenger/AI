{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Reuters Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Colab Note"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Don't forget that you can link your notebook to your drive and save your work there. Then you can download and backup your models, reload them to keep training them, or upload datasets to your drive. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "if 'google.colab' in sys.modules:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    os.chdir('drive/My Drive/') # 'My Drive' is the default name of Google Drives\n",
    "    os.listdir()\n",
    "    \n",
    "# use os.chdir(\"my-directory\") # to change directory, and\n",
    "# os.listdir()                 # to list its contents\n",
    "# os.getcwd()                  # to get the name of the current directory\n",
    "# os.mkdir(\"my-new-dir\")       # to create a new directory\n",
    "# See: https://realpython.com/working-with-files-in-python/\n",
    "\n",
    "# You can also use bash commands directly, preceded by a bang\n",
    "# !ls\n",
    "# However, the following will *not* change the Python directory \n",
    "# the notebook points to (use os.chdir for that)!\n",
    "# !cd my-directory    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "---\n",
    "\n",
    "## 1. Practice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G8RmLzZjj3Hl",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### For reproducible results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G8RmLzZjj3Hl"
   },
   "source": [
    "In Keras ([source](https://keras.io/examples/keras_recipes/reproducibility_recipes/)):\n",
    "```python\n",
    "tf.keras.utils.set_random_seed(812) # See below\n",
    "\n",
    "# If using TensorFlow, this will make GPU ops as deterministic as possible,\n",
    "# but it will affect the overall performance, so be mindful of that.\n",
    "tf.config.experimental.enable_op_determinism()\n",
    "```\n",
    "\n",
    "Note: `tf.keras.utils.set_random_seed` will do the following ([source](https://github.com/keras-team/keras/blob/f6c4ac55692c132cd16211f4877fac6dbeead749/keras/src/utils/rng_utils.py#L10)):\n",
    "\n",
    "```python\n",
    "import random\n",
    "random.seed(42)\n",
    "\n",
    "import numpy as np\n",
    "np.random.seed(42)\n",
    "\n",
    "tf.random.set_seed(42) # can be any number\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset processing & model building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize_sequences(sequences, dimension = 10000):\n",
    "    results = np.zeros((len(sequences), dimension))\n",
    "    for i, sequence in enumerate(sequences):\n",
    "        results[i, sequence] = 1.\n",
    "    return results\n",
    "\n",
    "# load\n",
    "(train_data, train_labels), (test_data, test_labels) = tf.keras.datasets.reuters.load_data(num_words=10000)\n",
    "\n",
    "# preprocess\n",
    "x_train = vectorize_sequences(train_data)\n",
    "x_test = vectorize_sequences(test_data)\n",
    "\n",
    "y_train = np.asarray(train_labels).astype('float32')\n",
    "y_test = np.asarray(test_labels).astype('float32')\n",
    "\n",
    "one_hot_train_labels = tf.keras.utils.to_categorical(train_labels)\n",
    "one_hot_test_labels = tf.keras.utils.to_categorical(test_labels)\n",
    "\n",
    "# split training set into train & validation\n",
    "partial_x_train=x_train[1000:]\n",
    "partial_y_train=one_hot_train_labels[1000:]\n",
    "x_val=x_train[:1000]\n",
    "y_val=one_hot_train_labels[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build\n",
    "model = tf.keras.models.Sequential()\n",
    "model.add(tf.keras.Input((10000,)))\n",
    "model.add(tf.keras.layers.Dense(64, activation = 'relu'))\n",
    "model.add(tf.keras.layers.Dense(64, activation = 'relu'))\n",
    "model.add(tf.keras.layers.Dense(46, activation = 'softmax'))\n",
    "\n",
    "model.compile(\n",
    "    optimizer='rmsprop',\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baselines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Do you remember the baseline discussion in the lecture? You can import the code and test it here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) Sanity check, how does our network perform before training (use `.evaluate` on `partial_x_train, partial_y_train`). Is the accuracy a value you would expect?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    partial_x_train,\n",
    "    partial_y_train,\n",
    "    epochs=20,\n",
    "    batch_size=512,\n",
    "    validation_data=(x_val,y_val)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualise your results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import `matplotlib` code to visualise the result of your experiments (from lab 3 or the lectures).\n",
    "\n",
    "Can you think of ways to make the code easy to reuse (when running several experiments)?\n",
    "\n",
    "As usual, we are after the epoch where best *validation* result (accuracy) has been achieved. Can you think of a way to retrieve that optimal epoch programmatically?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Plot training and validation loss and accuracy. Can you spot the optimal epoch (where the best *validation accuracy* has been achieved)?\n",
    "- Deliberately cause an information bottleneck by building a 64-4-46 network. Compare the validation accuracy with a 64-64-46 network;\n",
    "- Try using larger layers – 128 units and smaller layers – 32 units;\n",
    "- Try less and more hidden layers;\n",
    "- Tabulate your results / organise your experiments as much as you can."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 2. Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "Take your best network and train on **all the training data** (`x_train`, `one_hot_train_labels`), without a train/validation split, using the same hyperparameters (optimizer, learning rate, network size, etc.) as your best run, for the optimal number of epochs (looking at your best validation curves)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate this last model on the test set (`x_test, one_hot_test_labels`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Use your model (optional) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "Can you import the lecture code used to test the model on a newswire, and see if you agree with its prediction?\n",
    "\n",
    "AS shown in the lecture, the 46 topics are:\n",
    "```python\n",
    "# https://github.com/keras-team/keras/issues/12072\n",
    "# and here: https://martin-thoma.com/nlp-reuters/\n",
    "topics = [\n",
    "    'cocoa','grain','veg-oil','earn','acq','wheat','copper','housing','money-supply',\n",
    "    'coffee','sugar','trade','reserves','ship','cotton','carcass','crude','nat-gas',\n",
    "    'cpi','money-fx','interest','gnp','meal-feed','alum','oilseed','gold','tin',\n",
    "    'strategic-metal','livestock','retail','ipi','iron-steel','rubber','heat','jobs',\n",
    "    'lei','bop','zinc','orange','pet-chem','dlr','gas','silver','wpi','hog','lead'\n",
    "]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save and load models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To save and load models locally, you can use [the high-level API](https://www.tensorflow.org/tutorials/keras/save_and_load):\n",
    "```python\n",
    "model.save(\"my_reuters_model.keras\")\n",
    "```\n",
    "Later one, to reload it, use:\n",
    "```python\n",
    "reloaded_model = tf.keras.models.load_model('my_reuters_model.keras')\n",
    "```\n",
    "\n",
    "It is also possible to save not just the model, but also the state of your optimiser, and every variable used during training, using the more involved [checkpoints](https://www.tensorflow.org/guide/checkpoint#create_the_checkpoint_objects)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Additional experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Like in the IMDB dataset, one parameter you could study is the influence on the vocabulary size on the final results: you might then want to store the vocab size in a variable, and use that instead of the hard-coded `10000` that we have.\n",
    "- Another line of enquiry is the study of the behaviour of your trained model:\n",
    "  - Are you able to modify existing reviews in a way that changes the initial prediction of your model? (One 'automated' way of doing that would be to remove a certain number of words from the review, and see how performance is impacted by that information loss.)\n",
    "  - Are you able to create a pipeline where you write your own review, or find one online, transform it into the appropriate format (remove punctuation, turn everything to lower case, convert to an array of integers using the dictionary yielded by `tf.keras.datasets.imdb.get_word_index()` (beware of the shift by 3 induced by the reserved tokens for padding, start of sequence and unknown!), and see what prediction you get for it?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
