{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ConvNets\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 1. Practice on MNIST\n",
    "\n",
    "1. Copy DLWP Listings 8.1-8.3 (in the lecture notebook, `8.introduction-to-convnets.ipynb`) in this notebook.\n",
    "2. Experiment with moving/adding convolutional layers, and the number of filters and the size of the local receptive field.\n",
    "3. One interesting experiment is to create a Dense net with roughly as many parameters as your ConvNet, and compare the performance and speed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2. Optimization on Fashion MNIST\n",
    "\n",
    "#### Note\n",
    "\n",
    "If you worked on that dataset for your coursework, and are interested in working with images, you can of course also work on another one like [Cifar10](https://www.tensorflow.org/api_docs/python/tf/keras/datasets/cifar10/load_data), [Cats & Dogs](https://www.kaggle.com/c/dogs-vs-cats/data) or on [celebA](https://mmlab.ie.cuhk.edu.hk/projects/CelebA.html) (also on [Kaggle](https://www.kaggle.com/jessicali9530/celeba-dataset)), if you prefer.\n",
    "\n",
    "1. The [Fashion MNIST dataset](https://www.tensorflow.org/api_docs/python/tf/keras/datasets/fashion_mnist/load_data) is a multiclass image classification task. Follow the MNIST pattern and load the dataset directly from Tensorflow:\n",
    "  ```python\n",
    "  (x_train, y_train), (x_test, y_test) = tf.keras.datasets. ...\n",
    "  ```\n",
    "2. Explore the data: what is the shape and size of the training and test data? Take one of the training images and display it with `plt.pyplot`.\n",
    "3. Split the training set into a partial training set and a validation set. Reshape the partial training, validation and test sets and convert to floats in the range [0, 1].\n",
    "4. Build a model similar to Listings 8.1 and 8.2. Print a summary of the model.\n",
    "5. Compile and run the model for 20 epochs. Plot graphs, find the optimum epochs, retrain a newly initialised model on the whole training set and then evaluate the model on the test test. Regularise your model if you see overfitting. What accuracy does your model achieve? \n",
    "6. Have a look at the model's prediction (`y_hat = model.predict...`) on some test images by running this matplotlib code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the text labels\n",
    "dataset_labels = [\n",
    "    \"T-shirt/top\",  # index 0\n",
    "    \"Trouser\",      # index 1\n",
    "    \"Pullover\",     # index 2 \n",
    "    \"Dress\",        # index 3 \n",
    "    \"Coat\",         # index 4\n",
    "    \"Sandal\",       # index 5\n",
    "    \"Shirt\",        # index 6 \n",
    "    \"Sneaker\",      # index 7 \n",
    "    \"Bag\",          # index 8 \n",
    "    \"Ankle boot\"    # index 9\n",
    "]\n",
    "\n",
    "y_hat = model.predict(x_test)               # x_test: our test data\n",
    "\n",
    "# Plot a random sample of 10 test images, their predicted labels and ground truth\n",
    "figure = plt.figure(figsize=(20, 8))\n",
    "for i, index in enumerate(np.random.choice(x_test.shape[0], size=15, replace=False)):\n",
    "    ax = figure.add_subplot(3, 5, i + 1, xticks=[], yticks=[])\n",
    "    # Display each image\n",
    "    ax.imshow(np.squeeze(x_test[index]))    # x_test: our test data\n",
    "    predict_index = np.argmax(y_hat[index])\n",
    "    true_index = np.argmax(y_test[index])   # y_test: our test labels\n",
    "    # Set the title for each image\n",
    "    ax.set_title(\"{} ({})\".format(\n",
    "                    dataset_labels[predict_index],\n",
    "                    dataset_labels[true_index]),\n",
    "                    color=(\"green\" if predict_index == true_index else \"red\")\n",
    "                )\n",
    "# Reference:\n",
    "# https://colab.research.google.com/github/margaretmz/deep-learning/blob/master/fashion_mnist_keras.ipynb#scrollTo=oJv7XEk10bOv\n",
    "\n",
    "# for Cifar10, you would need:\n",
    "# dataset_labels = [\n",
    "#     \"airplane\",\n",
    "#     \"automobile\",\n",
    "#     \"bird\",\n",
    "#     \"cat\",\n",
    "#     \"deer\",\n",
    "#     \"dog\",\n",
    "#     \"frog\",\n",
    "#     \"horse\",\n",
    "#     \"ship\",\n",
    "#     \"truck\",\n",
    "# ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Experiment with different convolutional bases. For example, remove pooling, add more convolutional layers, resize the layers, etc. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Experiment with the fine-tuning or visualisation pipelines shown in the lecture\n",
    "\n",
    "Import the code from the lecture and see if you can replicate the results. The code for downloading the Cats vs Dogs is available in the lecture notebook (and the use of Kaggle to download it is described in section `8.2.2` of DLWP).\n",
    "\n",
    "If you want to focus on a specific part of the pipeline, here are links to the pretrained models I used in my notebooks. Saving them in a directory called `cats-vs-dogs` in the same directory as the notebook would allow you to load them and, comparing them with your own results, or continue training:\n",
    "- [convnet_from_scratch.keras](https://drive.google.com/file/d/1zyxeZ4vvIB-HXCk4yDWv8abALafzxlDa/view?usp=sharing)\n",
    "- [convnet_from_scratch_with_augmentation.keras](https://drive.google.com/file/d/1txobyWsdySTFgnJVBqkaHSXMW8XiVtCq/view?usp=sharing)\n",
    "- [feature_extraction.keras](https://drive.google.com/file/d/1ZgQzN7H7NDJLHqBv_USNnCyxB-rBb-6-/view?usp=sharing)\n",
    "- [feature_extraction_with_data_augmentation.keras](https://drive.google.com/file/d/1yAx8GHKbgB_qZ2mYHRZ4OwEpzvge4B2I/view?usp=sharing)\n",
    "- [fine_tuning.keras](https://drive.google.com/file/d/10THpiuKR_mFxPANzarrMtuJqn8C03xuw/view?usp=sharing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Colab Note\n",
    "\n",
    "When working with external datasets in Colab, I recommend the following workflow:\n",
    "\n",
    "1. Make sure your dataset is easily downloadable, either from an external source (a university website, Kaggle, etc.). This could involve uploading the dataset to your drive *as one compressed file (zip/gzip/tar/etc.)*, make that file public, and then copy the link. \n",
    "2. Then use tools like `gdown` (downloading from Google Drive, that ships with Colab, see [here](https://github.com/wkentaro/gdown)) or `wget` (for any link, also no install needed on Colab, [here](https://linuxize.com/post/wget-command-examples/)) to download it. Colab has a very, very high internet connection, which allows you to redownload even large datasets every time you start a session.\n",
    "3. Unzip the file using `unzip` ([here](https://linuxize.com/post/how-to-unzip-files-in-linux/#how-to-unzip-a-zip-file)) or `tar` ([here](https://linuxhint.com/untar_files_linux/)) utilities, so that the files are available to the virtual machine.\n",
    "4. Connect to your drive if you need to save model files, etc. But do not connect to your drive and use something like `tf.keras.image_dataset_from_directory` on an unzipped folder in your Google Drive, it is too slow.\n",
    "\n",
    "The code to connect to your drive:\n",
    "```python\n",
    "import os\n",
    "import sys\n",
    "\n",
    "if 'google.colab' in sys.modules:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    os.chdir('drive/My Drive/') # 'My Drive' is the default name of Google Drives\n",
    "    os.listdir()\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
