{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3e044249-ebbf-4c3a-b367-7551ab1483c0",
   "metadata": {},
   "source": [
    "# Layer parameters Quiz!\n",
    "\n",
    "Idea and functionality taken from the [einops](https://github.com/arogozhnikov/einops/blob/main/docs/2-einops-for-deep-learning.ipynb) tutorials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15ae50d6-d6da-47a3-9f54-0870adaa3c30",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display_html\n",
    "\n",
    "_style_inline = \"\"\"<style>\n",
    ".conv-answer {\n",
    "    color: transparent;\n",
    "    padding: 5px 15px;\n",
    "    background-color: lightgray;\n",
    "}\n",
    "div.overfitting-container {\n",
    "    width: 650px;\n",
    "    height: 450px;\n",
    "    background-color: white;\n",
    "    position: relative;\n",
    "    overflow: hidden;\n",
    "}\n",
    "img.overfitting, img.overfitting-answer {\n",
    "    position: absolute;\n",
    "    top: 0;\n",
    "    left: 0;\n",
    "    width: 100%;\n",
    "    height: 100%;\n",
    "    transition: opacity 0.5s ease-in-out, visibility 0.5s ease-in-out;\n",
    "}\n",
    "img.overfitting {\n",
    "    opacity: 1;\n",
    "    visibility: visible;\n",
    "}\n",
    "img.overfitting-answer {\n",
    "    opacity: 0;\n",
    "    visibility: hidden;\n",
    "}\n",
    "div.overfitting-container:hover img.overfitting {\n",
    "    opacity: 0;\n",
    "    visibility: hidden;\n",
    "}\n",
    "div.overfitting-container:hover img.overfitting-answer {\n",
    "    opacity: 1;\n",
    "    visibility: visible;\n",
    "}\n",
    "</style>\n",
    "\"\"\"\n",
    "\n",
    "def guess(x):\n",
    "    q, a = x  # 'q' is the default image, 'a' is the image with the answer\n",
    "    # Wrap both images inside the div container\n",
    "    answ = f\"\"\"\n",
    "    <div class='overfitting-container'>\n",
    "        <img src='{q}' class='overfitting'>\n",
    "        <img src='{a}' class='overfitting-answer'>\n",
    "    </div>\n",
    "    \"\"\"\n",
    "    return display_html(_style_inline + answ, raw=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38587990-fa84-45b7-acb1-f061b6d3a5d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "import io\n",
    "import base64\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "\n",
    "# load dataset\n",
    "(train_images, train_labels), (test_images, test_labels) = tf.keras.datasets.mnist.load_data()\n",
    "train_images = train_images.reshape((60000, 28 * 28))\n",
    "train_images = train_images.astype('float32') / 255\n",
    "test_images = test_images.reshape((10000, 28 * 28))\n",
    "test_images = test_images.astype('float32') / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bc69058-7abd-4af1-bb76-f319eac6c93b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to save the figure as an image and return the image in base64 format\n",
    "def plot_epochs(y_train, y_validation, title, y_label, answer=False, display=False):\n",
    "    x = range(1, len(y_train) + 1)\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(x, y_train, label=\"training\")\n",
    "    ax.plot(x, y_validation, label=\"validation\")\n",
    "    \n",
    "    if answer:\n",
    "        min_epoch = np.argmin(y_train)\n",
    "        min_val_epoch = np.argmin(y_validation)\n",
    "        # if validation is lower than train: underfitting!\n",
    "        if y_validation[min_val_epoch] <= y_train[min_epoch]:\n",
    "           ax.text(\n",
    "               min_val_epoch + .8, y_validation[min_val_epoch] + .05,\n",
    "               f\"underfitting!\"\n",
    "           )        \n",
    "        # overfitting\n",
    "        else:\n",
    "           ax.text(\n",
    "               min_val_epoch + .8, y_validation[min_val_epoch] + .05,\n",
    "                f\"overfitting!\"\n",
    "           )\n",
    "        ax.text(\n",
    "           min_val_epoch + .8, y_validation[min_val_epoch] + .035,\n",
    "           f\"min val loss:\"\n",
    "        )                  \n",
    "        ax.text(\n",
    "            min_val_epoch + .8,\n",
    "            y_validation[min_val_epoch] + .02,\n",
    "            f\"↓ epoch {min_val_epoch + 1}\"\n",
    "        )\n",
    "    ax.set_title(title)\n",
    "    ax.set_ylabel(y_label)\n",
    "    ax.xaxis.set_major_locator(ticker.MaxNLocator(integer=True))\n",
    "    ax.set_xticks(range(1, len(y_train) + 1))    \n",
    "    ax.set_xlabel(\"Epochs\")\n",
    "    ax.set_xlim(left=0)\n",
    "    ax.legend()\n",
    "\n",
    "    # no display: return as a base64 string\n",
    "    if not display:\n",
    "        # Save the figure to a bytes buffer\n",
    "        buf = io.BytesIO()\n",
    "        fig.savefig(buf, format='png')\n",
    "        buf.seek(0)\n",
    "        plt.close(fig)\n",
    "    \n",
    "        # Convert the image to a base64 string to embed in HTML\n",
    "        img_base64 = base64.b64encode(buf.read()).decode('utf-8')\n",
    "        img_str = f\"data:image/png;base64,{img_base64}\"\n",
    "        return img_str\n",
    "    else:\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22821223-7a12-4d9a-81a8-af9e81efe22b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_model():\n",
    "    n_layers = random.randint(1,4)    \n",
    "    hidden_units = []\n",
    "    r = random.randint(2,8)\n",
    "    hidden_units.append(2**r)\n",
    "    for _ in range(n_layers-1):\n",
    "        r = random.randint(r,8)\n",
    "        hidden_units.append(2**r)\n",
    "\n",
    "    model = tf.keras.models.Sequential()\n",
    "    model.add(tf.keras.Input((28*28,)))\n",
    "    for i in range(n_layers):\n",
    "        model.add(tf.keras.layers.Dense(hidden_units[i], activation=\"relu\"))\n",
    "    model.add(tf.keras.layers.Dense(10, activation=\"softmax\"))\n",
    "    model.compile(\n",
    "        optimizer=\"rmsprop\",\n",
    "        loss=\"sparse_categorical_crossentropy\", \n",
    "        metrics=[\"accuracy\"]\n",
    "    )\n",
    "    \n",
    "    layers_str = \"\\n\".join(\n",
    "        [f'model.add(tf.keras.layers.Dense({hidden_units[i]}, activation=\"relu\"))' for i in range(n_layers)]\n",
    "    )\n",
    "    \n",
    "    print(f\"\"\"\n",
    "reset_random_seeds()\n",
    "model = tf.keras.models.Sequential()\n",
    "model.add(tf.keras.Input((28*28,)))\n",
    "{layers_str}\n",
    "model.add(tf.keras.layers.Dense(10, activation=\"softmax\"))\n",
    "model.compile(\n",
    "    optimizer=\"rmsprop\",\n",
    "    loss=\"sparse_categorical_crossentropy\", \n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "history = model.fit(\n",
    "    train_images, train_labels, epochs=20,\n",
    "    validation_split=0.2, verbose=0\n",
    ")\n",
    "plot_epochs(\n",
    "    history.history[\"loss\"], history.history[\"val_loss\"],\n",
    "    title='Training and validation loss',\n",
    "    y_label='Loss', answer=True, display=True\n",
    ")\n",
    "    \"\"\")\n",
    "\n",
    "    print(\"Training...\")\n",
    "    \n",
    "    # model.summary()\n",
    "    history = model.fit(\n",
    "        train_images, train_labels, epochs=20,\n",
    "        validation_split=0.2, verbose=0\n",
    "    )\n",
    "    figure_base64 = plot_epochs(\n",
    "        history.history[\"loss\"], history.history[\"val_loss\"],\n",
    "        title='Training and validation loss',\n",
    "        y_label='Loss'\n",
    "    )\n",
    "    figure_answer_base64 = plot_epochs(\n",
    "        history.history[\"loss\"], history.history[\"val_loss\"],\n",
    "        title='Training and validation loss',\n",
    "        y_label='Loss', answer=True\n",
    "    )\n",
    "\n",
    "    print()\n",
    "    print(\"Consider the following plot: at which epoch does overfitting happen? (Hover to reveal.)\")\n",
    "    print()\n",
    "    print(\"(Copy the above code and run it if you want to train another model with the same hyperparameters.)\")\n",
    "    print()\n",
    "\n",
    "    return figure_base64,figure_answer_base64"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "211e70b2-6a4a-4aee-bef8-2ab14a239943",
   "metadata": {},
   "source": [
    "## The Quiz\n",
    "\n",
    "Rerun for a new set-up, hover to see the answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffe4999c-ed35-4220-90cc-8e1298e17926",
   "metadata": {},
   "outputs": [],
   "source": [
    "guess(random_model())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
