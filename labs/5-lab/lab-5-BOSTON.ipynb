{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C6gb6X1pzNp1"
   },
   "source": [
    "# The Boston Housing Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C6gb6X1pzNp1"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C6gb6X1pzNp1"
   },
   "source": [
    "### Colab Note"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Don't forget that you can link your notebook to your drive and save your work there. Then you can download and backup your models, reload them to keep training them, or upload datasets to your drive. \n",
    "\n",
    "```python\n",
    "import os\n",
    "import sys\n",
    "\n",
    "if 'google.colab' in sys.modules:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    os.chdir('drive/My Drive/') # 'My Drive' is the default name of Google Drives\n",
    "    os.listdir()\n",
    "    \n",
    "# use os.chdir(\"my-directory\") # to change directory, and\n",
    "# os.listdir()                 # to list its contents\n",
    "# os.getcwd()                  # to get the name of the current directory\n",
    "# os.mkdir(\"my-new-dir\")       # to create a new directory\n",
    "# See: https://realpython.com/working-with-files-in-python/\n",
    "\n",
    "# You can also use bash commands directly, preceded by a bang\n",
    "# !ls\n",
    "# However, the following will *not* change the Python directory \n",
    "# the notebook points to (use os.chdir for that)!\n",
    "# !cd my-directory\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C6gb6X1pzNp1"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C6gb6X1pzNp1"
   },
   "source": [
    "## 1. Practice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### For reproducible results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G8RmLzZjj3Hl"
   },
   "source": [
    "In Keras ([source](https://keras.io/examples/keras_recipes/reproducibility_recipes/)):\n",
    "```python\n",
    "tf.keras.utils.set_random_seed(812) # See below\n",
    "\n",
    "# If using TensorFlow, this will make GPU ops as deterministic as possible,\n",
    "# but it will affect the overall performance, so be mindful of that.\n",
    "tf.config.experimental.enable_op_determinism()\n",
    "```\n",
    "\n",
    "Note: `tf.keras.utils.set_random_seed` will do the following ([source](https://github.com/keras-team/keras/blob/f6c4ac55692c132cd16211f4877fac6dbeead749/keras/src/utils/rng_utils.py#L10)):\n",
    "\n",
    "```python\n",
    "import random\n",
    "random.seed(42)\n",
    "\n",
    "import numpy as np\n",
    "np.random.seed(42)\n",
    "\n",
    "tf.random.set_seed(42) # can be any number\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SQvMWYSdzNp8"
   },
   "outputs": [],
   "source": [
    "(train_data, train_targets), (test_data, test_targets) = tf.keras.datasets.boston_housing.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalization\n",
    "\n",
    "Compute `mean` and `std` from `train_data`, and apply those to both `train_data` and `test_data`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SQvMWYSdzNp8"
   },
   "outputs": [],
   "source": [
    "# compute the mean, subtract from `train_data`\n",
    "# then the std, and divide `train_data` by it\n",
    "\n",
    "# apply the same computation to `test_data` using `mean` and `std` computed above\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model building & callback"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Note"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can you make the function below more modular? You could modify it so that it accepts arguments changing the architecture of the network, and other hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SQvMWYSdzNp8"
   },
   "outputs": [],
   "source": [
    "def build_model(clear=True):\n",
    "    if clear:\n",
    "        tf.keras.backend.clear_session()\n",
    "    model = tf.keras.models.Sequential()\n",
    "    model.add(tf.keras.Input((train_data.shape[1],)))\n",
    "    model.add(tf.keras.layers.Dense(64, activation = 'relu'))\n",
    "    model.add(tf.keras.layers.Dense(64, activation = 'relu'))\n",
    "    model.add(tf.keras.layers.Dense(1))\n",
    "    model.compile(\n",
    "        optimizer='rmsprop',\n",
    "        loss='mse',\n",
    "        metrics=['mae']\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bOCOzAjOzNqC",
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CustomCallback(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, epochs):\n",
    "        super(tf.keras.callbacks.Callback, self).__init__()\n",
    "        self.epochs = epochs\n",
    "    def on_epoch_begin(self, epoch, logs=None):\n",
    "        c = ['|', '/', '-', '\\\\'] \n",
    "        print(f\"\\r{c[epoch % 4]} epoch: {epoch+1}/{self.epochs}\", end=\"\")\n",
    "    def on_train_end(self, logs=None):\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The K-fold algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2cubqyRFzNqG"
   },
   "outputs": [],
   "source": [
    "K = 4\n",
    "num_val_samples = len(train_data) // K\n",
    "num_epochs = 100\n",
    "all_mae_histories = []\n",
    "\n",
    "for i in range(K):\n",
    "    print('processing fold', i)\n",
    "    \n",
    "    # Prepare the validation data: data from partition i\n",
    "    a, b =        # prepare indices\n",
    "    val_data =    # extract validation samples from train_data\n",
    "    val_targets = # extract validation targets from train_targets\n",
    "    \n",
    "    # Prepare the training data: data from all other partitions\n",
    "    partial_train_data =    # extract partial train samples from train_data\n",
    "    partial_train_targets = # # extract partial train samples from  train_targets\n",
    "\n",
    "    # Build the Keras model (already compiled)\n",
    "    model = # use your function\n",
    "    \n",
    "    # Train the model using .fit()\n",
    "    # - train: partial_train_data, partial_train_targets\n",
    "    # - validation: val_data, val_targets\n",
    "    # - number of epochs, batch_size=1 for now\n",
    "    # - silent mode recommended, verbose=0\n",
    "    # collect the returned object in `history`\n",
    "\n",
    "    mae_history = # collect val_mae from history\n",
    "    # add mae_history to all_mae_histories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualise your results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can you think of a way to automate the visualisation once the training is done? This would mean encapsulating the plotting code into a function, and calling it once the K-fold loop is done."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7dNFOVfdzNqJ"
   },
   "outputs": [],
   "source": [
    "average_mae_history = np.array(all_mae_histories).mean(axis=0)\n",
    "plt.plot(range(1, len(average_mae_history) + 1), average_mae_history)\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Validation MAE')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8I58FoiazNqM"
   },
   "outputs": [],
   "source": [
    "def smooth_curve(points, beta = 0.9):       # beta must be between 0 and 1!\n",
    "    smoothed_points = []\n",
    "    for current in points:\n",
    "        if smoothed_points:                 # (an nonempty list is 'True')\n",
    "            previous = smoothed_points[-1]  # the last appended point\n",
    "                                            # ↓ a weighted sum of previous & point, controlled by beta\n",
    "            smoothed_points.append(beta * previous + (1 - beta) * current)\n",
    "        else:\n",
    "            smoothed_points.append(current) # at the start, the list is empty, we just add the first point\n",
    "    return smoothed_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7IaEOcb8zNqO"
   },
   "outputs": [],
   "source": [
    "smooth_mae_history = smooth_curve(average_mae_history[10:])\n",
    "plt.plot(range(1, len(smooth_mae_history) + 1), smooth_mae_history)\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Validation MAE')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Run k-fold validation on the Boston dataset;\n",
    "- At first, we used a mini-batch of 1. Experiment with different mini-batch sizes. What do you observe? Can you account for your observation?\n",
    "- Run a series of experiments to find the best model, like in previous labs.\n",
    "- A more advanced experiment could be to implement *iterated K-fold validation with shuffling*, as mentioned in the lecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retrain a final model (with the hyperparameters that yielded the best performance, up to the best epoch) on the entire the training data (`train_data` and `train_targets`) and evaluate on the test data (`test_data`, `test_targets`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can now use your model to make predictions on by selecting one data point in `test_data`, and compare the prediction to the equivalent price in `test_targets`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Advanced/Optional: the California dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the [`lab-5-CALIFORNIA.ipynb`](https://github.com/jchwenger/AI/blob/main/labs/5-lab/lab-5-CALIFORNIA.ipynb), steps are given to process the data in the California housing dataset from scratch. This is more involved, as the dataset has to be downloaded and processed manually. This counts as a 'not covered' dataset in the first coursework."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save and load models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To save and load models locally, you can use [the high-level API](https://www.tensorflow.org/tutorials/keras/save_and_load):\n",
    "```python\n",
    "model.save(\"my_imdb_model.keras\")\n",
    "```\n",
    "Later one, to reload it, use:\n",
    "```python\n",
    "reloaded_model = tf.keras.models.load_model('my_imdb_model.keras')\n",
    "```\n",
    "\n",
    "It is also possible to save not just the model, but also the state of your optimiser, and every variable used during training, using the more involved [checkpoints](https://www.tensorflow.org/guide/checkpoint#create_the_checkpoint_objects)."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
