{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C6gb6X1pzNp1"
   },
   "source": [
    "# The California Housing Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C6gb6X1pzNp1"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C6gb6X1pzNp1"
   },
   "source": [
    "### Colab Note"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Don't forget that you can link your notebook to your drive and save your work there. Then you can download and backup your models, reload them to keep training them, or upload datasets to your drive. \n",
    "\n",
    "```python\n",
    "import os\n",
    "import sys\n",
    "\n",
    "if 'google.colab' in sys.modules:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    os.chdir('drive/My Drive/') # 'My Drive' is the default name of Google Drives\n",
    "    os.listdir()\n",
    "    \n",
    "# use os.chdir(\"my-directory\") # to change directory, and\n",
    "# os.listdir()                 # to list its contents\n",
    "# os.getcwd()                  # to get the name of the current directory\n",
    "# os.mkdir(\"my-new-dir\")       # to create a new directory\n",
    "# See: https://realpython.com/working-with-files-in-python/\n",
    "\n",
    "# You can also use bash commands directly, preceded by a bang\n",
    "# !ls\n",
    "# However, the following will *not* change the Python directory \n",
    "# the notebook points to (use os.chdir for that)!\n",
    "# !cd my-directory\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UxAMektPDyQf"
   },
   "source": [
    "### For reproducible results\n",
    "\n",
    "```python\n",
    "tf.random.set_seed(42) # can be any number\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "s_a-FRQSH84B"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6ee-bCfzGkCq"
   },
   "source": [
    "## Method 1: Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vGOAu29gD1Jn"
   },
   "outputs": [],
   "source": [
    "(train_data, train_targets), (test_data, test_targets) = keras.datasets.california_housing.load_data(version=\"small\")\n",
    "print(train_data.shape, test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Uy3GsqAbJTZV",
    "outputId": "3b3b732e-0ac5-4ade-b630-35fe5085aa14"
   },
   "outputs": [],
   "source": [
    "print(test_targets.max())\n",
    "print(test_targets.min())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute `mean` and `std` from `train_data`, and apply those to both `train_data` and `test_data`. Also, divide `train_targets` and `test_targets` by `100000` to work on a sensible range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Wet33LwpHZfL"
   },
   "outputs": [],
   "source": [
    "# compute the mean, subtract from `train_data`\n",
    "# then the std, and divide `train_data` by it\n",
    "mean = train_data.mean(axis = 0)\n",
    "std = train_data.std(axis = 0)\n",
    "# shift & rescale\n",
    "x_train = (train_data - mean) / std \n",
    "\n",
    "# create an `x_test from `test_data`  using `mean` and `std` computed above\n",
    "x_test = (test_data - mean) / std\n",
    "\n",
    "# create `y_train` and `y_test` by dividing \n",
    "# `train_targets` and `test_targets` by 100_000\n",
    "\n",
    "y_train = train_targets / 100000\n",
    "y_test = test_targets / 100000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model building & callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "g_5i-iAKFCKR"
   },
   "outputs": [],
   "source": [
    "def build_model(\n",
    "    layers=[64, 64],\n",
    "    activation=\"relu\",\n",
    "    dropout_rate=0,\n",
    "    regularizer=None,\n",
    "    regularizer_rate=0.002,\n",
    "    optimizer=\"rmsprop\",\n",
    "    clear=True\n",
    "):\n",
    "    \"\"\"\n",
    "    Model building function\n",
    "    \n",
    "    Args:\n",
    "        layers (iterable): [units, activation]\n",
    "        dropout_rate (0: deactivated)\n",
    "        regularizer (None: deactivated): l1 or l2 regularizer for hidden layers\n",
    "        regularizer_rate (default: 0.002): rate applied to the regularizer\n",
    "        optimizer (string or tf.keras.optimizers object): optimizer to use\n",
    "        clear (boolean): whether to call tf.keras.backend.clear_session() before creating a new model\n",
    "\n",
    "    Returns:\n",
    "        the compiled Keras model\n",
    "    \"\"\"\n",
    "    if clear:\n",
    "        tf.keras.backend.clear_session()\n",
    "    model = tf.keras.models.Sequential()\n",
    "    model.add(tf.keras.Input((x_train.shape[1],)))\n",
    "    for units in layers:\n",
    "        model.add(\n",
    "            tf.keras.layers.Dense(\n",
    "                units, activation = activation,\n",
    "                kernel_regularizer=regularizer if regularizer is None else regularizer(regularizer_rate)\n",
    "            )\n",
    "        )\n",
    "        if dropout_rate > 0:\n",
    "            model.add(tf.keras.layers.Dropout(dropout_rate))\n",
    "    model.add(tf.keras.layers.Dense(1))\n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss='mse',\n",
    "        metrics=['mae']\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ynWYwJg7FCKR"
   },
   "source": [
    "##### Note"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ynWYwJg7FCKR"
   },
   "source": [
    "Can you make the function above more modular? You could modify it so that it accepts arguments changing the architecture of the network, and other hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(\n",
    "    model, x_train, y_train, validation_data,\n",
    "    num_epochs, batch_size, callbacks=None, verbose=0\n",
    "):\n",
    "    \"\"\"\n",
    "    Training function\n",
    "    \n",
    "    Args:\n",
    "        model (compiled Keras model)\n",
    "        x_train (np.array or tf tensor): the training data\n",
    "        y_train (np.array or tf tensor): the training targets\n",
    "        validation_data (iterable): tuple/list containing validation data and targets (both either np.array or tf tensor)\n",
    "        num_epochs (int): the number of epochs to train for\n",
    "        batch_size (int): the batch size\n",
    "        callbacks (iterable): a list/tuple containing Keras callbacks\n",
    "        verbose (int): verbosity levels for model.fit()\n",
    "\n",
    "    Returns:\n",
    "        the history object returned by model.fit()\n",
    "    \"\"\"    \n",
    "    if validation_data is not None:\n",
    "        x_val, y_val = validation_data\n",
    "    # Train the model (in silent mode, verbose=0)\n",
    "    return model.fit(\n",
    "        x_train, y_train,\n",
    "        validation_data=(x_val, y_val) if validation_data else None,\n",
    "        epochs=num_epochs, batch_size=batch_size,\n",
    "        callbacks=callbacks,\n",
    "        verbose=verbose,        \n",
    "    )    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Custom Callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bOCOzAjOzNqC",
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CustomCallback(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, epochs):\n",
    "        super(tf.keras.callbacks.Callback, self).__init__()\n",
    "        self.epochs = epochs\n",
    "    def on_epoch_begin(self, epoch, logs=None):\n",
    "        c = ['|', '/', '-', '\\\\']\n",
    "        print(f\"\\r{c[epoch % 4]} epoch: {epoch+1}/{self.epochs}\", end=\"\")\n",
    "    def on_train_end(self, logs=None):\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The K-fold algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 400
    },
    "id": "2cubqyRFzNqG",
    "outputId": "166d813c-4428-462d-edac-143ceb09f7de"
   },
   "outputs": [],
   "source": [
    "K = 4\n",
    "num_val_samples = len(x_train) // K\n",
    "num_epochs = 100\n",
    "all_mae_histories = []\n",
    "for i in range(K):\n",
    "    print('processing fold', i)\n",
    "\n",
    "    # Prepare the validation data: data from partition i\n",
    "    a, b = i * num_val_samples, (i + 1) * num_val_samples\n",
    "    val_data = x_train[a : b]\n",
    "    val_targets = y_train[a : b]\n",
    "\n",
    "    # Prepare the training data: data from all other partitions\n",
    "    partial_x_train = np.concatenate([x_train[:a], x_train[b:]], axis=0)\n",
    "    partial_y_train = np.concatenate([y_train[:a], y_train[b:]], axis=0)\n",
    "\n",
    "    # Build the Keras model (already compiled)\n",
    "    model = build_model()\n",
    "\n",
    "    # Train the model (in silent mode, verbose=0)\n",
    "    history = model.fit(\n",
    "        partial_x_train,\n",
    "        partial_y_train,\n",
    "        validation_data=(val_data, val_targets),\n",
    "        epochs=num_epochs, batch_size=1, verbose=0,\n",
    "        callbacks=[CustomCallback(num_epochs)]\n",
    "    )\n",
    "\n",
    "    mae_history = history.history['val_mae']\n",
    "    all_mae_histories.append(mae_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aZ5Fp--7FCKS"
   },
   "source": [
    "### Visualise your results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aZ5Fp--7FCKS"
   },
   "source": [
    "Can you think of a way to automate the visualisation once the training is done? This would mean encapsulating the plotting code into a function, and calling it once the K-fold loop is done."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7dNFOVfdzNqJ"
   },
   "outputs": [],
   "source": [
    "average_mae_history = np.array(all_mae_histories).mean(axis=0)\n",
    "plt.figure(figsize=(10,2))\n",
    "plt.plot(range(1, len(average_mae_history) + 1), average_mae_history)\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Validation MAE')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8I58FoiazNqM"
   },
   "outputs": [],
   "source": [
    "def smooth_curve(points, beta = 0.9):       # beta must be between 0 and 1!\n",
    "    smoothed_points = []\n",
    "    for current in points:\n",
    "        if smoothed_points:                 # (an nonempty list is 'True')\n",
    "            previous = smoothed_points[-1]  # the last appended point\n",
    "                                            # ↓ a weighted sum of previous & point, controlled by beta\n",
    "            smoothed_points.append(beta * previous + (1 - beta) * current)\n",
    "        else:\n",
    "            smoothed_points.append(current) # at the start, the list is empty, we just add the first point\n",
    "    return smoothed_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7IaEOcb8zNqO"
   },
   "outputs": [],
   "source": [
    "smooth_mae_history = smooth_curve(average_mae_history[5:])\n",
    "plt.figure(figsize=(10,2))\n",
    "plt.plot(range(1, len(smooth_mae_history) + 1), smooth_mae_history)\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Validation MAE')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oV50wyjqLd6v"
   },
   "source": [
    "### Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oV50wyjqLd6v"
   },
   "source": [
    "- Run k-fold validation on the California dataset;\n",
    "- Notice that the mini-batch size is set to 1. Experiment with different mini-batch sizes. What do you observe? Can you account for your observation?\n",
    "- Run a series of experiments to find the best model, like in previous labs.\n",
    "\n",
    "The obvious thing to be done here is to compare the results between the small random subset and the full dataset, if you were to train models on it (don't forget to split into train, validation and test sets when you work on the full data!). Varying the size of the test set could also be of interest."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Experiment 1\n",
    "\n",
    "- Test various batch sizes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First of all, here are two examples of functions plotting the validation MAE and the smoothed version.\n",
    "\n",
    "The following uses two subplots, aligning the `x` axis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subplots_avg_and_smooth(average_mae_history, omit=5):\n",
    "    \n",
    "    fig, axs = plt.subplots(2,1, figsize=(10,4), sharex=True)\n",
    "\n",
    "    # plot the raw history\n",
    "    axs[0].plot(range(1, len(average_mae_history) + 1), average_mae_history)\n",
    "    axs[0].set_ylabel('Validation MAE', fontsize=8)\n",
    "\n",
    "    # create the EMA data and plot it\n",
    "    smooth_mae_history = smooth_curve(average_mae_history[omit:])\n",
    "    axs[1].plot(range(omit + 1, len(smooth_mae_history) + omit + 1), smooth_mae_history)\n",
    "    axs[1].set_xlabel('Epochs')\n",
    "    axs[1].set_ylabel(f\"Validation MAE (from {omit})\", fontsize=8)\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "subplots_avg_and_smooth(average_mae_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The second one plots the exponential moving average (EMA) of our MAE values on top of the raw ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_avg_and_smooth(average_mae_history, omit=5):\n",
    "\n",
    "    smooth_mae_history = smooth_curve(average_mae_history[omit:])\n",
    "    \n",
    "    plt.figure(figsize=(10,2))\n",
    "    plt.plot(range(1, len(average_mae_history) + 1), average_mae_history, label=\"avg mae\")\n",
    "    plt.plot(range(omit + 1, len(smooth_mae_history) + omit + 1), smooth_mae_history, label=f\"smoothed avg mae (from {omit})\")\n",
    "    plt.ylabel('Validation MAE', fontsize=8)\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "plot_avg_and_smooth(average_mae_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will now gather the code required for the K-Fold algorithm into a function, for ease of use."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A slightly modified callback that knows which fold we are in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FoldCallback(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, epochs, fold):\n",
    "        super(tf.keras.callbacks.Callback, self).__init__()\n",
    "        self.epochs = epochs\n",
    "        self.fold = fold\n",
    "    def on_epoch_begin(self, epoch, logs=None):\n",
    "        c = ['|', '/', '-', '\\\\']\n",
    "        print(f\"\\r        {c[epoch % 4]} fold: {self.fold + 1} | epoch: {epoch+1}/{self.epochs}\", end=\"\")\n",
    "    def on_train_end(self, logs=None):\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The K-fold validation function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_kfold(\n",
    "    x_train, y_train, model_params,\n",
    "    batch_size, K=4, num_epochs=100,\n",
    "    clear=True\n",
    "):\n",
    "    \"\"\"\n",
    "    Run the K-Fold algorithm\n",
    "    \n",
    "    Args:\n",
    "        x_train (np.array or tf tensor): the training data\n",
    "        y_train (np.array or tf tensor): the training targets\n",
    "        model_params (dict): a dictionary containing parameters (used to configure the model in\n",
    "             various runs, and to retrieve the best params later), structured like so:\n",
    "            {\n",
    "                \"layers\":           [units_1, units_2, ..., units_3], # units per layer, determines the number of layers\n",
    "                \"activation\":       \"relu\", # which activation to use at each layer\n",
    "                \"dropout_rate\":     0,      # the dropout rate (0: no dropout)\n",
    "                \"regularizer_rate\": 0,      # the regularizer rate (not used if \"regularizer\" is None)\n",
    "                \"regularizer\":      None    # the regularizer to use (pass a regularizer object, e.g. `tf.keras.regularizers.l2`)\n",
    "            }\n",
    "        batch_size (int): the batch size\n",
    "        K (int): the number of folds\n",
    "        num_epochs (int): the number of epochs per training run\n",
    "        clear (bool): whether to call tf.keras.backend.clear_session() before the runs\n",
    "\n",
    "    Returns:\n",
    "        all_mae_histories (list, validation mae values for K runs)\n",
    "    \"\"\"    \n",
    "    if clear:\n",
    "        tf.keras.backend.clear_session()\n",
    "        \n",
    "    num_val_samples = len(x_train) // K\n",
    "    all_mae_histories = []\n",
    "    \n",
    "    for i in range(K):\n",
    "        \n",
    "        # Prepare the validation data: data from partition i\n",
    "        a, b = i * num_val_samples, (i + 1) * num_val_samples\n",
    "        val_data = x_train[a : b]\n",
    "        val_targets = y_train[a : b]\n",
    "        \n",
    "        # Prepare the training data: data from all other partitions\n",
    "        partial_x_train = np.concatenate([x_train[:a], x_train[b:]], axis=0)\n",
    "        partial_y_train = np.concatenate([y_train[:a], y_train[b:]], axis=0)\n",
    "    \n",
    "        # Build the Keras model (already compiled)\n",
    "        model = build_model(**model_params) # https://realpython.com/python-kwargs-and-args/\n",
    "        \n",
    "        # Train the model\n",
    "        history = train(\n",
    "            model,\n",
    "            partial_x_train,\n",
    "            partial_y_train,\n",
    "            validation_data=(val_data, val_targets),\n",
    "            num_epochs=num_epochs, batch_size=batch_size,\n",
    "            callbacks=[FoldCallback(num_epochs, i)]\n",
    "        )\n",
    "    \n",
    "        mae_history = history.history['val_mae']\n",
    "        all_mae_histories.append(mae_history)\n",
    "        del model # save memory\n",
    "        \n",
    "    return all_mae_histories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will use the same model parameters as in the initial example. I also implement a helper function to print the parameters easily."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_params = {\n",
    "    \"layers\":           [64, 64],  \n",
    "    \"activation\":       \"relu\",\n",
    "    \"dropout_rate\":     0,\n",
    "    \"regularizer_rate\": 0,\n",
    "    \"regularizer\":      None\n",
    "}\n",
    "\n",
    "# https://realpython.com/python-kwargs-and-args/\n",
    "def print_params(params, **kwargs):\n",
    "    print(f\"Model params:\")\n",
    "    # print params\n",
    "    for k,v in params.items():\n",
    "        print(f\" - {k}: {v}\")\n",
    "    # print additional keyword arguments\n",
    "    for k,v in kwargs.items():\n",
    "        print(f\" - {k}: {v}\")\n",
    "    print(\"-\" * 30) \n",
    "\n",
    "print_params(model_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training four models with four different batch sizes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Additionally, it is useful to have a helper function to retrieve the epoch and lowest value from a list of value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_lowest_mae(hist):\n",
    "    epoch = np.argmin(hist)\n",
    "    best_mae = hist[epoch]\n",
    "    return epoch, best_mae"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are now ready to train models on various batch sizes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc # we will need to clear the memory to prevent the Colab session to crash\n",
    "\n",
    "num_epochs = 100\n",
    "batch_sizes = [1, 16, 64, 256, 512]\n",
    "\n",
    "msg = \"Testing various batch sizes\"\n",
    "print(msg)\n",
    "print(\"-\"*len(msg))\n",
    "print_params(model_params)\n",
    "\n",
    "all_epochs = []\n",
    "all_maes = []\n",
    "for b in batch_sizes:\n",
    "\n",
    "    print(f\" - batch size: {b}\")\n",
    "    print()\n",
    "\n",
    "    # run k-fold\n",
    "    mae_histories = run_kfold(\n",
    "        x_train, y_train, model_params,\n",
    "        batch_size=1, K=4, num_epochs=num_epochs\n",
    "    )\n",
    "    \n",
    "    # compute the mean\n",
    "    avg_mae_history = np.array(mae_histories).mean(axis=0)\n",
    "    \n",
    "    # plot\n",
    "    plot_avg_and_smooth(avg_mae_history)\n",
    "    \n",
    "    # retrieve & save results\n",
    "    best_mae_epoch, best_mae = retrieve_lowest_mae(avg_mae_history)\n",
    "    all_epochs.append(best_mae_epoch)\n",
    "    all_maes.append(best_mae)\n",
    "\n",
    "    # print best mae\n",
    "    print(f\"      Lowest MAE: {best_mae} at epoch {best_mae_epoch+1}\")\n",
    "    print(\"      \" + \"-\" * 80)\n",
    "    print()\n",
    "\n",
    "    gc.collect() # save memory\n",
    "\n",
    "# sort all our results\n",
    "indz = np.argsort(np.array(all_maes))\n",
    "sorted_epochs = np.array(all_epochs)[indz][::-1] # reverse sort\n",
    "sorted_maes = np.array(all_maes)[indz][::-1]\n",
    "sorted_batch_sizes = np.array(batch_sizes)[indz][::-1]\n",
    "\n",
    "# string formatting\n",
    "longest_bs = len(str(max(batch_sizes)))\n",
    "longest_ep = len(str(max(all_epochs)))\n",
    "\n",
    "# print our final results\n",
    "print(\"=\" * 80)\n",
    "print(\"Results:\")\n",
    "for bs, mae, ep in zip(sorted_batch_sizes, sorted_maes, sorted_epochs):\n",
    "    print(f\" - batch size: {bs:>{longest_bs}} | lowest val mae: {mae:>.5f} at epoch: {ep:>{longest_ep}}\")\n",
    "\n",
    "print()\n",
    "print(f\"The best MAE result, {sorted_maes[-1]} (epoch {sorted_epochs[-1]}), was achieved with batch size {sorted_batch_sizes[-1]}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best value is obtained with batch size `256`, and it so happens that it is also the run that reached the best result the fastest, at epoch `38`. In the runs performed, increasing the batch size seems to have had a positive effect on our final results, at least up until `256`, after which the MAE value stagnaged (it is technically worse at `512`, but by a very small margin). It might be interesting to see if this result is robust, by running experiments with more batch sizes, and seeing if we see a smooth decrease of returns as the batch size increases. This would also help establishing what part the randomness in our system plays in this particular result (best result reached with batch size `256`, at epoch `38`): if the MAE value truly stagnates beyond a certain batch size for these hyperparameters, then random runs might yield a best result for various batch sizes beyond this point, without any significant influence on our results. In this case, it might be best to focus on what might be the smallest batch size from which we can reasonably establish the stagnation starts from.\n",
    "\n",
    "It is also interesting to note that the epoch at which the best (lowest) MAE value is reached is very similar (around 60-66) for batch sizes `1`, `16`, `64`. Given that the epochs seem to behave in a relatively similar fashion as with the MAE values themselves (with the lowest for batch size `256`, then going back up), more experiments with more batch sizes could also help us ascertain whether there is a phenomenon where there is a 'sweet spot', yielding both the best validation MAE value, and at the earliest epoch, with worsening results when we increase the batch size beyond this point.\n",
    "\n",
    "If we plotted those results, we would then expect to see the val MAE curve decreasing and flatlining (or increasing again perhaps) after the sweet spot, whereas the best epoch would display a U shape, with the numbers increasing again with higher batch sizes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Experiments 2\n",
    "\n",
    "- Testing random search with *iterated K-fold validation with shuffling*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the tools we developed above, we can now proceed to expand our experiments to tune other hyperparameters as well. Even if this isn't as common as grid search, **random search**, where we randomly select has some hyperparameters, and set up the number of runs we wish to perform according to our compute and time constraints, has some proponents, such as Andrej Karpathy. He summarizes the argument in favour of random search in the following way: \"Intuitively, this is because neural nets are often much more sensitive to some parameters than others. In the limit, if a parameter a matters but changing b has no effect then you’d rather sample a more throughly than at a few fixed points multiple times.\"  \n",
    "Source: [\"A Recipe for Training Neural Networks\", 5. Tune, Apr 25, 2019](https://karpathy.github.io/2019/04/25/recipe/#5-tune)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is an additional plotting helper, this time to plot multiple MAE histories (with some transparency) as well as the average of those."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_multiple_histories(histories, avg, label=\"fold:\", omit=5, figsize=(8,2)):\n",
    "    plt.figure(figsize=figsize)\n",
    "    # quite subtle and frustrating business to make sure the epochs on the \n",
    "    # plots show the same results as when printing (shifts by ones are the worst!)\n",
    "    for i, hist in enumerate(histories):\n",
    "        h = hist[omit:]\n",
    "        plt.plot(range(omit + 1, len(h) + omit + 1), h, label=f\"{label} {i+1}\", alpha=.2)\n",
    "    a = avg[omit:]\n",
    "    plt.plot(range(omit + 1, len(a) + omit + 1), a, label=f\"average\", color='r')\n",
    "    plt.xticks(range(omit + 1, len(a) + omit + 1), fontsize=6)\n",
    "    plt.ylabel('Validation MAE', fontsize=8)\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will need a utility to generate random hyperparameters. Here, each hyperparameter we wish to test is examined in advance, so that we have an idea of what values to expect, and then we use `NumPy` either to generate numbers, or to pick one element in an array for us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_params():\n",
    "    return {\n",
    "        \"layers\":           [2**np.random.randint(3,8)] * np.random.randint(1,4), # [8] to [256,256,256]       \n",
    "        \"activation\":       np.random.choice([\"relu\", \"tanh\"]),\n",
    "        \"dropout_rate\":     np.random.choice([0, .1, .3, .5]),  # this way 0 dropout sometimes happens\n",
    "        \"regularizer_rate\": np.random.random() * .5,            # 0 - .5\n",
    "        \"regularizer\":      np.random.choice(\n",
    "                                [None, tf.keras.regularizers.l1, tf.keras.regularizers.l2]\n",
    "                            ),\n",
    "    }\n",
    "\n",
    "print_params(random_params()) # generate and print"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now it is possible to write a function wrapping `run_kfold`, and feeding it a shuffled version of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iterated_kfold(\n",
    "    x_train, y_train,\n",
    "    model_params, batch_size,\n",
    "    n_iter=5, K=4, num_epochs=100,\n",
    "):\n",
    "\n",
    "    \"\"\"\n",
    "    Run Iterated K-Fold with Shuffling\n",
    "    \n",
    "    Args:\n",
    "        x_train (np.array or tf tensor): the training data\n",
    "        y_train (np.array or tf tensor): the training targets\n",
    "        model_params (dict): a dictionary containing parameters (used to configure the model in\n",
    "             various runs, and to retrieve the best params later), structured like so:\n",
    "            {\n",
    "                \"layers\":           [units_1, units_2, ..., units_3], # units per layer, determines the number of layers\n",
    "                \"activation\":       \"relu\", # which activation to use at each layer\n",
    "                \"dropout_rate\":     0,      # the dropout rate (0: no dropout)\n",
    "                \"regularizer_rate\": 0,      # the regularizer rate (not used if \"regularizer\" is None)\n",
    "                \"regularizer\":      None    # the regularizer to use (pass a regularizer object, e.g. `tf.keras.regularizers.l2`)\n",
    "            }\n",
    "        batch_size (int): the batch size\n",
    "        K (int): the number of folds for the K-fold algorithm\n",
    "        n_iter (int): the number of iterations (how many shufflings & k-folds we perofrm)\n",
    "        num_epochs (int): the number of epochs per training run\n",
    "\n",
    "    Returns:\n",
    "        best_overall_mae (float, best MAE value for all runs)\n",
    "        best_overall_mae_epoch (int, epoch at which the best value was reached)\n",
    "        iterated_avg_mae_history (list, average validation mae values for the best K-fold run)\n",
    "    \"\"\"   \n",
    "    \n",
    "    assert x_train.shape[0] == y_train.shape[0], f\"`x_train` ({x_train.shape[0]}) and `y_train` ({y_train.shape[0]}) must contain the same amount of elements!\"\n",
    "\n",
    "    all_iterated_mae_histories = []\n",
    "    \n",
    "    for i in range(n_iter):\n",
    "        \n",
    "        print()\n",
    "        print(f\"Iteration: {i+1}/{n_iter} | K-folding with k={K}\")\n",
    "        print()\n",
    "\n",
    "        # shuffling indices\n",
    "        shuffled_indz = np.random.permutation(x_train.shape[0])\n",
    "\n",
    "        # using indices to shuffle data & targets\n",
    "        shuffled_x_train = x_train[shuffled_indz]\n",
    "        shuffled_y_train = y_train[shuffled_indz]\n",
    "\n",
    "        # run k-fold on shuffled dataset\n",
    "        mae_histories = run_kfold(\n",
    "            shuffled_x_train, shuffled_y_train,\n",
    "            model_params, batch_size,\n",
    "            K=K, num_epochs=num_epochs,\n",
    "        )\n",
    "        \n",
    "        # compute the mean and append to our histories\n",
    "        avg_mae_history = np.array(mae_histories).mean(axis=0)\n",
    "        all_iterated_mae_histories.append(avg_mae_history)\n",
    "        \n",
    "        # # plot each fold & average\n",
    "        # plot_multiple_histories(mae_histories, avg_mae_history)\n",
    "        \n",
    "        best_mae_epoch, best_mae = retrieve_lowest_mae(avg_mae_history)\n",
    "        print()\n",
    "        print(f\"      Lowest average MAE: {best_mae} at epoch {best_mae_epoch + 1}.\")\n",
    "        print(\"      \" + \"-\" * 80)\n",
    "        \n",
    "        gc.collect() # save memory\n",
    "\n",
    "    print()\n",
    "    msg = f\"Finished performing {n_iter} iterations, results:\"\n",
    "    print(\"=\" * len(msg))\n",
    "    print(msg)    \n",
    "\n",
    "    iterated_avg_mae_history = np.array(all_iterated_mae_histories).mean(axis=0)\n",
    "\n",
    "    # plot\n",
    "    plot_multiple_histories(\n",
    "        all_iterated_mae_histories, iterated_avg_mae_history, \n",
    "        label=\"iteration:\", figsize=(17,3))\n",
    "\n",
    "    best_overall_mae_epoch, best_overall_mae = retrieve_lowest_mae(iterated_avg_mae_history)\n",
    "    \n",
    "    print()\n",
    "    print(f\"After {n_iter} x {K} = {n_iter*K} runs, lowest MAE result: {best_overall_mae} at epoch {best_overall_mae_epoch + 1}.\")\n",
    "    print()\n",
    "    print_params(model_params)\n",
    "    \n",
    "    return best_overall_mae, best_overall_mae_epoch, iterated_avg_mae_history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we generate random parameters outside the call to `iterated_kfold`, and simply save the current parameters if the MAE result is lower than the currently saved best result. This cell is likely to take some time to run, especially if `n_trials` is large!\n",
    "\n",
    "Here we run `5` trials (sets of hyperparameters), and each of those is tested on `2` iterations of the K-fold algorithm (with `K = 3`), each run training for `100` epochs, as a demonstration of how the system works, but given more time, one could certainly consider increasing these numbers, to see if it is possible to obtain an even lower MAE value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_results = {\n",
    "    \"mae\": np.inf, # to start with\n",
    "}\n",
    "\n",
    "msg = \"Random Search through Iterated K-Fold with Shuffling\"\n",
    "print(msg)\n",
    "print(\"-\"*len(msg))\n",
    "\n",
    "n_trials = 5\n",
    "\n",
    "# O nestedness! We try 10 different random parameters\n",
    "for i in range(n_trials):\n",
    "\n",
    "    # get random params\n",
    "    model_params = random_params()\n",
    "    # get random batch size\n",
    "    batch_size = 2 ** np.random.randint(0,5)\n",
    "\n",
    "    # print\n",
    "    print()\n",
    "    print(f\"Trial: {i+1}/{n_trials}, generating random hyperparameters...\")\n",
    "    print()\n",
    "    print_params(model_params, batch_size=batch_size)\n",
    "\n",
    "    # run n_iter x k experiments\n",
    "    best_mae, best_epoch, _ = iterated_kfold(\n",
    "        x_train, y_train,\n",
    "        model_params, batch_size,\n",
    "        num_epochs=100,\n",
    "        n_iter=2, K=3,\n",
    "    )\n",
    "    \n",
    "    # update results\n",
    "    if best_mae < best_results[\"mae\"]:\n",
    "        best_results = {\n",
    "            \"mae\": best_mae,\n",
    "            \"epoch\": best_epoch,\n",
    "            \"params\": model_params,\n",
    "            \"batch_size\": batch_size\n",
    "        }\n",
    "\n",
    "    print()\n",
    "    print(\"-\" * 140)\n",
    "\n",
    "print(f\"Best result found: MAE: {best_results['mae']} at epoch {best_results['epoch'] + 1}.\")\n",
    "print_params(best_results[\"params\"], batch_size=best_results[\"batch_size\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cfwCUU0uIMEP"
   },
   "source": [
    "### 2. Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cfwCUU0uIMEP"
   },
   "source": [
    "Retrain the best model:\n",
    " - with the same hyperparameters\n",
    " - on the entire the training data (`train_data` and `train_targets`)\n",
    " - without validation data\n",
    " - up until the best epoch (lowest average MAE)\n",
    " - and then evaluate on the test data (`test_data`, `test_targets`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model = build_model(**best_results[\"params\"])\n",
    "_ = train(\n",
    "    final_model,\n",
    "    train_data,\n",
    "    train_targets,\n",
    "    validation_data=None,\n",
    "    num_epochs=best_results[\"epoch\"],\n",
    "    batch_size=best_results[\"batch_size\"]\n",
    ")\n",
    "\n",
    "result = model.evaluate(test_data, test_targets, verbose=0)\n",
    "print(\"Final results:\")\n",
    "print(f\"MSE: {result[0]}, MAE: {result[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our final result is an MAE of $3.32$ (approximately \\$3'320) on the test set. This is not an amazing result: one would hope that running more trials would lead better hyperparameters. It would in fact be quite damning if, after running many trials of the **random search**, we weren't able to improve this result by much. Then, one would probably have to study the influence of each parameter more closely, to see which ones are more likely to yield a better performance (one thing that was not included in the current framework was a thorough study of optimizers and learning rates, for instance!)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can now use your model to make predictions by selecting one data point in `x_test`, and compare the prediction to the equivalent price in `y_test`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = np.random.randint(x_test.shape[0])\n",
    "pred_price = model.predict(x_test[n:n+1], verbose=0)[0,0]\n",
    "print(f\"Predicted price: ${pred_price * 100_000:.1f}\")\n",
    "print(f\"Ground truth:    ${y_test[n]  * 100_000}\")\n",
    "print(f\"Error:           ${abs(pred_price - y_test[n])  * 100_000:.1f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[California Housing](https://www.dcc.fc.up.pt/~ltorgo/Regression/cal_housing.html), original website. (Also available on Kaggle: [California Housing, Kaggle](https://www.kaggle.com/datasets/camnugent/california-housing-prices).)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
