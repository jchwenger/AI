{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The IMDB and Reuters (and MNIST) problems are examples of classification\n",
    "\n",
    "Decide a particular class from a finite number of possibilities\n",
    "\n",
    "They are discrete problems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "The IMDB and Reuters (and MNIST) problems are examples of single label classification: decide a particular class from a finite number of possibilities. They are 'discrete' problems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Regression** problems, on the other hand, are continuous\n",
    "\n",
    "E.g. Predicting tomorrow's temperature, the time to run a marathon or... "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "**Regression** problems, on the other hand, are continuous. For example, Predicting tomorrow's temperature, the time to run a marathon or... "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "1970s house prices in a Boston suburb "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "1970s house prices in a Boston suburb. The problem is continuous because houses can have (almost) any price - house price is (essentially) a continuous variable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The Boston housing dataset\n",
    "\n",
    "The aim is the prediction of the median house price on the basis of knowledge of local property tax, crime rate, rooms per dwelling, accesibility to highways and nine other features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "\n",
    "The aim, for the Boston housing dataset, is the prediction of the median house price on the basis of knowledge of local property tax, crime rate, rooms per dwelling, accesibility to highways and nine other features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "There are only 506 data samples, split into 404 training and 102 test \n",
    "\n",
    "Furthermore, each feature has a different scale\n",
    "\n",
    "Some features are values in $[0, 1]$, some in $[1, 12]$, some in $[0, 100]$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "There are only 506 data samples, split into 404 training and 102 test and furthermore, each feature has a different scale. Some features are values in $[0, 1]$, some in $[1, 12]$, some in $[0, 100]$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(404, 13) (102, 13)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.datasets import boston_housing\n",
    "\n",
    "(train_data, train_targets), (test_data, test_targets) = boston_housing.load_data()\n",
    "print(train_data.shape, test_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "There are 404 and 102 samples in training and test sets, and each label has 13 numerical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  1.23247   0.        8.14      0.        0.538     6.142    91.7\n",
      "   3.9769    4.      307.       21.      396.9      18.72   ]\n"
     ]
    }
   ],
   "source": [
    "print(train_data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "The first sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([15.2, 42.3, 50. , 21.1, 17.7, 18.5, 11.3, 15.6, 15.6, 14.4])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_targets[:10] # in 1000's"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "The targets of the first ten samples in thousands of dollars."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    1.2325    0.0000    8.1400    0.0000    0.5380    6.1420   91.7000    3.9769\n",
      "\n",
      "    0.0218   82.5000    2.0300    0.0000    0.4150    7.6100   15.7000    6.2700\n",
      "\n",
      "    4.8982    0.0000   18.1000    0.0000    0.6310    4.9700  100.0000    1.3325\n",
      "\n",
      "    0.0396    0.0000    5.1900    0.0000    0.5150    6.0370   34.5000    5.9853\n",
      "\n",
      "    3.6931    0.0000   18.1000    0.0000    0.7130    6.3760   88.4000    2.5671\n",
      "\n",
      "    0.2839    0.0000    7.3800    0.0000    0.4930    5.7080   74.3000    4.7211\n",
      "\n",
      "    9.1870    0.0000   18.1000    0.0000    0.7000    5.5360  100.0000    1.5804\n",
      "\n",
      "    4.0974    0.0000   19.5800    0.0000    0.8710    5.4680  100.0000    1.4118\n",
      "\n",
      "    2.1551    0.0000   19.5800    0.0000    0.8710    5.6280  100.0000    1.5166\n",
      "\n",
      "    1.6286    0.0000   21.8900    0.0000    0.6240    5.0190  100.0000    1.4394\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for row in range(10):\n",
    "    for col in range(8):\n",
    "        x = train_data[row, col]        \n",
    "        print(\"{:10.4f}\".format(x), end='')\n",
    "    print('\\n') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "The data in tabular form: samples in rows, features in columns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "These ranges present difficulties\n",
    "\n",
    "Neural networks have difficulty adapting to heterogeneous data \n",
    "\n",
    "The data will have to be **normalised**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "These ranges present difficulties because neural networks have difficulty adapting to heterogeneous data. The data will have to be **normalised**"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
