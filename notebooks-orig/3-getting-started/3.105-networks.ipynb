{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "A feed forward network is a directed acyclic graph of layers\n",
    "\n",
    "A linear stack of layers is common but there are also two-branch layers, multihead layers, 'Inception' layers..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "A feed forward network is a directed acyclic graph of layers. A linear stack of layers is common but there are also two-branch layers, multihead layers, 'Inception' layers... again, these more advanced networks are covered in Part 2 of Deep Learning With Python."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The topology of a network and the layer functions define a space of possible data transformations\n",
    "\n",
    "The layer transformation \n",
    "\\begin{align*}\n",
    "y_l = f_l(w_l \\cdot x_l + b_l) := L_l(x_l)\n",
    "\\end{align*}\n",
    "\n",
    "depends on the choice of activation, $f_l$, and the parameter values $(w_l, b_l)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "The topology of a network and the layer functions define a space of possible data transformations. The layer transformation, written here as L sub l, depends on the choice of activation and the parameters w and b."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "For example a three layer network transforms $x$ to $y$:\n",
    "\n",
    "\\begin{align*}\n",
    "y = L_3(L_2((L_1(x))))\n",
    "\\end{align*}\n",
    "\n",
    "Think of the parameters $(w_1, b_1, w_2, b_2, w_3, b_3)$ as a point in a multi-dimensional space - the **hypothesis space**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "A three layer network chains L sub 1, L sub 2 and L sub 3. The layer parameters can be thought of as a point in a multi-dimensional 'hypothesis space'. Each point in the hypothesis space corresponds to a particular uncrumpling of the data.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The hypothesis space is arbitrary\n",
    "\n",
    "Rely on best practices\n",
    "\n",
    "DL is *engineering*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "The hypothesis space - defined by the depth of the network and the size and activation of each layer - is arbitrary. There is no formula. We have to rely on rules of thumb, best practices - deep learning is closer to engineering than it is to mathematics. "
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
