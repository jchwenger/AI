{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Vectorisation \n",
    "\n",
    "- all inputs must be floating point tensors\n",
    "\n",
    "- for example, words in text data  are one-hot encoded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "Data preprocessing\n",
    "\n",
    "Vectorisation: all inputs must be floating point tensors. For example, words in text data  are one-hot encoded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Normalisation\n",
    "\n",
    "- digit classification - integer vector elements in $[0, 255]$ normalised by casting as floats and dividing by 255 to give floating point data in $[0, 1]$\n",
    "\n",
    "- house prices - the data was normalised so that each feature had mean of 0 and std of 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "Normalisation:  in the digit classification, integer vector elements in $[0, 255]$ were normalised by casting as floats and dividing by 255 to give floating point data in $[0, 1]$ and in the house prices example the data was normalised so that each feature had a mean of 0 and a standard deviation of 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Gradient descent works best if data is homogeneous and constrained"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "Gradient descent works best if data is homogeneous and constrained. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Constrain\n",
    "\n",
    "- aim to put data values in $[0, 1]$ or $[-1, 1]$ \n",
    "- weights and biases are initialised with small values otherwise a few large inputs might dominate training "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "Aim to put data values in $[0, 1]$ or $[-1, 1]$ and weights and biases should be initialised with small values otherwise a few large inputs might dominate training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Homogeneity \n",
    "\n",
    "- all features take values in roughly the same range\n",
    "- inhomogeneity can trigger large gradient updates and hamper convergence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "All features should ideally take values in roughly the same range because inhomogeneity can trigger large gradient updates and hamper convergence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Normalisation to a mean of 0 and standard deviation of 1 can help but is not always necessary \n",
    "\n",
    "(e.g. we didn't normalise the digit data in this way) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "Normalisation to a mean of 0 and standard deviation of 1 can help but is not always necessary - we didn't normalise the digit data in this way) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Missing values\n",
    "\n",
    "- sometimes a data point lacks a feature\n",
    "\n",
    "- you could fill the missing data with zeros (as long as 0 isn't already meaningful)\n",
    "\n",
    "- the network will learn to ignore 0's because the 0's don't correlate with anything"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "Missing values: sometimes a data point lacks a feature. You could fill the missing data with zeros (as long as 0 isn't already meaningful). The network will learn to ignore 0's because the 0's don't correlate with anything."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Perhaps the test data has missing values but the training data does not\n",
    "\n",
    "In that case, duplicate some training data and randomly place 0's in some features (but leave the test data alone!) so that the network can learn to ignore missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "Perhaps the test data has missing values but the training data does not. In that case, duplicate some training data and randomly place 0's in some features  so that the network can learn to ignore missing values. But leae the test data alone!"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
