{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Today"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Attendance\n",
    "\n",
    "[The link to SEAts](https://goldsmithscollege.sharepoint.com/sites/intranet-supporting-students/SitePages/SEAtS--QR-codes-for-check-in.aspx?utm_campaign=SEAtS%20reminder%2027.09.22&utm_source=emailCampaign&utm_content=&utm_medium=email)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "----\n",
    "\n",
    "## 9.110 Various approaches to AI\n",
    "\n",
    "*Artificial Intelligence* is the automation of thought: from spreadsheets to humanoid robots\n",
    "\n",
    "*Machine Learning*, a subfield of AI \n",
    "\n",
    "= automated thought by training programs by exposure to data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "*Deep Learning* is one of many branches of ML\n",
    "\n",
    "DL models are long chains of geometric transformations\n",
    "\n",
    "Implemented as neural networks\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The operations are structured into modules called *layers*\n",
    "\n",
    "DL models are graphs of layers \n",
    "\n",
    "DL layers are parameterised by *weights* (and biases)\n",
    "\n",
    "Weights change during training - learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 9.120 Why DL is special\n",
    "\n",
    "DL, in only a few years, has achieved a range of tasks that were previously considered to be very difficult for computers:\n",
    "- machine perception\n",
    "- information extraction from images, videos and sound\n",
    "- speech recognition\n",
    "- smart assistants\n",
    "- machine translation\n",
    "- many more"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Some practitioners (e.g. F. Chollet) claim that given enough human-annotated training data, DL models can be equivalent to humans in these kind of tasks\n",
    "\n",
    "Some claim that 'perception has been solved'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "We are in the middle of a period of intense interest and hype - an AI 'summer'\n",
    "\n",
    "DL stands to transform many industries and businesses *even if no further progress is made*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 9.130 How to think about DL\n",
    "\n",
    "DL - it's not that hard to understand\n",
    "\n",
    "DL models apply a series of simple geometric transformations to vectorised data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The total of the chain of simple transformations is a complex transformation from an input space to a target space\n",
    "\n",
    "The transformations must be *differentiable*\n",
    "\n",
    "The layer parameters that determine transformations change during training in order to lower a loss function \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "This loss must also be differentiable\n",
    "\n",
    "Premise: meaning can be derived by smooth mappings between vector spaces\n",
    "\n",
    "But meaning can be represented in other ways, for example by graphs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The representation of meaning by graphs was the original stimulus for *connectionism* and was realised in artificial neural networks\n",
    "\n",
    "However ANN's bear little resemblance to the brain "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "DL experts talk about *layered representations*, *hierarchical representation learning* and *deep differentiable models of chained geometric transforms* \n",
    "\n",
    "Despite this jargonised, abstract viewpoint - promoted by DLWP - deep learning concepts and implementations derive from (artificial) neural networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Always good to have several ways of thinking about the same thing\n",
    "\n",
    "Especially if these ways are complementary\n",
    "\n",
    "*Artificial neurons sending signals along connecting wires*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 9.140 Key enabling technologies\n",
    "\n",
    "- Algorithms: incremental innovations, especially since 2012\n",
    "- Big data: Large perceptual data bases\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- GPU: fast parallel GPU computation: the NVIDIA gaming GPU was particularly important\n",
    "- Open source/public libraries/APIs: CUDA, TensorFlow, PyTorch, Numpy..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 9.150 The DL workflow\n",
    "\n",
    "-  Define the problem: \n",
    "    - what data is available, \n",
    "    - what are you trying to predict?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "-  Identify a measure of success \n",
    "    -  e.g. the prediction accuracy\n",
    "-  Define an evaluation procedure \n",
    "    -  training and validation sets and a reserved test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "-  Vectorise and if necessary normalise data\n",
    "-  Develop a baseline model that beats a common sense baseline\n",
    "-  Tune hyper-parameters according to validation performance \n",
    "-  Overfit and regularise/downsize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 9.160 Key network architectures\n",
    "\n",
    "Three families: dense, convolutional and recurrent\n",
    "\n",
    "Each type matches a particular task and encodes assumptions about the structure of the data i.e. a hypothesis space\n",
    "\n",
    "The network types can be combined"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- General data - fully connected (dense) layers\n",
    "- Image data - 2D convnets\n",
    "- Text data - 1D convnets (preferred) or RNNs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- Time series data - RNNs (preferred) or 1D convnets\n",
    "- Other types of sequence data - RNNs or convnets\n",
    "    - Prefer RNNs if the order is important (as in time series) and convnets otherwise (for example, text)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- Video data - 3D convnets for motion or 2D convnets for frame level feature extraction followed by an RNN or a convnet to process the resulting sequence\n",
    "- Volumetric data - 3D convnets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Densely connected networks\n",
    "\n",
    "A stack of dense layers\n",
    "\n",
    "No specific structure in the data is assumed. (Unlike, for example, 2D convolutional layers which assume *local* structure.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Commonly used for categorical data (e.g. the input features are lists of attributes such as the Boston Housing dataset.)\n",
    "\n",
    "Also used as the final classification or regression stage of most other networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Binary classification\n",
    "\n",
    "The final layer is a single sigmoid unit. \n",
    "\n",
    "The model is trained with the binary cross-entropy loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Dense(32, activation = 'relu', \n",
    "                       input_shape = (num_input_features, )))\n",
    "model.add(layers.Dense(32, activation = 'relu'))\n",
    "model.add(layers.Dense(1, activation = 'sigmoid'))\n",
    "\n",
    "model.compile(optimizer = 'rmsprop', loss = 'binary_crossentropy')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "##### Single label multi-class classification\n",
    "\n",
    "Number of final dense layer units = number of classes\n",
    "\n",
    "Softmax activation\n",
    "\n",
    "Categorical cross-entropy loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Dense(32, activation = 'relu', \n",
    "                       input_shape = (num_input_features, )))\n",
    "model.add(layers.Dense(32, activation = 'relu'))\n",
    "model.add(layers.Dense(num_classes, activation = 'softmax'))\n",
    "\n",
    "model.compile(optimizer = 'rmsprop', loss = 'categorical_crossentropy')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "##### Multi-label multi-class classification\n",
    "\n",
    "Final layer of sigmoid units\n",
    "\n",
    "Binary cross-entropy\n",
    "   \n",
    "'num_classes' copies of binary classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Dense(32, activation = 'relu', \n",
    "                       input_shape = (num_input_features, )))\n",
    "model.add(layers.Dense(32, activation = 'relu'))\n",
    "model.add(layers.Dense(num_classes, activation = 'sigmoid'))\n",
    "\n",
    "model.compile(optimizer = 'rmsprop', loss = 'binary_crossentropy')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Regression\n",
    "\n",
    "Number of final units = number of values\n",
    "\n",
    "Final units have no activation (any continuous value is possible)\n",
    "\n",
    "Loss is commonly MSE, but could be MAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Dense(32, activation = 'relu', \n",
    "                       input_shape = (num_input_features, )))\n",
    "model.add(layers.Dense(32, activation = 'relu'))\n",
    "model.add(layers.Dense(num_values))\n",
    "\n",
    "model.compile(optimizer = 'rmsprop', loss = 'mse')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Convnets\n",
    "\n",
    "The same geometric transformation is applied to different spatial locations (local receptive fields/patches)\n",
    "\n",
    "Resulting representations are translation invariant"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Applicable in any dimensionality\n",
    "\n",
    "Can be used for sequence processing if the sequence is translation invariant (not time series, but e.g. text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Convnet architecure:\n",
    "- Stacks of convolutional and pooling layers\n",
    "- Pooling layers downsize and increase the spatial extent of the filter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- End the stack with a flattening or a global pooling layer in order to turn the feature maps into vectors\n",
    "- Then add a dense classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Models with depthwise convolutions (these perform spatial convolutions separately on each channel) are smaller, quicker to train and, it seems, better "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "model - models.Sequential()\n",
    "model.add(layers.SeparableConv2D(32, \n",
    "                                 3, \n",
    "                                 activation = 'relu', \n",
    "                                 input_shape = (height, width, channels)))\n",
    "model.addlayers.SeparableConv2D(64, 3, activation = 'relu')\n",
    "model.add(layers.MaxPooling2D(2)) # i.e. pool_size = (2, 2)\n",
    "\n",
    "model.addlayers.SeparableConv2D(64, 3, activation = 'relu')\n",
    "model.addlayers.SeparableConv2D(128, 3, activation = 'relu')\n",
    "model.add(layers.MaxPooling2D(2)) \n",
    "\n",
    "model.addlayers.SeparableConv2D(64, 3, activation = 'relu')\n",
    "model.addlayers.SeparableConv2D(128, 3, activation = 'relu')\n",
    "model.add(layers.GlobalAveragePooling2D()) \n",
    "\n",
    "model.add(layers.Dense(32, activation = 'relu'))\n",
    "model.add(layers.Dense(num_classes, activation = 'softmax'))\n",
    "\n",
    "model.compile(optimizer = 'rmsprop', loss = 'categorical_crossentropy')\n",
    "          \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### RNNs\n",
    "\n",
    "Process sequences one step at a time\n",
    "\n",
    "They maintain a 'state' - the previous output\n",
    "\n",
    "Used for sequences without translation invariance e.g. for time series where the recent past is more informative than the distant past"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "`tensorflow.keras` has three RNN layers: `SimpleRNN`, `GRU` and `LSTM`\n",
    "\n",
    "Normally avoid `SimpleRNN`\n",
    "\n",
    "LSTM is more powerful than the GRU, but is computationally more exensive "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Interior layers in RNN stacks should return the full sequence of outputs \n",
    "\n",
    "The final RNN layer commonly return only the last output which contains information about the whole sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.LSTM(32, \n",
    "                      return_sequences = True, \n",
    "                      input_shape = (num_timesteps, num_features)))\n",
    "model.add(layers.LSTM(32, return_sequences = True))\n",
    "model.add(layers.LSTM(32))\n",
    "\n",
    "model.add(layers.Dense(num_classes, activation = 'sigmoid')) # multi-label\n",
    "\n",
    "model. compile(optimizer = 'rmsprop', loss = 'binary_crossentropy')\n",
    "          "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 9.170 Possibilites\n",
    "\n",
    "All of the following are learnable even if generalisation might be impossible.\n",
    "\n",
    "\n",
    "| Input | Output | Task | Example |\n",
    "|---|---|---|---|\n",
    "| category | category | predictive healthcare | medical records -> prediction of treatment outcome  |\n",
    "| category | continuous value |  behaviour | website attributes -> time spent on website |\n",
    "| \" | \" | quality control | product attributes -> probability of failure | \n",
    "| image | category | Doctor assistant | medical slides -> diagnosis |\n",
    "| \" | \" | self-driving vehicle | dash-cam -> steering commands |\n",
    "| \" | \" | board game | Go, chess images -> next move |\n",
    "| \" | \" | age prediction | selfies -> age |\n",
    "| image | continuous value | Diet helper | image of dish -> calorie count |\n",
    "| time series | category | weather | weather data in a grid of locations -> prediction at a single location |\n",
    "| \" | \" | brain-computer interface | EEG -> computer commands |\n",
    "| text | text | smart reply | emails -> one-lne replies |\n",
    "| \" | \" | answering questions | general knowledge questions -> answers |\n",
    "| \" | \" | summarising | long article -> short summary |\n",
    "| images | text | captioning | image -> short caption\n",
    "| text | images | conditioned image generation | short text -> matching image |\n",
    "| \" | \" | logo generation/selection | name and company description -> logo |\n",
    "| images | images | super-resolution | downsized inmages -> hi res versions |\n",
    "| \" | \" | visual depth sensing | image of indoor environment -> depth map |\n",
    "| images and text | text | visual QA | images and questions -> answers |\n",
    "| video and text | text | video QA | short videos and questions about the contents -> answers |\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
