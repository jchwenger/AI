{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "## import tensorflow as tf\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 8.100 Text generation\n",
    "\n",
    "We have seen how DL can analyse data - but can it also create?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "2015: Google's DeepDream produced psychedelic images\n",
    "\n",
    "2016: Prisma turns photos into 'paintings'\n",
    "\n",
    "2016: [Sunspring](https://www.youtube.com/watch?v=LY7x2Ihqjmc), an experimental film with an LSTM generated script\n",
    "\n",
    "https://www.youtube.com/watch?v=LY7x2Ihqjmc\n",
    "\n",
    "2000's: Neural network generated music"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Not human replacement, but augmented intelligence\n",
    "\n",
    "A different kind of intelligence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "##### The idea\n",
    "\n",
    "Artistic creation involves pattern recognition and technical skill - tedious work that can be mechanised\n",
    "\n",
    "Perceptual modalities, language, artwork and music all have statistical structure and statistical structure can be learned by DL algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "DL algorithms can learn a statistical *latent space*\n",
    "\n",
    "Sampling from the latent space 'creates' new artworks similar to the training data\n",
    "\n",
    "The algorithm attaches no meaning to the process and the product - but we might\n",
    "\n",
    "Potentially eliminates technical skill\n",
    "\n",
    "=> enables free expression; separates art from craft"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 8.120 Generating sequence data\n",
    "\n",
    "RNNs can generate new sequence data\n",
    "\n",
    "- musical notes\n",
    "\n",
    "- brushstrokes recorded on an iPad\n",
    "\n",
    "- handwriting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- speech synthesis\n",
    "\n",
    "- chatbox dialogue\n",
    "\n",
    "- Google's Smart Reply (2016) - automatic generation of short replies to emails and text messages."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "Train an ANN to predict the next token, or tokens, in a sequence using the previous tokens as input\n",
    "\n",
    "Text = words or characters\n",
    "\n",
    "Any text-trained model is known as a *language model*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "A language model captures the latent space of language i.e. its statistical structure\n",
    "\n",
    "1. Train model\n",
    "2. Present an initial *conditioning* text string\n",
    "3. Model predicts the next token(s)\n",
    "4. Add the generated text to the input text\n",
    "5. Go back to step 3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 8.130 The sampling strategy\n",
    "\n",
    "1. *Greedy sampling.* Select the most probable token - repetitive and unrealistic\n",
    "\n",
    "2. *Stochastic sampling.* Sample from the probability distribution of the next character"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Possible to sample from the softmax output which we know produces a 'probability' distribution\n",
    "\n",
    "But - uncontrollable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "*Uniform sampling* Each token has the same probability - maximum randomness  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "*Intermediate randomness* controlled by the softmax temperature - this is where we expect to find the more interesting, creative outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "###### Softmax temperature\n",
    "\n",
    "Remember, the softmax output is \n",
    "\n",
    "$\n",
    "p_i = \\frac{1}{N}e^{x_i}\n",
    "$\n",
    "\n",
    "where $N = \\sum e^{x_i}$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The parameterised softmax distribution is \n",
    "\n",
    "$\n",
    "q_i = \\frac{1}{N}e^\\frac{x_i}{T}\n",
    "$\n",
    "\n",
    "where $N = \\sum e^\\frac{x_i}{T}$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "The paramaterised softmax distribution is computed like this:\n",
    "\n",
    "1. Take logs: $\\frac{\\log(p_i)}{T} = \\frac{x_i}{T} - \\frac{N}{T}$\n",
    "2. Re-exponentiate: $e^{\\frac{\\log(p_i)}{T}} = c(T) e^{\\frac{x_i}{T}} \\text{ where }c\\text{ is a temperature dependent constant}$\n",
    "3. Find new normalisation: $N' = \\sum c(T) e^{\\frac{x_i}{T}}$\n",
    "4. Temperatured softmax: $q_i = \\frac{1}{N'}e^{\\frac{x_i}{T}} = \\frac{ e^{\\frac{x_i}{T}} }{\\sum e^{\\frac{x_i}{T}}} $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Limiting cases\n",
    "\n",
    "1. $T \\rightarrow 0$ \n",
    "\n",
    "$\\max\\left( \\frac{1}{N}e^{\\frac{x_i}{T}}\\right)$ dominates - greedy sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "2. $T \\rightarrow \\infty$ \n",
    "\n",
    "$e^{\\frac{x_i}{T}} \\rightarrow 1$ so $q_i \\rightarrow \\frac{1}{M}$ where $M$ is the number of softmax outputs - a uniform distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 8.140 Implementing character-level LSTM text generation\n",
    "\n",
    "A large training set is required for a good language model\n",
    "\n",
    "Any large text file such as Lord of the Rings, or even set of texts such as Wikipedia\n",
    "\n",
    "We will model the writings of a late C19 German philosopher \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "##### Preparing the data\n",
    "\n",
    "Downloading the corpus and converting to lowercase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corpus length: 600893\n"
     ]
    }
   ],
   "source": [
    "import tensorflow.keras as keras\n",
    "import numpy as np\n",
    "\n",
    "path = keras.utils.get_file(\n",
    "    'nietzsche.txt',\n",
    "    origin='https://s3.amazonaws.com/text-datasets/nietzsche.txt')\n",
    "text = open(path).read().lower()\n",
    "print('Corpus length:', len(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Extract partially-overlapping sequences of length `maxlen`, one-hot encodes and pack in a 3D Numpy array `x` of shape `(sequences, maxlen, unique_characters)`\n",
    "\n",
    "Prepare an array `y` containing the corresponding targets: the one-hot encoded characters that come right after each extracted sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sequences: 200278\n",
      "Unique characters: 57\n",
      "Vectorization...\n"
     ]
    }
   ],
   "source": [
    "# Length of extracted character sequences\n",
    "maxlen = 60\n",
    "\n",
    "# We sample a new sequence every `step` characters\n",
    "step = 3\n",
    "\n",
    "# This holds our extracted sequences\n",
    "sentences = []\n",
    "\n",
    "# This holds the targets (the follow-up characters)\n",
    "next_chars = []\n",
    "\n",
    "for i in range(0, len(text) - maxlen, step):\n",
    "    sentences.append(text[i: i + maxlen])\n",
    "    next_chars.append(text[i + maxlen])\n",
    "print('Number of sequences:', len(sentences))\n",
    "\n",
    "# List of unique characters in the corpus\n",
    "chars = sorted(list(set(text)))\n",
    "print('Unique characters:', len(chars))\n",
    "# Dictionary mapping unique characters to their index in `chars`\n",
    "char_indices = dict((char, chars.index(char)) for char in chars)\n",
    "\n",
    "# Next, one-hot encode the characters into binary arrays.\n",
    "print('Vectorization...')\n",
    "x = np.zeros((len(sentences), maxlen, len(chars)), dtype=np.bool)\n",
    "y = np.zeros((len(sentences), len(chars)), dtype=np.bool)\n",
    "for i, sentence in enumerate(sentences):\n",
    "    for t, char in enumerate(sentence):\n",
    "        x[i, t, char_indices[char]] = 1\n",
    "    y[i, char_indices[next_chars[i]]] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "###### Building the network\n",
    "\n",
    "A single `LSTM` layer followed by a `Dense` classifier and softmax over all possible characters\n",
    "\n",
    "(1D convnets as an alternative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers\n",
    "\n",
    "model = keras.models.Sequential()\n",
    "model.add(layers.LSTM(128, input_shape=(maxlen, len(chars))))\n",
    "model.add(layers.Dense(len(chars), activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Targets are one-hot encoded => use `categorical_crossentropy` loss:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.RMSprop(lr=0.01)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "##### Training and sampling the language model\n",
    "\n",
    "The sampling function:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "def sample(preds, temperature=1.0):\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds) / temperature\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    return np.argmax(probas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Train and generate text using a range of different temperatures at each epoch end\n",
    "\n",
    "=> monitor convergence and the impact of temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1\n",
      "1565/1565 [==============================] - 123s 79ms/step - loss: 1.9975\n",
      "--- Generating with seed: \"ngs is wholly\n",
      "superfluous. it is simply the result of opinio\"\n",
      "------ temperature: 0.2\n",
      "ngs is wholly\n",
      "superfluous. it is simply the result of opinion of the the enture the men an in the men the the instinct the externt the mankind the the men the the extence of the exterity of the men an the the still the the consequence of the the are of the men the have a men of the menting the men the the the menter the instinct the still the moral the finder the the the the the prosince of the the there are the the externce of the mankind there are a men \n",
      "------ temperature: 0.5\n",
      "e there are the the externce of the mankind there are a men an the extence of the makent there is liked the wark.\n",
      "\n",
      "13. there the inventer of one the instill there an to not one is the spirit. the himself, and the prose them and chilosophy and the concemition of the wills the enstance of the act of the an and the extract the great self-act of the religion of his to the mancers and the inthrester a means in the manker conception and deselves there are the co\n",
      "------ temperature: 1.0\n",
      "means in the manker conception and deselves there are the convery by ito extratce\n",
      "supposion it, evil, our is activine ecemony fined tak groex more--indeed beching a\n",
      "or living one h wen a varted. then being -eke, he and tengec\n",
      "pradence of not thoreby still are sompthysest trase homowiel\"-socrent,\" in livent\n",
      "plistation, so the samating the beacher but fore oppressain frume part\n",
      "a to eare criat masthy, athiss.\n",
      "\"in a concestion of\n",
      "the compunter\n",
      "cretusent to th\n",
      "------ temperature: 1.2\n",
      "y, athiss.\n",
      "\"in a concestion of\n",
      "the compunter\n",
      "cretusent to the\n",
      "dasm of him in estlbeknts all even aure which there, every intoide danwrenges\n",
      "therestvable--he to oliginable i freroped, bey ourself is prysepty to epo1; a men an at he ond, love haght\n",
      "cuntument need: oradian thus she, as i the th- didw.\n",
      "? be ha, fgicner, which not there most obli(g.\".=--? homean resent notity evil told be or the istemous oo every\n",
      "synstesually,,--as a mane even bosthrby, we cons\n",
      "epoch 2\n",
      "1565/1565 [==============================] - 130s 83ms/step - loss: 1.6229\n",
      "--- Generating with seed: \".\n",
      "\n",
      "249. every nation has its own \"tartuffery,\" and calls tha\"\n",
      "------ temperature: 0.2\n",
      ".\n",
      "\n",
      "249. every nation has its own \"tartuffery,\" and calls that the sense of the moral to the moral to the complession of the moral man in the complession of the strong the moral to the sense of the sensures to be still the complession of the farication of the spirit of the the presenty of the comparation of the more of the sense of the sense of the science of the moral the sense of the moral the servation of the moral will the complession of the propess of \n",
      "------ temperature: 0.5\n",
      "rvation of the moral will the complession of the propess of the spectity for other the their will the father and seess of the things to the lighter of the fairistic and\n",
      "exprentable to the aristifed the pridentary of the spirit in for the presenty of the belief to the haint the grouted to all the morally this may one one may be are is spirit and the comple distifucal to the same of the greatest and every concuted to this interest the fathers of the are real\n",
      "------ temperature: 1.0\n",
      " every concuted to this interest the fathers of the are really instinct of the\n",
      "tradual sumprows a most is lift will to\n",
      "real, and strare to the mortomed abow contrutedpition will berbje:\n",
      "if though gralline crue that is himself deed is their the volus in un-is todder . whom the complise semplitity and the yet, as wets used, in a paint whole animy  and lore yope of his greatffels, why charationment, it is the aoted to\n",
      ": and it hateselfvera, wellorc for him th\n",
      "------ temperature: 1.2\n",
      "it is the aoted to\n",
      ": and it hateselfvera, wellorc for him there it, its fore infirsuming theme liw branss\" and: bet\". andecoping\n",
      "the nun-alivingss to. iusheb, andrevation. is tarrss hands from which whichshed as greating by philosophing: every must i of\n",
      "virtumselfide not it nosedimes it is bolky regliged\" with ceas its\n",
      "yig, us lapidationse\"\n",
      "nevenonine one orifucaarefveride itsten from ignocound rum.\n",
      " wend\n",
      "cesses any\n",
      "impolity'y ugesshe: and honouge and be\n",
      "b\n",
      "epoch 3\n",
      "1565/1565 [==============================] - 135s 86ms/step - loss: 1.5292\n",
      "--- Generating with seed: \"belated fugitives.\n",
      "\n",
      "256. owing to the morbid estrangement wh\"\n",
      "------ temperature: 0.2\n",
      "belated fugitives.\n",
      "\n",
      "256. owing to the morbid estrangement which a significations, and the farse of the state of the same and the sense of the superistic for the state of the sense of the delight the higher of the same of the same in the stand of the same and the suffering and the sense of the same and delight the state of the superiting of the same that the same of the something in the same and in the suffering in the suffering of the state of the morality\n",
      "------ temperature: 0.5\n",
      " the suffering in the suffering of the state of the morality, it is stilled believe of the stand him in all mentavely protect in every of a surmound to lack the man what it out of a more principle and nature in his own man in all the soul and the deception in a progress of the superiting for the higher and only man be will the other immorality of the interest in the constance in a order \"in all greatest in such in must be morality so one for the farse and \n",
      "------ temperature: 1.0\n",
      "eatest in such in must be morality so one for the farse and to the on.\n",
      "\"there of\n",
      "the instancted sympathy him, as to onality covered\n",
      "blasinary in the beimentne. but oneself, for the domeated that illsoquation. in\n",
      "every hin which shankent\n",
      "adevative sover religions, poines: see hise priwed those of the same instansioned. dongrancail naturivity and vooined apperspoistes, of morals that what must dospois,  that ideasly, the intelligeness, and that and belang di\n",
      "------ temperature: 1.2\n",
      "is,  that ideasly, the intelligeness, and that and belang dim]ley frembhing,\n",
      "shoutk, to wity.urnigidirine? suce gro\"tenes\n",
      "and\n",
      "unarouse\"\" in itsedard que amour! than sacribling\n",
      "same, not nationsus howeverhounners! in their graid logicilicather that oascement a peisoosaus it moral instrugulaten utility ot accodsy-soal. or\n",
      "flemers to so fat certed instance \"very f olds begutize coceeacs hiln--ruilnce that interents of sufferly we pholate, senscer\" in the\n",
      "ince\n",
      "epoch 4\n",
      "1565/1565 [==============================] - 152s 97ms/step - loss: 1.4812\n",
      "--- Generating with seed: \"ge appears in its most hideous aspect. this crushing of\n",
      "self\"\n",
      "------ temperature: 0.2\n",
      "ge appears in its most hideous aspect. this crushing of\n",
      "self-discovered because the state of the same the consequently the more always to the sense of the concerns of the sense of the sense of the sense of the supporsed the senses of the sense of the same the spirit and the sense of the sense of the same of the science of the sense of the same state and the sense of the same the other to the sense of the way to the same the sense of the sense of the world \n",
      "------ temperature: 0.5\n",
      " of the way to the same the sense of the sense of the world to the consequently let us have the\n",
      "entilation of the spirit,\n",
      "the way\n",
      "conscience. the most self-consequently the man as the sunterable all the spirits, he has reality and that in the prible, to conscience of the small to him would like the way to the says because he may been sensition, and in the way to the very being to the ellite to man they all to the world mere things the whole with the acts t\n",
      "------ temperature: 1.0\n",
      " they all to the world mere things the whole with the acts thee-counter--as slave \n",
      "greeks it always of the appear, art peiph gard by the formarped acendcuations of germans.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "hnow con\n",
      "ot upmite of all drempus. not gernans to\n",
      "goodidiacy\n",
      "but\n",
      "cannotice sort\n",
      "of geratest carnated as the deasts there1ble, lives man eurituble of\n",
      "a with why dasponsed every soke and delight more simplying and tappicious conclusioned.\n",
      "\n",
      "    goody have most the suppen, to peo\n",
      "------ temperature: 1.2\n",
      "icious conclusioned.\n",
      "\n",
      "    goody have most the suppen, to people seasilely.--more :ully\n",
      "etance.\n",
      "\n",
      "cainer morally we though tenours, there untimism errhly authar, stylet unhis phatificn, in whint\n",
      "no  is the concerns,n, id;\n",
      "and it is place how that doanctur.\n",
      "\n",
      "    who would hep they eef methadic zefer in him one yfastly usfuln aitual,\n",
      "sheare the more, men than of all ob? moben.\n",
      "the balt: dif with a po loug to beentias, is so-prewed for the weone as many countru\n",
      "epoch 5\n",
      "1565/1565 [==============================] - 137s 87ms/step - loss: 1.4492\n",
      "--- Generating with seed: \" own, that\n",
      "can set its aims thousands of years ahead; so tha\"\n",
      "------ temperature: 0.2\n",
      " own, that\n",
      "can set its aims thousands of years ahead; so that the same and the strong and the soul as a conscience of the more of the conscience of the same and the species of the spiritualy and the state of the same and the state of the say, and the soul and the spirituality of the species of the stand and the same and strong and the moral the sensially and the same and the state of the strong and the spirit of the self-and the spirit of the state of the \n",
      "------ temperature: 0.5\n",
      "d the spirit of the self-and the spirit of the state of the english the being is as himself, and to have the whole has for the spiritually have the such a world mistaken of the acts the promisens of the same country and the sensial rule of order and remains of a be an evidence, or of a feeling of a stuphich the such a formerly, feels the hough every souls of the reason with a respect of the best the precial reason and the the \"sensition of the art of the g\n",
      "------ temperature: 1.0\n",
      "he precial reason and the the \"sensition of the art of the german formul!,, he knows thinkerly nootharich. or self merarrity af atterners\n",
      "and  and when ata; even of \"compehly have\n",
      "in self-relations of unhe germany dingers digher belongness throught in difficumed to origin of the jestured, be above accirability itself as alise in man does not believed borkimis\n",
      "and advent all\n",
      "a wholly isoal,\" regernt. the\n",
      "igno\" as would religion much ourselves should he dise\n",
      "------ temperature: 1.2\n",
      "t. the\n",
      "igno\" as would religion much ourselves should he disevery ous stine out.--hh\"--be command: is, a look in\n",
      "love ettlber! .ut, which or\n",
      "entably stfermant and more proces, and stranged\n",
      "enoruglant cales foolness, example, and \"areyonel), falsishs, unwilly faction--norefuar as oppas.\n",
      "ul handy and create to allogictleval histown, as his ckrictive\n",
      "elew. to\n",
      "much sal, the greated to germans. in such a fe:s) carry deness. ye\n",
      "han case..\", anway we facco.cendan\n",
      "\n",
      "epoch 6\n",
      "1565/1565 [==============================] - 143s 92ms/step - loss: 1.4263\n",
      "--- Generating with seed: \" glorify himself and gave superiority and distinction,--this\"\n",
      "------ temperature: 0.2\n",
      " glorify himself and gave superiority and distinction,--this in the something the same the sense of the moral something of the same of the father the same the world of the present the same the more the conditions of the father the same the same with it is the present men to be a thing the same of the same the same of the father the same which all one which one with the same which the sense of the sense of the from and the sense of the same which all the em\n",
      "------ temperature: 0.5\n",
      "sense of the from and the sense of the same which all the emotion and one for the chinds of which allowed every one of the organce of the way the father himself becomes the free words of the interpretation of the world of the world and in them and the truth and still a allow with the from from the same in the earthesic of the fare and discassion of the same of him which or the first\n",
      "the intermored with the most world of his particulary of his from the will\n",
      "------ temperature: 1.0\n",
      " with the most world of his particulary of his from the will be not uteponaory\n",
      "tovowerve in prestants. with most to rari himself lifers and praises of longer\n",
      "to emotion of rangele. perfessist, the vible nifhed at\n",
      "over no lo.\n",
      ", smitted, e strodificual serientsy men the\n",
      "whylh finds have done at the exception of his decerringness.=--seriously?       jigh that in his dogmanilate--they are inducted finder there\n",
      "and\n",
      "seschs of \"make god,\n",
      "to make to be as look and\n",
      "------ temperature: 1.2\n",
      "der there\n",
      "and\n",
      "seschs of \"make god,\n",
      "to make to be as look and mod tardwadued    nlety--is orh-nate, they or noflegether: something and coed-musicism; how gaur disgude.--togethinolierly, and byst danfoted, accurable, epsivinden, we ppicul,m mame fi;\n",
      "naims of the bra: for the addate simrition outwarn poseison, who orr known knowlegg of mallquentrpance,   more fore!-\n",
      "the orl. who essentive, moral finditaic far, revarious.] at\n",
      "wish \"undrbabants (pudists the wha\n",
      "epoch 7\n",
      "1565/1565 [==============================] - 154s 98ms/step - loss: 1.4088\n",
      "--- Generating with seed: \"o wield the sceptre.\n",
      "the christian pessimists of practice, h\"\n",
      "------ temperature: 0.2\n",
      "o wield the sceptre.\n",
      "the christian pessimists of practice, he is the same same sense of the fact of the other conduct and the same and some and some one of the spirit and all the same stronge and also the superiority in the conduct and some the same sufferess of the same stronger and some states and some of the spirit and assumed the states and proses and stronges of the ancient and sense of the spirit and the are soul and also its conscience of the proves\n",
      "------ temperature: 0.5\n",
      "pirit and the are soul and also its conscience of the provessy in the form is be an incertain promasing who has not been lack and formul, and man and such a have the fear, the states in the sense and present morality of the processe of its own who has been assures as a music fore all the other wastle of the education of the still and menit one long to have proper the origin of the heposhing the precisely with the assumerance, which the old pated between fo\n",
      "------ temperature: 1.0\n",
      "ecisely with the assumerance, which the old pated between fortem last exercice necessaried--yes original foregnoth and over-pride of shame methally forehated truves of an act oftiness sas.\n",
      "in feels a man a good perhaps sort and\n",
      "as modes modes in the cunderstand, and be human to an earistwacher. the be again allow it god ohh dey-sopether of themselves from the cails:\n",
      "here is when he let be the\n",
      "enhuring of person one more tiral soul more contemption of the\n",
      "e\n",
      "------ temperature: 1.2\n",
      "ring of person one more tiral soul more contemption of the\n",
      "evloughtiitions difficed and english them to\n",
      "could have is every bood higher objection is and  thever keen to the e?fings\n",
      "togeate, more\n",
      "typancy is tires evil, a \"morality-\"antilation as then, impyes yerefdle, perhope wide gro: constants when it . hent consiturable mequerists, \"therought, all, undity of theselver\n",
      "wkbonaus, involboded ley ralitijakilement in\n",
      "referonge of the\n",
      "represeffhe, regard on th\n",
      "epoch 8\n",
      "1426/1565 [==========================>...] - ETA: 12s - loss: 1.3943"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-9486ed95c0ca>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'epoch'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;31m# Fit the model for 1 epoch on the available training data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     model.fit(x, y,\n\u001b[0m\u001b[1;32m      8\u001b[0m               \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m               epochs=1)\n",
      "\u001b[0;32m~/anaconda3/envs/tf-2-3/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf-2-3/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1098\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1099\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf-2-3/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf-2-3/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    805\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    806\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 807\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    808\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf-2-3/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2829\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2831\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf-2-3/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1841\u001b[0m       \u001b[0;31m`\u001b[0m\u001b[0margs\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1842\u001b[0m     \"\"\"\n\u001b[0;32m-> 1843\u001b[0;31m     return self._call_flat(\n\u001b[0m\u001b[1;32m   1844\u001b[0m         [t for t in nest.flatten((args, kwargs), expand_composites=True)\n\u001b[1;32m   1845\u001b[0m          if isinstance(t, (ops.Tensor,\n",
      "\u001b[0;32m~/anaconda3/envs/tf-2-3/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1921\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1922\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1923\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1924\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m~/anaconda3/envs/tf-2-3/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    543\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 545\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    546\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf-2-3/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import random\n",
    "import sys\n",
    "\n",
    "for epoch in range(1, 60):\n",
    "    print('epoch', epoch)\n",
    "    # Fit the model for 1 epoch on the available training data\n",
    "    model.fit(x, y,\n",
    "              batch_size=128,\n",
    "              epochs=1)\n",
    "\n",
    "    # Select a text seed at random\n",
    "    start_index = random.randint(0, len(text) - maxlen - 1)\n",
    "    generated_text = text[start_index: start_index + maxlen]\n",
    "    print('--- Generating with seed: \"' + generated_text + '\"')\n",
    "\n",
    "    for temperature in [0.2, 0.5, 1.0, 1.2]:\n",
    "        print('------ temperature:', temperature)\n",
    "        sys.stdout.write(generated_text)\n",
    "\n",
    "        # We generate 400 characters\n",
    "        for i in range(400):\n",
    "            sampled = np.zeros((1, maxlen, len(chars)))\n",
    "            for t, char in enumerate(generated_text):\n",
    "                sampled[0, t, char_indices[char]] = 1.\n",
    "\n",
    "            preds = model.predict(sampled, verbose=0)[0]\n",
    "            next_index = sample(preds, temperature)\n",
    "            next_char = chars[next_index]\n",
    "\n",
    "            generated_text += next_char\n",
    "            generated_text = generated_text[1:]\n",
    "\n",
    "            sys.stdout.write(next_char)\n",
    "            sys.stdout.flush()\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "epoch 7\n",
    "1565/1565 [==============================] - 154s 98ms/step - loss: 1.4088\n",
    "--- Generating with seed: \"o wield the sceptre.\n",
    "the christian pessimists of practice, h\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "------ temperature: 0.2\n",
    "o wield the sceptre.\n",
    "the christian pessimists of practice, he is the same same sense of the fact of the other conduct and the same and some and some one of the spirit and all the same stronge and also the superiority in the conduct and some the same sufferess of the same stronger and some states and some of the spirit and assumed the states and proses and stronges of the ancient and sense of the spirit and the are soul and also its conscience of the proves\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "------ temperature: 0.5\n",
    "pirit and the are soul and also its conscience of the provessy in the form is be an incertain promasing who has not been lack and formul, and man and such a have the fear, the states in the sense and present morality of the processe of its own who has been assures as a music fore all the other wastle of the education of the still and menit one long to have proper the origin of the heposhing the precisely with the assumerance, which the old pated between fo\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "------ temperature: 1.0\n",
    "ecisely with the assumerance, which the old pated between fortem last exercice necessaried--yes original foregnoth and over-pride of shame methally forehated truves of an act oftiness sas.\n",
    "in feels a man a good perhaps sort and\n",
    "as modes modes in the cunderstand, and be human to an earistwacher. the be again allow it god ohh dey-sopether of themselves from the cails:\n",
    "here is when he let be the\n",
    "enhuring of person one more tiral soul more contemption of the\n",
    "e\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "------ temperature: 1.2\n",
    "ring of person one more tiral soul more contemption of the\n",
    "evloughtiitions difficed and english them to\n",
    "could have is every bood higher objection is and  thever keen to the e?fings\n",
    "togeate, more\n",
    "typancy is tires evil, a \"morality-\"antilation as then, impyes yerefdle, perhope wide gro: constants when it . hent consiturable mequerists, \"therought, all, undity of theselver\n",
    "wkbonaus, involboded ley ralitijakilement in\n",
    "referonge of the\n",
    "represeffhe, regard on th"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Low temperature: extremely repetitive and predictable text, with realistic local structure - almost all words (= a local pattern of characters) are real English words \n",
    "\n",
    "Intermediate temperatures: more interesting, surprising, even creative text - sometimes completely new but plausible words are invented \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "High temperature: local structure breaks down and most words look random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "0.5 is the most interesting temperature in this case\n",
    "\n",
    "A bigger model, trained for longer and on more data, would achieve more coherent and \n",
    "realistic text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "But don't expect meaning!\n",
    "\n",
    "The network is merely sampling a statistical model of which characters follow other characters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 8.150 Wrapping-up\n",
    "\n",
    "* we can generate discrete sequence data by training a model to predict the next token(s) given previous tokens\n",
    "* in the case of text, such a model is called a _language model_ \n",
    "\n",
    "* based on either words or characters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* Sampling the next token requires balance between adhering to what the model judges likely, and introducing randomness\n",
    "* => _softmax temperature_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "----"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
