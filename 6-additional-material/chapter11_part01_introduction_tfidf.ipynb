{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "54fd3280-5c76-4e96-8a3c-218fec930e36",
   "metadata": {
    "id": "54fd3280-5c76-4e96-8a3c-218fec930e36"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import shutil\n",
    "import random\n",
    "import pathlib\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef03e5fc-a971-4931-a888-06e5b72e0985",
   "metadata": {
    "id": "ef03e5fc-a971-4931-a888-06e5b72e0985"
   },
   "source": [
    "### Downloading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "-LYh6f1pgper",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-LYh6f1pgper",
    "outputId": "17067fcc-84de-4134-f2f4-48a69d287866"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100 80.2M  100 80.2M    0     0  20.2M      0  0:00:03  0:00:03 --:--:-- 20.2M\n"
     ]
    }
   ],
   "source": [
    "DATASET_DIR = pathlib.Path(\"aclImdb\")\n",
    "\n",
    "if not DATASET_DIR.exists():\n",
    "    !curl -O https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n",
    "    !tar -xf aclImdb_v1.tar.gz # this untars the archive to a folder called aclImdb\n",
    "    !rm -r aclImdb/train/unsup\n",
    "\n",
    "MODELS_DIR = pathlib.Path(\"models\")\n",
    "MODELS_DIR.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a7718009-10dc-4428-aef3-660f94261912",
   "metadata": {
    "id": "a7718009-10dc-4428-aef3-660f94261912"
   },
   "outputs": [],
   "source": [
    "# code to split the data into train/val folders\n",
    "TRAIN_DIR = DATASET_DIR / \"train\"\n",
    "VAL_DIR = DATASET_DIR / \"val\"\n",
    "TEST_DIR = DATASET_DIR / \"test\"\n",
    "for category in (\"neg\", \"pos\"):\n",
    "    if not os.path.isdir(VAL_DIR / category):    # do this only once\n",
    "        os.makedirs(VAL_DIR / category)          # make 'neg'/'pos' dir in validation\n",
    "        files = os.listdir(TRAIN_DIR / category) # list files in 'train'\n",
    "        random.Random(1337).shuffle(files)       # shuffle using a seed\n",
    "        num_val_samples = int(0.2 * len(files))  # 2% of our samples for validation\n",
    "        val_files = files[-num_val_samples:]\n",
    "        for fname in val_files:                  # move our files\n",
    "            shutil.move(TRAIN_DIR / category / fname,\n",
    "                        VAL_DIR / category / fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9ac3ff05-4c93-42c5-9501-8b2092fb076d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9ac3ff05-4c93-42c5-9501-8b2092fb076d",
    "outputId": "5922d79f-f9b3-4dad-d57f-2fda3881191c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 20000 files belonging to 2 classes.\n",
      "Found 20000 files belonging to 2 classes.\n",
      "Found 5000 files belonging to 2 classes.\n",
      "Found 25000 files belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "train_ds = tf.keras.utils.text_dataset_from_directory(\n",
    "    TRAIN_DIR, batch_size=batch_size\n",
    ")\n",
    "train_ds = tf.keras.utils.text_dataset_from_directory(\n",
    "    TRAIN_DIR, batch_size=batch_size\n",
    ")\n",
    "val_ds = tf.keras.utils.text_dataset_from_directory(\n",
    "    VAL_DIR, batch_size=batch_size\n",
    ")\n",
    "test_ds = tf.keras.utils.text_dataset_from_directory(\n",
    "    TEST_DIR, batch_size=batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3b73a8b7-4b3c-47e9-90c5-a74b705cc01a",
   "metadata": {
    "id": "3b73a8b7-4b3c-47e9-90c5-a74b705cc01a"
   },
   "outputs": [],
   "source": [
    "text_only_train_ds = train_ds.map(lambda x, y: x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f411589f-ca2f-4931-bd91-33dfacd21fc3",
   "metadata": {
    "id": "95997174-9c2a-4e32-9e4d-aa03e6579aba"
   },
   "source": [
    "---\n",
    "\n",
    "### Bigrams with TF-IDF encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e91df9c-1c8a-4385-8098-643839036e75",
   "metadata": {
    "id": "95997174-9c2a-4e32-9e4d-aa03e6579aba"
   },
   "source": [
    "####  TF-IDF: Term Frequency / Inverse Document Frequency"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5419eff3-cc97-437b-a73d-f1749558512f",
   "metadata": {
    "id": "95997174-9c2a-4e32-9e4d-aa03e6579aba"
   },
   "source": [
    "- the most frequent terms in documents tell us something about the **topic**;  \n",
    "  (\"flower\" appearing often in a doc about flowers)\n",
    "- however, **some terms** appear **often and everywhere**;  \n",
    "  (\"the\", \"a\", are frequent in the whole dataset);  \n",
    "- to counteract that, divide the frequency in one doc by the frequency in all docs:\n",
    "\n",
    "$$\n",
    "\\bbox[5px,border:2px solid red]\n",
    "{\n",
    "\\text{TF-IDF} = \\frac{\\text{frequency in one document}}{\\text{frequency in all documents (dataset)}}\n",
    "}\n",
    "$$\n",
    "\n",
    "<small>[See Wikipedia the exact maths](https://en.wikipedia.org/wiki/Tf%E2%80%93idf)</small>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "926d762d-f631-4f70-8355-716a71d20402",
   "metadata": {
    "id": "926d762d-f631-4f70-8355-716a71d20402"
   },
   "outputs": [],
   "source": [
    "text_vectorization = tf.keras.layers.TextVectorization(\n",
    "    ngrams=2,\n",
    "    max_tokens=20000,\n",
    "    output_mode=\"count\" # configuring the `TextVectorization` layer to return token counts\n",
    ")\n",
    "\n",
    "text_vectorization.adapt(text_only_train_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "209349b5-cfd3-4ebe-a4b3-0b7cd52f348f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "209349b5-cfd3-4ebe-a4b3-0b7cd52f348f",
    "outputId": "2d89a54d-bd61-4753-c003-1a17cc10884d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([8 2 0 ... 0 0 0], shape=(20000,), dtype=int64)\n",
      "\n",
      "token    0 | frequency: 8 | decoded: [UNK]\n",
      "token    1 | frequency: 2 | decoded: the\n",
      "token  153 | frequency: 1 | decoded: over\n",
      "token  568 | frequency: 1 | decoded: over the\n",
      "token 1535 | frequency: 1 | decoded: dog\n",
      "token 3247 | frequency: 1 | decoded: fox\n",
      "token 3439 | frequency: 2 | decoded: quick\n",
      "token 4986 | frequency: 2 | decoded: brown\n",
      "token 6162 | frequency: 1 | decoded: jumps\n"
     ]
    }
   ],
   "source": [
    "vocabulary = text_vectorization.get_vocabulary()\n",
    "inverse_vocab = dict(enumerate(vocabulary))\n",
    "tokens = text_vectorization(\"the quick brown fox jumps over the quick brown dog\")\n",
    "print(tokens) # instead of just 1 at the word index we get a count!\n",
    "print()\n",
    "words = tf.where(tokens > 0)\n",
    "for word in words:\n",
    "    word = word.numpy().item()\n",
    "    print(f\"token {word:>4} | frequency: {tokens[word]} | decoded: {inverse_vocab[word]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "40602054-9453-4b04-bd9b-ddc5df5f470b",
   "metadata": {
    "id": "40602054-9453-4b04-bd9b-ddc5df5f470b",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "text_vectorization = tf.keras.layers.TextVectorization(\n",
    "    ngrams=2,\n",
    "    max_tokens=20000,\n",
    "    output_mode=\"tf_idf\", # configuring `TextVectorization` to return TF-IDF-weighted outputs\n",
    ")\n",
    "text_vectorization.adapt(text_only_train_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0f3791bd-b181-424e-92e5-cf890b53cc18",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0f3791bd-b181-424e-92e5-cf890b53cc18",
    "outputId": "fff402f8-21fc-46fe-f4df-835989d98331"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([42.621906   1.3945451  0.        ...  0.         0.         0.       ], shape=(20000,), dtype=float32)\n",
      "\n",
      "token    0 | tf-idf: 42.6219063 | decoded: [UNK]\n",
      "token    1 | tf-idf:  1.3945451 | decoded: the\n",
      "token  153 | tf-idf:  1.9289606 | decoded: over\n",
      "token  568 | tf-idf:  2.9110560 | decoded: over the\n",
      "token 1535 | tf-idf:  3.9795589 | decoded: dog\n",
      "token 3247 | tf-idf:  4.7938089 | decoded: fox\n",
      "token 3439 | tf-idf:  9.0870848 | decoded: quick\n",
      "token 4986 | tf-idf: 10.1312609 | decoded: brown\n",
      "token 6162 | tf-idf:  5.0974345 | decoded: jumps\n"
     ]
    }
   ],
   "source": [
    "vocabulary = text_vectorization.get_vocabulary()\n",
    "inverse_vocab = dict(enumerate(vocabulary))\n",
    "tokens = text_vectorization(\"the quick brown fox jumps over the quick brown dog\")\n",
    "print(tokens) # instead of just 1 or a count at the word index we get the tf-idf quantity!\n",
    "print()\n",
    "words = tf.where(tokens > 0)\n",
    "for word in words:\n",
    "    word = word.numpy().item()\n",
    "    print(f\"token {word:>4} | tf-idf: {tokens[word]:10.7f} | decoded: {inverse_vocab[word]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca6db221-a3ef-47ee-8a2d-224fe8bce583",
   "metadata": {
    "id": "ca6db221-a3ef-47ee-8a2d-224fe8bce583"
   },
   "source": [
    "---\n",
    "\n",
    "### Training a simple model with TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "55e52d0b-c1ef-4f13-be21-4445af688d73",
   "metadata": {
    "id": "55e52d0b-c1ef-4f13-be21-4445af688d73"
   },
   "outputs": [],
   "source": [
    "# our datasets\n",
    "tfidf_2gram_train_ds = train_ds.map(\n",
    "    lambda x, y: (text_vectorization(x), y),\n",
    "    num_parallel_calls=4)\n",
    "tfidf_2gram_val_ds = val_ds.map(\n",
    "    lambda x, y: (text_vectorization(x), y),\n",
    "    num_parallel_calls=4)\n",
    "tfidf_2gram_test_ds = test_ds.map(\n",
    "    lambda x, y: (text_vectorization(x), y),\n",
    "    num_parallel_calls=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2fd5365e-ab04-40e2-97c2-d84b4577b5c8",
   "metadata": {
    "id": "2fd5365e-ab04-40e2-97c2-d84b4577b5c8"
   },
   "outputs": [],
   "source": [
    "def get_model(max_tokens=20000, hidden_dim=16, clear=True):\n",
    "    \"\"\"\n",
    "    Our model-building utility\n",
    "    \"\"\"\n",
    "    if clear:\n",
    "        tf.keras.backend.clear_session()\n",
    "    inputs = tf.keras.Input(shape=(max_tokens,))\n",
    "    x = tf.keras.layers.Dense(hidden_dim, activation=\"relu\")(inputs)\n",
    "    x = tf.keras.layers.Dropout(0.5)(x)\n",
    "    outputs = tf.keras.layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "    model = tf.keras.Model(inputs, outputs)\n",
    "    model.compile(\n",
    "        optimizer=\"rmsprop\",\n",
    "        loss=\"binary_crossentropy\", # our labels are only 0 or 1 (negative/positive)\n",
    "        metrics=[\"accuracy\"]\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3d9ce932-1bc9-40ba-89e9-57b619324368",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 640
    },
    "id": "3d9ce932-1bc9-40ba-89e9-57b619324368",
    "outputId": "ca2db9b4-5595-4326-feae-b6c898b03dc2"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20000</span>)               │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                  │         <span style=\"color: #00af00; text-decoration-color: #00af00\">320,016</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">17</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20000\u001b[0m)               │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                  │         \u001b[38;5;34m320,016\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │              \u001b[38;5;34m17\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">320,033</span> (1.22 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m320,033\u001b[0m (1.22 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">320,033</span> (1.22 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m320,033\u001b[0m (1.22 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1009s\u001b[0m 2s/step - accuracy: 0.6466 - loss: 0.6488 - val_accuracy: 0.8810 - val_loss: 0.3096\n",
      "Epoch 2/10\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8164 - loss: 0.3942 - val_accuracy: 0.8734 - val_loss: 0.3099\n",
      "Epoch 3/10\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8296 - loss: 0.3440 - val_accuracy: 0.8766 - val_loss: 0.3162\n",
      "Epoch 4/10\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8509 - loss: 0.3137 - val_accuracy: 0.8780 - val_loss: 0.3296\n",
      "Epoch 5/10\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8753 - loss: 0.2847 - val_accuracy: 0.8852 - val_loss: 0.3262\n",
      "Epoch 6/10\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8925 - loss: 0.2548 - val_accuracy: 0.8864 - val_loss: 0.3484\n",
      "Epoch 7/10\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8953 - loss: 0.2491 - val_accuracy: 0.8886 - val_loss: 0.3294\n",
      "Epoch 8/10\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8964 - loss: 0.2355 - val_accuracy: 0.8764 - val_loss: 0.3517\n",
      "Epoch 9/10\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8992 - loss: 0.2322 - val_accuracy: 0.8642 - val_loss: 0.3663\n",
      "Epoch 10/10\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9046 - loss: 0.2314 - val_accuracy: 0.8642 - val_loss: 0.3875\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7ba9fdff8820>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = get_model()\n",
    "model.summary()\n",
    "\n",
    "callbacks = [\n",
    "    tf.keras.callbacks.ModelCheckpoint(\n",
    "        str(MODELS_DIR / \"tfidf_2gram.keras\"),\n",
    "        save_best_only=True\n",
    "    )\n",
    "]\n",
    "\n",
    "model.fit(\n",
    "    tfidf_2gram_train_ds.cache(),\n",
    "    validation_data=tfidf_2gram_val_ds.cache(),\n",
    "    epochs=10,\n",
    "    callbacks=callbacks\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fcf425ce-24db-474a-ac27-cb4cd1613d43",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fcf425ce-24db-474a-ac27-cb4cd1613d43",
    "outputId": "59f5b45e-149d-4909-aea1-7e4aea134dd9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m982s\u001b[0m 1s/step - accuracy: 0.8751 - loss: 0.3087\n",
      "Test acc: 0.875\n"
     ]
    }
   ],
   "source": [
    "# and testing\n",
    "model = tf.keras.models.load_model(MODELS_DIR / \"tfidf_2gram.keras\")\n",
    "_, acc = model.evaluate(tfidf_2gram_test_ds)\n",
    "print(f\"Test acc: {acc:.3f}\") # this did not beat the bigram model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "G4HvuEo0IV1N",
   "metadata": {
    "id": "G4HvuEo0IV1N"
   },
   "source": [
    "### Save models to Google Drive\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "JYIXMpgSV2ks",
   "metadata": {
    "id": "JYIXMpgSV2ks"
   },
   "outputs": [],
   "source": [
    "EXPORT=False\n",
    "\n",
    "if EXPORT:\n",
    "    # zip models\n",
    "    !zip tfidf.models.zip {MODELS_DIR}/*\n",
    "    # connect to drive\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    # copy zip to drive (adjust folder as needed)\n",
    "    !cp tfidf.models.zip drive/MyDrive/IS53024B-Artificial-Intelligence/models"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
