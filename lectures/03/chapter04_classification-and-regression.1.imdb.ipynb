{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "03a99f97-a8c7-4871-97ed-69196440c0d8",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Attendance\n",
    "\n",
    "[The link to SEAts](https://gold.seats.cloud/angular/#/lectures)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6639e0e-a393-4106-a21c-62a3002429d7",
   "metadata": {
    "id": "7bcf6188-684a-464c-bd97-29ec054c79f3"
   },
   "source": [
    "# 4 Classification and regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "657f86a4",
   "metadata": {
    "id": "657f86a4"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "# nice scatter point size\n",
    "plt.rcParams['lines.markersize'] = 2\n",
    "# more matplotlib shenanigans\n",
    "import matplotlib as mpl\n",
    "plt_fontsize = mpl.rcParams[\"font.size\"]\n",
    "\n",
    "from IPython.core.magic import register_cell_magic\n",
    "\n",
    "import keras\n",
    "\n",
    "os.environ[\"KERAS_BACKEND\"] = \"jax\"\n",
    "\n",
    "@register_cell_magic\n",
    "def backend(line, cell):\n",
    "    current, required = os.environ.get(\"KERAS_BACKEND\", \"\"), line.split()[-1]\n",
    "    if current == required:\n",
    "        get_ipython().run_cell(cell)\n",
    "    else:\n",
    "        print(\n",
    "            f\"This cell requires the {required} backend. To run it, change KERAS_BACKEND to \"\n",
    "            f\"\\\"{required}\\\" at the top of the notebook, restart the runtime, and rerun the notebook.\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef86b826",
   "metadata": {
    "id": "ef86b826",
    "tags": []
   },
   "source": [
    "## * Binary classification: data → scalar (probability of *one* class)\n",
    "\n",
    "*\\\"Here is a photo, is it a cat or not?\" (Negative/Positive, detecting if something is there, etc.)*\n",
    "\n",
    "#### Multiclass classification: data → vector (distribution over *many classes*)\n",
    "\n",
    "*\\\"Here is a photo, multiple choice for you: is it a cat, a dog, an airplane, a flower, ... ?*\n",
    "\n",
    "#### Regression: data → scalar (a continuous value describing the data)\n",
    "\n",
    "*\\\"Here is a data about a house, what is its price)?* <small>☠️☠️☠️ *Logistic regression* (*classification problem*) ≠ *regression*!!</small>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d6386c4-11e3-4842-9a74-72a7473e788b",
   "metadata": {
    "id": "f639357b-1288-4ac5-8484-3c71fe2e1ab3"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22935ebc-37f6-4ed4-85f8-a8cde68ebc7b",
   "metadata": {
    "id": "f639357b-1288-4ac5-8484-3c71fe2e1ab3"
   },
   "source": [
    "## Classifying movie reviews: a binary classification example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07d51b55-d013-4b65-bd97-47c78527aec2",
   "metadata": {
    "id": "f639357b-1288-4ac5-8484-3c71fe2e1ab3"
   },
   "source": [
    "### The IMDB dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f90b873c",
   "metadata": {
    "id": "f90b873c"
   },
   "source": [
    "Two-class, or binary, classification, is a common ML application.\n",
    "\n",
    "The [International Movie Data Base dataset](https://keras.io/api/datasets/imdb/) consists of 50000 highly polarised textual movie reviews.\n",
    "\n",
    "They are labelled **positive** or **negative**.\n",
    "\n",
    "Ships with Keras! 25000 training, 25000 testing.\n",
    "\n",
    "Each set has 50% positive reviews, 50% negative."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d026af3-fabf-4ad8-ab1d-dd53df098a9f",
   "metadata": {},
   "source": [
    "### Code: loading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b2361266",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b2361266",
    "outputId": "940c5a39-1252-4221-d5ba-1bfaa6c71d2d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000,) (25000,)\n"
     ]
    }
   ],
   "source": [
    "# download data                            # top 10000 most frequent words only, discard rare words ↓\n",
    "((train_data, train_labels), (test_data, test_labels)) = keras.datasets.imdb.load_data(num_words=10000)\n",
    "print(train_data.shape, test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8371e3a8-ea3c-4c09-a982-8e3481c5559a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8371e3a8-ea3c-4c09-a982-8e3481c5559a",
    "outputId": "39e9e4e9-e43b-412c-9fa5-277f62d3838c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 13, 244, 6, 87, 337, 7, 628, 2219, 5, 28, 285, 15, 240, 93, 23, 288, 549, 18, 1455, 673, 4, 241, 534, 3635, 8448, 20, 38, 54, 13, 258, 46, 44, 14, 13, 1241, 7258, 12, 5, 5, 51, 9, 14, 45, 6, 762, 7, 2, 1309, 328, 5, 428, 2473, 15, 26, 1292, 5, 3939, 6728, 5, 1960, 279, 13, 92, 124, 803, 52, 21, 279, 14, 9, 43, 6, 762, 7, 595, 15, 16, 2, 23, 4, 1071, 467, 4, 403, 7, 628, 2219, 8, 97, 6, 171, 3596, 99, 387, 72, 97, 12, 788, 15, 13, 161, 459, 44, 4, 3939, 1101, 173, 21, 69, 8, 401, 2, 4, 481, 88, 61, 4731, 238, 28, 32, 11, 32, 14, 9, 6, 545, 1332, 766, 5, 203, 73, 28, 43, 77, 317, 11, 4, 2, 953, 270, 17, 6, 3616, 13, 545, 386, 25, 92, 1142, 129, 278, 23, 14, 241, 46, 7, 158]\n"
     ]
    }
   ],
   "source": [
    "print(train_data[100]) # how a text looks like: a list of numbers!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5a1de101-318b-4b20-851d-c1e659bb6326",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get words → index\n",
    "word_index = keras.datasets.imdb.get_word_index()\n",
    "# reverse: index → word (Python dict comprehension)\n",
    "reverse_word_index = {value:key for key,value in word_index.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afbf7f1d",
   "metadata": {
    "id": "afbf7f1d"
   },
   "source": [
    "#### A negative review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "47cee6a9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "47cee6a9",
    "outputId": "558265f1-a649-46c4-dcf4-a10b87800c62"
   },
   "outputs": [],
   "source": [
    "decoded_review = ' '.join(\n",
    "    [                                      # get() works like [] but you can set a default\n",
    "        reverse_word_index.get(i - 3, '?') # value if the key isn't found -3 because the first\n",
    "        for i in train_data[100]           # three slots in the vocab are 0: \"padding\",\n",
    "    ]                                      #                              1: \"start of sequence\",\n",
    ")                                          #                              2: \"unknown\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dc910c76-b08f-4e63-b039-a5e7e7bf306e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dc910c76-b08f-4e63-b039-a5e7e7bf306e",
    "outputId": "0752025c-e706-45d6-ca11-560502bc11af"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "? i am a great fan of david lynch and have everything that he's made on dvd except for hotel room the 2 hour twin peaks movie so when i found out about this i immediately grabbed it and and what is this it's a bunch of ? drawn black and white cartoons that are loud and foul mouthed and unfunny maybe i don't know what's good but maybe this is just a bunch of crap that was ? on the public under the name of david lynch to make a few bucks too let me make it clear that i didn't care about the foul language part but had to keep ? the sound because my neighbors might have all in all this is a highly disappointing release and may well have just been left in the ? box set as a curiosity i highly recommend you don't spend your money on this 2 out of 10\n"
     ]
    }
   ],
   "source": [
    "print(decoded_review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c7f3a2c5-db7c-4db9-8c8d-0f5f4327c17a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c7f3a2c5-db7c-4db9-8c8d-0f5f4327c17a",
    "outputId": "caf733a3-5b5a-4df3-b3a3-af86ae415af6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "print(train_labels[100]) # 0: negative"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89a92cc2-33b8-4341-98af-36c0b19ab798",
   "metadata": {
    "id": "389ce11b"
   },
   "source": [
    "#### A positive review"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a17818e3-b8ff-4964-babc-2a247d4b325a",
   "metadata": {
    "id": "389ce11b"
   },
   "source": [
    "The question marks are in place of words outside the 10000 word dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "32591733-55e9-4b66-9deb-f3dc5fdafe6f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "32591733-55e9-4b66-9deb-f3dc5fdafe6f",
    "outputId": "e6760cfe-111c-4795-ae28-a9798ad396f9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "? the biggest reason i had to see this movie was that it stars susan swift an outstanding and all too ? actress time travel movies usually don't interest me and neither do movies about witchcraft but this movie was fascinating and creepy it didn't rely on outrageous special effects and it didn't focus so heavily on the time travel that the viewer gets lost and confused this was a really creative movie kept simple and focused with great acting by all \n",
      "\n",
      "label:  1\n"
     ]
    }
   ],
   "source": [
    "# let's try another one\n",
    "decoded_review = ' '.join([reverse_word_index.get(i - 3, '?') for i in train_data[83]])\n",
    "print(decoded_review, '\\n\\nlabel: ', train_labels[83])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f735ece6-1595-467c-8d01-22ee7e7a3b06",
   "metadata": {
    "id": "22aae0d1"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3f11b1c-fe2c-4327-a6c2-1127f8ea2400",
   "metadata": {
    "id": "22aae0d1"
   },
   "source": [
    "## Preparing the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84cc7f2d-5c05-4711-87b0-610db22fc007",
   "metadata": {},
   "source": [
    "### Workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9518645a-d353-4e9e-8a10-6c3a5c75e9f5",
   "metadata": {
    "id": "9518645a-d353-4e9e-8a10-6c3a5c75e9f5"
   },
   "source": [
    "The network requires tensor input, not lists!\n",
    "\n",
    "1.  Create integer tensors;\n",
    "2.  **Pad** lists so they have equal length;\n",
    "3.  Use **multi-hot** encode."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a92589b-2e8d-45c6-b2a6-fc421aab1de6",
   "metadata": {
    "id": "afc5704d"
   },
   "source": [
    "#### Padding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82dced8a-e370-41a6-b318-36944febc351",
   "metadata": {
    "id": "afc5704d"
   },
   "source": [
    "It is very common for our systems only to accept tensors of a fixed length.\n",
    "\n",
    "Here, the length will be our vocabulary.\n",
    "\n",
    "In general, what does padding mean?\n",
    "\n",
    "- add a **filler** (often `0`) before, or after, shorter sequences;\n",
    "- **truncate** longer sequences."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a224ba4",
   "metadata": {
    "id": "0a224ba4"
   },
   "source": [
    "```python\n",
    "x = [1,3]\n",
    "y = [8,5,9,4,6,7]\n",
    "# max sequence length: 5\n",
    "padded_before  = [  # all the same length\n",
    "    [0,0,0,1,3],    # zeros before\n",
    "    [5,9,4,6,7],\n",
    "]\n",
    "padded_after  = [   # all the same length\n",
    "    [1,3,0,0,0],    # zeros after\n",
    "    [8,5,9,4,6],\n",
    "]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b5e4710-9f3b-45ee-acff-e4cbab4c72d7",
   "metadata": {
    "id": "b6192227"
   },
   "source": [
    "#### Multi-hot encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "944e8110-75c7-47da-9254-2a4f758c0ea9",
   "metadata": {
    "id": "b6192227"
   },
   "source": [
    "Same as one-hot, but we allow for **more than a single hot index**.\n",
    "\n",
    "The total length of the list is the **size of our vocabulary** (10k words)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d1cdea3-4cb6-4fe0-83b2-6532b48c8e9b",
   "metadata": {},
   "source": [
    "### Code: preparing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "82658ded",
   "metadata": {
    "id": "82658ded"
   },
   "outputs": [],
   "source": [
    "# turn our texts into multi-hot encodings\n",
    "def vectorize_sequences(sequences, dimension=10000):\n",
    "    results = np.zeros((len(sequences), dimension))     # a matrix of shape len(seq) x vocab, full of zeros\n",
    "    for i, sequence in enumerate(sequences):            # for each sequence:\n",
    "        results[i, sequence] = 1.                       # fill the appropriate indices with 1\n",
    "    return results                                      # note the NumPy magic! `sequence` is an array!\n",
    "                                                        # acting as the list of all indices where we want 1s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e59ccbdb",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e59ccbdb",
    "outputId": "ea4b9f3d-9933-4a8e-ba8a-08bb1baf6aee"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3 5]]\n",
      "[[0. 0. 0. 1. 0. 1. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "my_sequences = np.array([[3, 5]])\n",
    "print(my_sequences)\n",
    "print(vectorize_sequences(my_sequences, dimension=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6cae30e5-3423-4cb9-8103-cd183c1825ec",
   "metadata": {
    "id": "6cae30e5-3423-4cb9-8103-cd183c1825ec"
   },
   "outputs": [],
   "source": [
    "x_train = vectorize_sequences(train_data)\n",
    "x_test = vectorize_sequences(test_data)\n",
    "\n",
    "y_train = np.asarray(train_labels).astype('float32') # convert to float32\n",
    "y_test = np.asarray(test_labels).astype('float32')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51b498e3-01bc-448c-91fe-40f75bd07fbc",
   "metadata": {
    "id": "51b498e3-01bc-448c-91fe-40f75bd07fbc"
   },
   "source": [
    "This code one-hot encodes samples and converts the labels to floating point valued tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b64a0a3-6f22-40fa-893d-127f75565272",
   "metadata": {
    "id": "85085633-e5cc-459d-8092-db6dbec9fc2c"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "960a25b8-6c27-453e-a08e-22d62131b43d",
   "metadata": {
    "id": "85085633-e5cc-459d-8092-db6dbec9fc2c"
   },
   "source": [
    "## Building your model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa4a4870-5e90-47b3-a7fb-4be39467531d",
   "metadata": {
    "id": "fa4a4870-5e90-47b3-a7fb-4be39467531d"
   },
   "source": [
    "What we have so far: vector samples, scalar labels.\n",
    "\n",
    "Let's build a small stack of fully connected `relu`-activated layers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c8b131c-a775-474d-837e-63d76daf4e03",
   "metadata": {},
   "source": [
    "### Code: building the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "18a91ac2",
   "metadata": {
    "id": "18a91ac2"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1765547436.010790  435394 service.cc:152] XLA service 0x600002d13600 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1765547436.010816  435394 service.cc:160]   StreamExecutor device (0): Host, Default Version\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.Sequential()\n",
    "model.add(keras.Input((10000,)))\n",
    "model.add(keras.layers.Dense(16, activation='relu'))\n",
    "model.add(keras.layers.Dense(16, activation='relu'))\n",
    "model.add(keras.layers.Dense(1, activation='sigmoid')) # outputs a single number between 0 & 1: a single probability"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5105f072-8e6b-482f-b5cd-93c1fae57ac6",
   "metadata": {},
   "source": [
    "### Recap: dense layers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00d3372e-5114-4df3-b062-bc8d244a18f6",
   "metadata": {
    "id": "00d3372e-5114-4df3-b062-bc8d244a18f6"
   },
   "source": [
    "`Dense(16, activation='relu')` implements `output = relu(dot(w, input) + b)`.\n",
    "\n",
    "\n",
    "- This layer transforms an input tensor into a 1D tensor of shape (16,) – a 16-dimensional vector.\n",
    "\n",
    "- **Representational space** = **(hidden) units/neurons** = **spatial dimensions** = 16.\n",
    "\n",
    "- Performs a **geometric transformation** resulting in a **point in 16 dimensional space**.\n",
    "\n",
    "- Because we always process a **batch**, the dimension you'll see will be 2D: (batch_size, 16).\n",
    "\n",
    "Think: 16 units → 16-dimensional output."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a916903c",
   "metadata": {
    "id": "a916903c"
   },
   "source": [
    "##### For one sample\n",
    "\n",
    "| parameter |  shape | note |\n",
    "| --- |  :--- | :--- |\n",
    "| input| `(1,10000)`  ||\n",
    "| weights| `(10000, 16)`  ||\n",
    "| $Wx$| `(1,16)` | `(1,10000)`$\\times$`(10000,16)` → `(1,16)` |\n",
    "| bias|`(1,16)`  | added elementwise |\n",
    "| output| `(1,16)`  | activation also elementwise |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caf6e60b",
   "metadata": {
    "id": "caf6e60b"
   },
   "source": [
    "##### For a mini-batch\n",
    "\n",
    "| parameter |  shape | note |\n",
    "| --- |  :--- | :--- |\n",
    "| input| `(batch_size,10000)`  ||\n",
    "| weights| `(10000, 16)`  ||\n",
    "| $Wx$| `(batch_size,16)` | `(batch_size,10000)`$\\times$`(10000,16)` → `(batch_size,16)` |\n",
    "| bias|`(batch_size,16)`  | added elementwise|\n",
    "| output| `(batch_size,16)`  |  activation also elementwise |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c042508-943c-4e68-ad71-862684a490b3",
   "metadata": {
    "id": "9c042508-943c-4e68-ad71-862684a490b3"
   },
   "source": [
    "##### Note\n",
    "\n",
    "- Math: the number of elements in a vector is the **dimension** or **length** of the vector  \n",
    "- Programming: **dimension** of a tensor, which is the number of **axes** (or the *length* of the *shape*)!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e46cd459-dd50-440a-9658-fbb05670c30e",
   "metadata": {
    "id": "7307d282-67ed-4cbe-867b-775445fc95fb"
   },
   "source": [
    "#### How many hidden units?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5518dc21-a3fd-4dd1-bba1-2cc47ff9ca78",
   "metadata": {
    "id": "7307d282-67ed-4cbe-867b-775445fc95fb"
   },
   "source": [
    "More hidden units means more complex representations can be learned but:\n",
    "\n",
    "- the network is computationally more expensive;\n",
    "- the network might fit the training data too tightly and performance on the test set degrades.  \n",
    "  (This is called **overfitting**, we are going to talk about that a lot.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfa48309-5cc7-46b6-a89d-19752a03ca0d",
   "metadata": {
    "id": "91ed3430"
   },
   "source": [
    "### Loss & optimiser"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "928db6d9-7c54-4242-8309-a6ec86d7fbcf",
   "metadata": {
    "id": "91ed3430"
   },
   "source": [
    "This is a binary classification problem: positive or negative.\n",
    "\n",
    "Our network output could a probability, between 0 and 1, and we cut off at 0.5.\n",
    "\n",
    "The **binary cross-entropy** is the loss that will get you that result.\n",
    "\n",
    "Optimizer: `RMSprop`, for starters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1e71ace-b60f-4fcf-a0e8-b8ffc5a9fd87",
   "metadata": {
    "id": "1f00c0db"
   },
   "source": [
    "#### Binary cross-entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff3f1a64-dfbf-4a28-9adb-67b2d9ac9bf3",
   "metadata": {
    "id": "1f00c0db"
   },
   "source": [
    "We have a label that can be 0 or 1.\n",
    "\n",
    "We have a network that outputs a probability between 0 and 1.\n",
    "\n",
    "We want a loss that penalises the network if it predicts 0 instead of 1, and 1 instead of 0."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3417e961-ba30-4d86-8a72-5c939a4c7c95",
   "metadata": {
    "id": "202f6f5d"
   },
   "source": [
    "The math (for reference):\n",
    "\n",
    "\\begin{align*}\n",
    "\\bbox[5px,border:2px solid red]\n",
    "{\n",
    "J_{sample} = \\color{purple}{- y \\log y_{pred}} \\color{navy}{- (1 - y) \\log (1 - y_{pred})}\n",
    "}\n",
    "\\end{align*}\n",
    "\n",
    "- $y$: our **label**, either 0 or 1.  \n",
    "- $y_{pred}$: our **predictions**: a probability between 0 and 1!  \n",
    "- smooth & differentiable for SGD. (◕‿◕)\n",
    "\n",
    "Notice the $y$ and $(1 - y)$?\n",
    "\n",
    "This means that if $y$ is 0, the left term goes away, and vice-versa if $y$ is 1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60f74c29-89f9-4799-b7fe-a8dd6afbe660",
   "metadata": {
    "id": "60f74c29-89f9-4799-b7fe-a8dd6afbe660"
   },
   "source": [
    "\\begin{align*}\n",
    "& & J_{sample} &= \\color{blue}{- y \\log y_{pred}} \\color{red}{- (1 - y) \\log (1 - y_{pred})}\\\\\n",
    "\\text{case 1:}\\ \\color{fuchsia}{y = 0} \\Rightarrow&& J_{sample} &= \\color{red}{-\\log(1 - y_{pred})} \\\\\n",
    "\\text{minimize } J_{sample} \\Rightarrow&& &= 0\\\\\n",
    "& & & & y_{pred} \\rightarrow 0\n",
    "\\end{align*}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "563410ca-32eb-469a-ad01-3618e135d763",
   "metadata": {
    "id": "563410ca-32eb-469a-ad01-3618e135d763"
   },
   "source": [
    "\\begin{align*}\n",
    "& & J_{sample} &= \\color{red}{- y \\log y_{pred}} \\color{blue}{- (1 - y) \\log (1 - y_{pred})} \\\\\n",
    "\\text{case 2:}\\ \\color{fuchsia}{y = 1} \\Rightarrow&& J_{sample} &= \\color{red}{-\\log y_{pred}} \\\\\n",
    "\\text{minimize } J_{sample} \\Rightarrow&& &= 0\\\\\n",
    "& & & & y_{pred} \\rightarrow 1\n",
    "\\end{align*}  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "400efcfd",
   "metadata": {
    "id": "400efcfd"
   },
   "outputs": [],
   "source": [
    "def plot_binary_crossentropy(figsize=(10,8)):\n",
    "    preds = np.linspace(0.01, .99, 100)\n",
    "    matplotlib.rcParams.update({'font.size': plt_fontsize * 1.5}) # bigger font\n",
    "    f = plt.figure(figsize=figsize)                               # control figure size\n",
    "    plt.plot(preds, -np.log(preds), label=\"If truth is 1: -log(x)\")\n",
    "    plt.plot(preds, -np.log(1 - preds), label=\"If truth is 0: -log(1 - x)\")\n",
    "    plt.text(0.03, 4, \"← truth: 1\") # -log(x)\n",
    "    plt.text(0.065, 3.8, \"pred: 0\")\n",
    "    plt.text(0.065, 3.55, \"BAD!\")\n",
    "    plt.text(0.055, 0.7, \"truth: 0\")\n",
    "    plt.text(0.055, 0.5, \"pred: 0\")\n",
    "    plt.text(0.02, 0.3, \"↓ GOOD!\")\n",
    "    plt.text(0.82, 4, \"truth: 0 →\") # -log(1-x)\n",
    "    plt.text(0.82, 3.8, \"pred: 1\")\n",
    "    plt.text(0.82, 3.55, \"BAD!\")\n",
    "    plt.text(0.88, 0.7, \"truth: 1\")\n",
    "    plt.text(0.88, 0.5, \"pred: 1\")\n",
    "    plt.text(0.85, 0.3, \"↓ GOOD!\")\n",
    "    plt.title(\"Logistic regression loss\")\n",
    "    plt.xlabel(\"Predictions\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.grid()\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    matplotlib.rcParams.update({'font.size': plt_fontsize})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3802bcde",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 735
    },
    "id": "3802bcde",
    "outputId": "3a6bd3e0-9d53-4ef6-f4d0-3e894a7de49f"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'matplotlib' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mplot_binary_crossentropy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[13], line 3\u001b[0m, in \u001b[0;36mplot_binary_crossentropy\u001b[0;34m(figsize)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mplot_binary_crossentropy\u001b[39m(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m10\u001b[39m,\u001b[38;5;241m8\u001b[39m)):\n\u001b[1;32m      2\u001b[0m     preds \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mlinspace(\u001b[38;5;241m0.01\u001b[39m, \u001b[38;5;241m.99\u001b[39m, \u001b[38;5;241m100\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m     \u001b[43mmatplotlib\u001b[49m\u001b[38;5;241m.\u001b[39mrcParams\u001b[38;5;241m.\u001b[39mupdate({\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfont.size\u001b[39m\u001b[38;5;124m'\u001b[39m: plt_fontsize \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m1.5\u001b[39m}) \u001b[38;5;66;03m# bigger font\u001b[39;00m\n\u001b[1;32m      4\u001b[0m     f \u001b[38;5;241m=\u001b[39m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39mfigsize)                               \u001b[38;5;66;03m# control figure size\u001b[39;00m\n\u001b[1;32m      5\u001b[0m     plt\u001b[38;5;241m.\u001b[39mplot(preds, \u001b[38;5;241m-\u001b[39mnp\u001b[38;5;241m.\u001b[39mlog(preds), label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIf truth is 1: -log(x)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'matplotlib' is not defined"
     ]
    }
   ],
   "source": [
    "plot_binary_crossentropy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d744b0ad-865d-4a00-a94f-6bd1243ead43",
   "metadata": {},
   "source": [
    "### Code: compilation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b74b2aa8-f020-4450-8abf-3d1fbac9c010",
   "metadata": {},
   "source": [
    "```python\n",
    "# for more control, we can pass the optimizer as an object! \n",
    "# (See: https://keras.io/api/optimizers/)\n",
    "model.compile(                                                   \n",
    "    optimizer=keras.optimizers.RMSprop(learning_rate=0.001),  \n",
    "    loss=keras.losses.binary_crossentropy,                   \n",
    "    metrics=['accuracy']\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "804955cb-bb50-4f72-bf22-915491fda7e5",
   "metadata": {
    "id": "804955cb-bb50-4f72-bf22-915491fda7e5"
   },
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer='rmsprop',\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd74c25d",
   "metadata": {
    "id": "cd74c25d"
   },
   "source": [
    "### Code: Test untrained / commonsense baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffc3b80e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ffc3b80e",
    "outputId": "5764c095-225d-44fb-e088-1eba37a034f5"
   },
   "outputs": [],
   "source": [
    "results = model.evaluate(x_test, y_test, verbose=0) # test our untrained net.\n",
    "\n",
    "print(f\"loss: {results[0]}, accuracy: {results[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d634afc",
   "metadata": {
    "id": "0d634afc"
   },
   "source": [
    "Each set has 50% positive reviews, 50% negative, remember?\n",
    "\n",
    "In this case, a **commonsense baseline** is just a **random guess**.\n",
    "\n",
    "A random guess would give you 50%, and we have around 0.5 accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3311041d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3311041d",
    "outputId": "a70eed9c-ea58-4ac1-9656-0ef59e3d138f"
   },
   "outputs": [],
   "source": [
    "random_guesses = y_test > 0 # an array of booleans ↔ can be interpreted as 0s and 1s\n",
    "print(random_guesses.mean(), random_guesses)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c93f9ba-17ee-4692-a1e0-13ce22592f05",
   "metadata": {
    "id": "1e424f38-a308-4508-b153-a4e2ad37a94d"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80938ba7-d125-4b43-8917-6b1a15b44f34",
   "metadata": {
    "id": "1e424f38-a308-4508-b153-a4e2ad37a94d"
   },
   "source": [
    "## Validating your approach"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c4744c9-6289-4851-88c9-0971a4dc855e",
   "metadata": {
    "id": "3fb4a099"
   },
   "source": [
    "### The problem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45ff7fa9-c82f-42bc-824b-c0141b92ec23",
   "metadata": {
    "id": "3fb4a099"
   },
   "source": [
    "We want our model to do well on unseen data. (We use our test set for that.)\n",
    "\n",
    "To do that, we **tweak** hyperparameters.\n",
    "\n",
    "For example, experiment with different learning rates."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f63f700-e695-42fe-a757-aae46aa10448",
   "metadata": {
    "id": "3fb4a099"
   },
   "source": [
    "##### Note"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c03f9a3-bbfb-45b5-aa90-4bbb29109d8e",
   "metadata": {
    "id": "3fb4a099"
   },
   "source": [
    "Hyperparameters are all **non-trainable parameters**.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ffca98d-dcbb-433d-b688-f60ebf55c770",
   "metadata": {
    "id": "0ea748b3"
   },
   "source": [
    "#### However"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72719c61-46d2-4685-8fd9-11f827ea8d32",
   "metadata": {
    "id": "0ea748b3"
   },
   "source": [
    "If we tweak our parameters and then check the results on our test set...\n",
    "\n",
    "It's **no longer unseen data**!\n",
    "\n",
    "**Information** about/from our test set has **leaked** into our training process.\n",
    "\n",
    "*It's as if we had trained on our test set (a little bit).*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9640cf83-af8e-4c22-93dd-1184e4789ae1",
   "metadata": {
    "id": "eca14cb4"
   },
   "source": [
    "### A solution: validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deb92cea-db8b-421a-906c-9dda5e9265e2",
   "metadata": {
    "id": "eca14cb4"
   },
   "source": [
    "We are going to replicate our train/test division **within the training set**.\n",
    "\n",
    "Training → partial train + validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0b27332-c9df-4cc7-8b5c-9a3d890d6c61",
   "metadata": {},
   "source": [
    "### Code: Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dd863c3-9651-452a-ac2a-eb0e6a399190",
   "metadata": {
    "id": "5dd863c3-9651-452a-ac2a-eb0e6a399190"
   },
   "outputs": [],
   "source": [
    "partial_x_train = x_train[10000:]\n",
    "partial_y_train = y_train[10000:]\n",
    "\n",
    "x_val = x_train[:10000]\n",
    "y_val = y_train[:10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0d51f8a-4990-4f06-9f21-24229fa17dff",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b0d51f8a-4990-4f06-9f21-24229fa17dff",
    "outputId": "916d2693-1328-4a10-9d5c-9173a7a1d5d1"
   },
   "outputs": [],
   "source": [
    "history = model.fit( # note that a history object is returned by model.fit\n",
    "    partial_x_train,\n",
    "    partial_y_train,\n",
    "    epochs = 20,\n",
    "    batch_size = 512,\n",
    "    validation_data = (x_val, y_val),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00216007-783e-4a03-90a8-0641fe277fee",
   "metadata": {},
   "source": [
    "**Something's going on here: let's plot!**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a00a30a-c9f1-44e3-9d80-426fae951178",
   "metadata": {
    "id": "c4eac03c"
   },
   "source": [
    "### Code: plot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5338330a-ec56-45bb-becc-b521dc83c585",
   "metadata": {
    "id": "c4eac03c"
   },
   "source": [
    "`model.fit()` returns a `history` object, as a dictionary.\n",
    "\n",
    "This contains all the data we asked `compile` to track for us:  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea55679e-5b51-482e-a194-cd7e40ad1790",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ea55679e-5b51-482e-a194-cd7e40ad1790",
    "outputId": "cd8e6722-97c0-4682-a10a-26c71812cc8a"
   },
   "outputs": [],
   "source": [
    "history_dict = history.history\n",
    "history_dict.keys() # the data gathered during training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "789f51ef-7815-4553-8aaa-15b8c436f5ea",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "789f51ef-7815-4553-8aaa-15b8c436f5ea",
    "outputId": "9077a9ae-84d3-4895-a9c3-098d869c443e",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "history_dict['loss'] # our loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b7af3a7-4b4c-4055-9fc7-22cee282678b",
   "metadata": {
    "id": "8b7af3a7-4b4c-4055-9fc7-22cee282678b"
   },
   "outputs": [],
   "source": [
    "def plot_loss():\n",
    "\n",
    "    history_dict = history.history\n",
    "    loss = history_dict['loss']\n",
    "    val_loss = history_dict['val_loss']\n",
    "\n",
    "    epochs = range(1, len(loss) + 1)\n",
    "\n",
    "    blue_dots = 'bo'\n",
    "    solid_blue_line = 'b'\n",
    "\n",
    "    plt.plot(epochs, loss, blue_dots, label = 'Training loss')\n",
    "    plt.plot(epochs, val_loss, solid_blue_line, label = 'Validation loss')\n",
    "    plt.title('Training and validation loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    # plt.savefig('overfitting.png', format = 'png')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2111be05-64c7-477a-9be3-916b81bd54a2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 472
    },
    "id": "2111be05-64c7-477a-9be3-916b81bd54a2",
    "outputId": "fe725fad-39e8-4a2c-a50f-6f6bf1301ca0"
   },
   "outputs": [],
   "source": [
    "plot_loss() # overfitting!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41564167-dd0b-42c1-aa7c-252ba44c91d5",
   "metadata": {
    "id": "41564167-dd0b-42c1-aa7c-252ba44c91d5"
   },
   "outputs": [],
   "source": [
    "def plot_acc():\n",
    "    plt.clf()\n",
    "    acc = history_dict['accuracy']\n",
    "    val_acc = history_dict['val_accuracy']\n",
    "    epochs = range(1, len(acc) + 1)\n",
    "    plt.plot(epochs, acc, 'bo', label = 'Training acc')\n",
    "    plt.plot(epochs, val_acc, 'b', label = 'Validation acc')\n",
    "    plt.title('Training and validation acc')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31558df8-93e7-4f29-b45a-f527dbdba641",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 472
    },
    "id": "31558df8-93e7-4f29-b45a-f527dbdba641",
    "outputId": "e3d00faf-ad4f-4018-e714-3cc78d1f8667"
   },
   "outputs": [],
   "source": [
    "plot_acc() # our model is *very* good on what it has seen, less so on the validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75eee406-4028-4d56-b511-3f69b256c568",
   "metadata": {
    "id": "75eee406-4028-4d56-b511-3f69b256c568"
   },
   "source": [
    "The model has been 'overtrained' – it fits the training set too closely and begins to fail on unseen data.\n",
    "\n",
    "The learned representations are too specific.\n",
    "\n",
    "This is an example of **overfitting**!\n",
    "\n",
    "We want both curves (training and validation) to evolve close to each other, rather than a divergence!\n",
    "\n",
    "That holds even if the training curve takes a hit in performance, as ultimately what matters is **validation** (our proxy measure for generalisation – performing well on unseen data)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38cd6b9e-5956-48cf-91af-c127ca849fad",
   "metadata": {
    "id": "869c0d2f-fd8c-432d-acac-d518797bc2d8",
    "tags": []
   },
   "source": [
    "### One solution: early stopping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1641d70b-7a5b-4125-acc6-ca472dd7cc8b",
   "metadata": {
    "id": "869c0d2f-fd8c-432d-acac-d518797bc2d8",
    "tags": []
   },
   "source": [
    "One solution to this is to stop training just as overfitting kicks in."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "433431a1-5c97-421a-a14d-d14dcb5b6942",
   "metadata": {
    "id": "869c0d2f-fd8c-432d-acac-d518797bc2d8",
    "tags": []
   },
   "source": [
    "#### Workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da293eec-3fc5-4a57-a536-b4792e2012ef",
   "metadata": {
    "id": "869c0d2f-fd8c-432d-acac-d518797bc2d8",
    "tags": []
   },
   "source": [
    "- We trained on the **partial training set**;\n",
    "- We **found the best cut-off epoch** (where overfitting starts);\n",
    "- We retrain a fresh net on **the full training set** until that number of epochs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a229c0bc-db7a-435b-83f3-144eb789107f",
   "metadata": {
    "id": "869c0d2f-fd8c-432d-acac-d518797bc2d8",
    "tags": []
   },
   "source": [
    "##### Note"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fb49f6a-5c7a-432b-8edb-337fabef430c",
   "metadata": {
    "id": "869c0d2f-fd8c-432d-acac-d518797bc2d8",
    "tags": []
   },
   "source": [
    "We train on the complete training set to give our network as much data as possible for it to perform well."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de61697d-8103-41b6-a54e-f33d27b8e642",
   "metadata": {},
   "source": [
    "### Code: automatic best epoch extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb053c73",
   "metadata": {
    "id": "fb053c73"
   },
   "source": [
    "When did we reach our top `val_accuracy`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d39b852",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4d39b852",
    "outputId": "09fcc793-8355-46c5-eeaa-19b664c50f50"
   },
   "outputs": [],
   "source": [
    "early_stopping_epoch = np.argmax(history.history[\"val_accuracy\"])\n",
    "print(f\"Reached best validation accuracy {history.history['val_accuracy'][early_stopping_epoch]} at epoch {early_stopping_epoch}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daac5466-a655-4efe-a850-c383eefcce70",
   "metadata": {
    "id": "323457f8"
   },
   "source": [
    "### Code: memory clean-up"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cc540b1-7c57-4a88-9038-cb5ab94e806c",
   "metadata": {
    "id": "323457f8"
   },
   "source": [
    "Unfortunately, memory management isn't super straightforward, and creating many models in Jupyter will make you run out of memory quite fast!\n",
    "\n",
    "I'm including code to clear the memory in Jupyter, but even this has some limitations. One thing to consider is to fashion your code so that you can easily restart the kernel and rerun parts of your notebook (while leaving the finished experiments untouched)!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd6b75a4-5f89-4795-8cb4-85982e4a3b7d",
   "metadata": {
    "id": "fd6b75a4-5f89-4795-8cb4-85982e4a3b7d"
   },
   "outputs": [],
   "source": [
    "# Memory clean-up for Jupyter\n",
    "# Slightly modified from fast.ai utils: https://github.com/fastai/course22p2/blob/df9323235bc395b5c2f58a3d08b83761947b9b93/miniai/init.py#L31\n",
    "\n",
    "import gc\n",
    "import sys\n",
    "import time\n",
    "import traceback\n",
    "\n",
    "def clean_ipython_hist():\n",
    "    # Code in this function mainly copied from IPython source\n",
    "    if not 'get_ipython' in globals(): return\n",
    "    ip = get_ipython()\n",
    "    user_ns = ip.user_ns\n",
    "    ip.displayhook.flush()\n",
    "    pc = ip.displayhook.prompt_count + 1\n",
    "    for n in range(1, pc): user_ns.pop('_i'+repr(n),None)\n",
    "    user_ns.update(dict(_i='',_ii='',_iii=''))\n",
    "    hm = ip.history_manager\n",
    "    hm.input_hist_parsed[:] = [''] * pc\n",
    "    hm.input_hist_raw[:] = [''] * pc\n",
    "    hm._i = hm._ii = hm._iii = hm._i00 =  ''\n",
    "\n",
    "def clean_tb():\n",
    "    # h/t Piotr Czapla\n",
    "    if hasattr(sys, 'last_traceback'):\n",
    "        traceback.clear_frames(sys.last_traceback)\n",
    "        delattr(sys, 'last_traceback')\n",
    "    if hasattr(sys, 'last_type'): delattr(sys, 'last_type')\n",
    "    if hasattr(sys, 'last_value'): delattr(sys, 'last_value')\n",
    "\n",
    "def clean_mem():\n",
    "    clean_tb()\n",
    "    clean_ipython_hist()\n",
    "    gc.collect()\n",
    "    keras.utils.clear_session(free_memory=True)\n",
    "    time.sleep(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58400d2f-3da9-40d0-a23f-cec34d5d4578",
   "metadata": {},
   "source": [
    "### Code: Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "860f6ef5-f841-4a7e-9edc-50f7ae26271a",
   "metadata": {
    "id": "860f6ef5-f841-4a7e-9edc-50f7ae26271a",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "clean_mem() # your friend whenever you train many models in a session, this should help with memory use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62d07bc7-4c9a-4310-a04e-28cdf380760b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "62d07bc7-4c9a-4310-a04e-28cdf380760b",
    "outputId": "fb006b92-fde0-4728-9ba9-6de75e949b5e",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = keras.models.Sequential()\n",
    "model.add(keras.Input((10000,)))\n",
    "model.add(keras.layers.Dense(16, activation='relu'))\n",
    "model.add(keras.layers.Dense(16 ,activation='relu'))\n",
    "model.add(keras.layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(\n",
    "    optimizer='rmsprop',\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "model.fit(\n",
    "    x_train,                     # full training set\n",
    "    y_train,\n",
    "    epochs=early_stopping_epoch, # the epoch where overfitting starts\n",
    "    batch_size=512\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84fb73c4-389f-4498-9a2a-450126a2238c",
   "metadata": {},
   "source": [
    "### Code: evaluate on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33f049b1-1cb5-4a2b-b321-8e37d42e2d41",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "33f049b1-1cb5-4a2b-b321-8e37d42e2d41",
    "outputId": "97a446d4-30db-4950-b2f6-06bcc5aad95e"
   },
   "outputs": [],
   "source": [
    "results = model.evaluate(x_test, y_test, verbose=0)\n",
    "\n",
    "print(f\"loss: {results[0]}, accuracy: {results[1]}\") # accuracy better than before!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da108689-1d5d-4233-ac1b-ac77f9d91d6f",
   "metadata": {
    "id": "6e9d358c-5b6b-44b7-9111-f34fc9acd481"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a765afd6-7658-45cd-9601-d164cac209a2",
   "metadata": {
    "id": "6e9d358c-5b6b-44b7-9111-f34fc9acd481"
   },
   "source": [
    "## Using a trained model to generate predictions on new data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd108f6c-8927-46e0-8f89-bd4815b90b13",
   "metadata": {
    "id": "6e9d358c-5b6b-44b7-9111-f34fc9acd481"
   },
   "source": [
    "Our IMDB network has been trained, we can now use it.\n",
    "\n",
    "Use `predict` to generate predictions for data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5327574a-e827-4b58-b7ab-0c6912ffdbf5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5327574a-e827-4b58-b7ab-0c6912ffdbf5",
    "outputId": "f7c58442-55df-4c3b-9033-548e98bce013"
   },
   "outputs": [],
   "source": [
    "model.predict(x_test[:10], verbose=0) # this yields probabilities: negative (0) or positive (1) ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57ecefc3",
   "metadata": {
    "id": "57ecefc3"
   },
   "outputs": [],
   "source": [
    "def print_predictions(preds, init=0):\n",
    "    labels = [\"negative\", \"positive\"]\n",
    "    for i, pred in enumerate(preds.ravel()): # ravel() makes the array flat (1D)\n",
    "        print(f\"Review n° {init+i} is {labels[int(pred > .5)]} | score: {pred:.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6890664",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a6890664",
    "outputId": "8143b153-662b-4e0e-fd35-173bc2ab5020"
   },
   "outputs": [],
   "source": [
    "print_predictions(model.predict(x_test[:10], verbose=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae5d7f21-331d-4247-89c5-a9b05cdb81a8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ae5d7f21-331d-4247-89c5-a9b05cdb81a8",
    "outputId": "d3de3aa7-0bf6-48fa-b260-07249b9fa02e"
   },
   "outputs": [],
   "source": [
    "test_labels[:10] # the first ten labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9da04436-4865-4017-a56e-8c2f462c588d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9da04436-4865-4017-a56e-8c2f462c588d",
    "outputId": "65f2b2b8-5b78-4f58-a0ed-9157c4641f99"
   },
   "outputs": [],
   "source": [
    "print('review', '\\t', 'prediction → rounded', '\\t', 'label', '\\t', 'correct?')\n",
    "print()\n",
    "for i in range(20):\n",
    "    y_pred = model.predict(x_test[i:i+1], verbose=0)[0][0]\n",
    "    print(i, '\\t', y_pred,'\\t', round(y_pred), '\\t', test_labels[i], '\\t', int(y_pred > .5) == test_labels[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c6b41ee-3fb4-4d82-93ee-fe14ba28eb56",
   "metadata": {
    "id": "7c6b41ee-3fb4-4d82-93ee-fe14ba28eb56"
   },
   "outputs": [],
   "source": [
    "# How to use generators in Python: https://realpython.com/introduction-to-python-generators/\n",
    "def review_finder(prediction, label):\n",
    "    for i in range(len(x_test)):                                       # looping through our test set\n",
    "        y_pred = round(model.predict(x_test[i:i+1], verbose=0)[0, 0])  # get prediction\n",
    "        if y_pred == prediction and test_labels[i] == label:           # if the prediction and the label\n",
    "            yield i                                                    # are what we are after, yield the index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "113e3ee9-ea03-4f00-b3c7-da809437026e",
   "metadata": {
    "id": "113e3ee9-ea03-4f00-b3c7-da809437026e"
   },
   "outputs": [],
   "source": [
    "def print_review(n):\n",
    "    word_index = keras.datasets.imdb.get_word_index()                                                  # decoding work\n",
    "    reverse_word_index = {value:key for key,value in word_index.items()}\n",
    "    decoded_review = ' '.join([reverse_word_index.get(i - 3, '?') for i in test_data[n]])\n",
    "\n",
    "    y_pred = model.predict(x_test[n:n+1], verbose=0)[0,0]                                                 # predict\n",
    "    print(f\"review: {n} | predicted: {y_pred:.6f} | rounded: {round(y_pred)} | label: {test_labels[n]}\")  # print\n",
    "    print()\n",
    "    print(decoded_review, '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5211e739",
   "metadata": {
    "id": "5211e739"
   },
   "source": [
    "The first successful prediction of a negative review."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "293b1699",
   "metadata": {
    "id": "293b1699"
   },
   "outputs": [],
   "source": [
    "neg_neg = review_finder(prediction=0, label=0) # create a generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9a94ec9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f9a94ec9",
    "outputId": "4ba41cd9-af12-4407-9554-172274ed4563"
   },
   "outputs": [],
   "source": [
    "print_review(next(neg_neg)) # run again for the next one"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a4da745",
   "metadata": {
    "id": "0a4da745"
   },
   "source": [
    "The first successful positive prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52969fa7",
   "metadata": {
    "id": "52969fa7"
   },
   "outputs": [],
   "source": [
    "pos_pos = review_finder(prediction=1, label=1) # another generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "498afd8d-8c23-4437-8cff-95ff7d175235",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "498afd8d-8c23-4437-8cff-95ff7d175235",
    "outputId": "258d2512-cf8c-4ddc-b8a1-0fe97a84457b"
   },
   "outputs": [],
   "source": [
    "print_review(next(pos_pos))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49afc797",
   "metadata": {
    "id": "49afc797"
   },
   "source": [
    "The network predicted negative but the actual label is positive. What do you think?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48061c59",
   "metadata": {
    "id": "48061c59"
   },
   "outputs": [],
   "source": [
    "neg_pos = review_finder(prediction=0, label=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd99c863",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dd99c863",
    "outputId": "4cf79610-bb51-4d87-f9d0-b3acc95a6582",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print_review(next(neg_pos))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1939145",
   "metadata": {
    "id": "a1939145"
   },
   "source": [
    "And the reviews wronglyc classed as positive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df107829",
   "metadata": {
    "id": "df107829"
   },
   "outputs": [],
   "source": [
    "pos_neg = review_finder(prediction=1, label=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b88b14a7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b88b14a7",
    "outputId": "2fc183f3-cfdf-4912-9197-b830009adaa2",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print_review(next(pos_neg))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d8349f6-c286-45d3-a6f9-175babc21ac3",
   "metadata": {
    "id": "5c197551"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82780ca3-ab1c-4297-b6e5-b1f7d9652b23",
   "metadata": {
    "id": "5c197551"
   },
   "source": [
    "## Hyperparameter tuning: three ideas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e587bf28-5e12-4195-8359-1bcd3248995e",
   "metadata": {
    "id": "16acb5e9"
   },
   "source": [
    "### 1.  Grid search"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d640e234-ad2e-4962-9f61-dae5f05644d5",
   "metadata": {
    "id": "16acb5e9"
   },
   "source": [
    "Systematically try the range of your parameter.\n",
    "\n",
    "Example: learning rate, best model in bold, we then search around the best parameter...\n",
    "\n",
    "| **first pass** | **second pass** | **third pass** |\n",
    "| ---            | ---             | ---            |\n",
    "| .001           | .0037           | .00377         |\n",
    "| .002           | **.0038**       | .00378         |\n",
    "| .003           | .0039           | .00379         |\n",
    "| **.004**       | .0040           | .00380         |\n",
    "| .005           | .0041           | .00381         |\n",
    "| .006           | .0042           | .00382         |\n",
    "| .007           | .0043           | **.00383**     |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9ea1983-6850-4ce2-beb6-7c49bfc2c4f7",
   "metadata": {
    "id": "80879551"
   },
   "source": [
    "### 2.  Random search"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4b604e6-1159-405f-b88b-0f8f8a7fdbd7",
   "metadata": {
    "id": "80879551"
   },
   "source": [
    "Given that you want to optimize **many** hyperparmeters at the same time, it [has been argued](https://cs231n.github.io/neural-networks-3/#hyper) that grid search is not only infeasible with many params, but also less successful than random search!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c36d589-72f8-453c-a85c-a0179e4bc8bc",
   "metadata": {
    "id": "80879551"
   },
   "source": [
    "#### Workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f12bfac-71c6-4061-8e3b-00f870b305da",
   "metadata": {
    "id": "80879551"
   },
   "source": [
    "- Determine a range for each hyperparameter;\n",
    "- Use a random generator to create numbers within this range;\n",
    "- Try a number of different models, pick the best one.\n",
    "\n",
    "Document the methodology and list the hyperparameters that were tried!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d16ef52-fc46-4b10-ae9e-d3200bf9c7d4",
   "metadata": {
    "id": "f4f16004"
   },
   "source": [
    "#### Example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dadc2eeb-d6be-4f91-bb22-1ab468447004",
   "metadata": {
    "id": "f4f16004"
   },
   "source": [
    "You want to try different momentums, between let's say between .9, and .999.\n",
    "\n",
    "```python\n",
    "momentum = 0.9 + np.random.uniform()/10 # a random number between 0. and 0.01\n",
    "```\n",
    "\n",
    "You would do the same for a few other hyperparameters.\n",
    "\n",
    "Make sure to document the process of randomisation and the parameters that have been tried!\n",
    "\n",
    "Also: you may want to start with this then try and go back to grid search and try further."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6026089-c659-4e84-a06b-0d3ce7fd7d5e",
   "metadata": {
    "id": "356d2f75"
   },
   "source": [
    "### 3.  Babysitting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bf5d344-cebe-48c1-9040-ac036385b0b6",
   "metadata": {
    "id": "356d2f75"
   },
   "source": [
    "This could seem clunky, but is what happens with [LARGE models](https://github.com/facebookresearch/metaseq/blob/main/projects/OPT/chronicles/) (← check the logbooks (╯✧▽✧)╯)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d6a1cc4-580b-4e0c-81b8-037f3d7ccc52",
   "metadata": {
    "id": "356d2f75"
   },
   "source": [
    "#### Workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0f2e33e-cfb0-4b95-ae07-be7e5ac0b1fd",
   "metadata": {
    "id": "356d2f75"
   },
   "source": [
    "1. Start training for some epochs, look at how your network is doing;\n",
    "2. Save your net, and **document** the parameters, epoch, etc.\n",
    "3. Think about what hyperparameters to change next, if any;\n",
    "4. Keep training;\n",
    "5. If the result is good, **document** & go back to 3 (save); if not, **document** & go back to 2 (retry)!\n",
    "\n",
    "\n",
    "Make sure to **document** every stage of the process of tuning!  \n",
    "\n",
    "Ideally, **someone else should be able to reproduce your results**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08c81cb3-4948-457f-8ed4-158febe1c291",
   "metadata": {
    "id": "156fe83e"
   },
   "source": [
    "### Note: reproducible results in TF?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4eec02a-6f56-435c-9b35-a6337b72fc49",
   "metadata": {
    "id": "156fe83e"
   },
   "source": [
    "Pure TF:\n",
    "\n",
    "```python\n",
    "import tensorflow as tf\n",
    "tf.random.set_seed(42) # can be any number\n",
    "```\n",
    "Keras ([source](https://keras.io/examples/keras_recipes/reproducibility_recipes/)):\n",
    "```python\n",
    "# Set the seed using keras.utils.set_random_seed. This will set:\n",
    "# 1) `numpy` seed\n",
    "# 2) backend random seed\n",
    "# 3) `python` random seed\n",
    "keras.utils.set_random_seed(812)\n",
    "\n",
    "# If using TensorFlow, this will make GPU ops as deterministic as possible,\n",
    "# but it will affect the overall performance, so be mindful of that.\n",
    "tf.config.experimental.enable_op_determinism()\n",
    "```\n",
    "\n",
    "In NumPy & the `random` Python package:\n",
    "```python\n",
    "import random\n",
    "random.seed(42)\n",
    "\n",
    "import numpy as np\n",
    "np.random.seed(42)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2db3e7ea-6ad0-4032-a2af-f06d4bdc098c",
   "metadata": {
    "id": "b813a4b7-d08b-4fd5-9aaf-15f11db01f3a"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09631ff6-3a3c-4f4f-ad64-b3b28afcd600",
   "metadata": {
    "id": "b813a4b7-d08b-4fd5-9aaf-15f11db01f3a"
   },
   "source": [
    "## Further experiments & Wrapping up"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6787082c-a963-4f6b-a7d7-fd9ff712efde",
   "metadata": {
    "id": "7aab70d5"
   },
   "source": [
    "### Workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4f172e5-80b0-44b0-b3a6-9627e2e018cf",
   "metadata": {
    "id": "7aab70d5"
   },
   "source": [
    "1. Prepare the data & split into Train/Validation/Test\n",
    "2. Define your model\n",
    "3. Evaluate your untrained model / a **commonsense baseline**\n",
    "4. Train using **Train/Validation**\n",
    "5. Tweak **hyperparameters** → pick best validation results\n",
    "6. Retrain on **whole train dataset**\n",
    "7. Evaluate on **Test**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a58aab4-6814-49a5-8e22-11f794bc04a6",
   "metadata": {
    "id": "53ff42ba"
   },
   "source": [
    "### Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ad8bfc7-b5ee-43c4-b409-4f0b6b2bed5b",
   "metadata": {
    "id": "53ff42ba"
   },
   "source": [
    "#### Inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b123f58-de43-4a33-ab18-74f2306d7271",
   "metadata": {
    "id": "53ff42ba"
   },
   "source": [
    "- Sequences of words often encoded as *binary vectors*;\n",
    "- Processing inputs as *multi-hot* (similar to *one-hot*);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e45955af-2c00-4c9f-b78b-36da17b1515c",
   "metadata": {
    "id": "53ff42ba"
   },
   "source": [
    "#### Labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef322977-7715-4565-a9b3-f1e7f4e15e33",
   "metadata": {
    "id": "53ff42ba"
   },
   "source": [
    "- Our labels are just integers (0 or 1);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3271a549-0961-4cf5-8c33-8077e630f365",
   "metadata": {
    "id": "53ff42ba"
   },
   "source": [
    "#### Key ideas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17d83f09-4e6f-49bd-a6b1-e80cce8b99c5",
   "metadata": {
    "id": "53ff42ba"
   },
   "source": [
    "- Train/Validation/Test splits;\n",
    "- Overfitting;\n",
    "- Commonsense baselines;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c94ca84-b30b-45a6-b6ca-138f46fbd02d",
   "metadata": {
    "id": "86877d7a"
   },
   "source": [
    "### Binary classification\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb95e28a-3314-47b9-a3e7-5c33e8d8bedf",
   "metadata": {
    "id": "86877d7a"
   },
   "source": [
    "- Used for 0/1, true/false problems (two classes: **binary**);\n",
    "- The final layer is a single dense **sigmoid** unit;\n",
    "- The loss function is `binary_crossentropy`;\n",
    "- The model outputs a **one probability**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fcb0fdb-6632-4cb3-8b5a-3aeb49b28e39",
   "metadata": {
    "id": "95e62441"
   },
   "source": [
    "### Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49d517b9-5622-4f6a-bd2b-573ba8769070",
   "metadata": {
    "id": "95e62441"
   },
   "source": [
    "- More or fewer hidden layers, with less/more units;\n",
    "- Try different learning rates and batch sizes;\n",
    "- Replace `relu` with an early neural network favourite, `tanh`;\n",
    "- Try the [`Adam` optimizer](https://www.tensorflow.org/api_docs/python/tf/keras/optimizers#classes_2): `optimizers.Adam(learning_rate=0.001)`, with various learning rates.\n",
    "- Try and think about how you would go about automating hyperparameter search (= making your life easier, so that the search is done by a system rather than manually)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "celltoolbar": "Slideshow",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
