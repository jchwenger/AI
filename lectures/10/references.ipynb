{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2ab3b772-597b-4387-9cd8-72eff87cfe84",
   "metadata": {},
   "source": [
    "# References | Review, Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c35778a5-0c5b-4bbd-8bf4-357af16744b7",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "### References"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0b7ffa3-6c09-4ef5-866e-3e134b90e79b",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "If you are interested in Chollet's theory of intelligence, and the series of tests he developed, here's a fairly comprehensive series of video explaining Chollet's paper [\"On the Measure of Intelligence\"](https://arxiv.org/abs/1911.01547)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8d27d45-0c4b-41a2-af5e-b477ed0c9893",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "[Yannic Kilcher, On the Measure of Intelligence by François Chollet - Part 1: Foundations (Paper Explained)](https://www.youtube.com/watch?v=3_qGrmD6iQY)  \n",
    "[Yannic Kilcher, On the Measure of Intelligence by François Chollet - Part 2: Human Priors (Paper Explained)](https://www.youtube.com/watch?v=THcuTJbeD34)  \n",
    "[Yannic Kilcher, On the Measure of Intelligence by François Chollet - Part 3: The Math (Paper Explained)](https://www.youtube.com/watch?v=cuyM63ugsxI)  \n",
    "[Yannic Kilcher, On the Measure of Intelligence by François Chollet - Part 4: The ARC Challenge (Paper Explained)](https://www.youtube.com/watch?v=O9kFX33nUcU)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e3da723-0e60-4c27-b1cb-ec32fa595a10",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "### Foudations / Going Deeper"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67c5a11e-62c1-44f6-9c52-d263e1ade056",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "[Goodfellow, Bengio and Courville, *Deep Learning*](https://www.deeplearningbook.org/)  \n",
    "[Christopher M. Bishop, *Pattern Recognition and Machine Learning*](https://www.microsoft.com/en-us/research/uploads/prod/2006/01/Bishop-Pattern-Recognition-and-Machine-Learning-2006.pdf)  \n",
    "[MacKay, *Information Theory, Inference, and Learning Algorithms*](https://www.inference.org.uk/mackay/itila/) (ignore the horrendous website)  \n",
    "MacKay has lectures here as well on [YouTube](https://www.youtube.com/playlist?list=PLruBu5BI5n4aFpG32iMbdWoRVAA-Vcso6).  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3b9914e-5322-4b60-b702-83af4943b2c0",
   "metadata": {
    "colab_type": "text",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Local generalization vs. extreme generalization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f315d5d2-aa6d-4d9f-af72-306aeb9ca457",
   "metadata": {
    "colab_type": "text",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Even beyond, through experience, our access to broad training sets, here is another findamental dfference berween us and them (DL models).\n",
    "\n",
    "We maintain *abstract* models of our social and natural environment and we use these models to anticpate and predict.\n",
    "\n",
    "Thanks to that we are able to form representations of things that are novel to our experience, like dogs cooking or winnng the lottery.\n",
    "\n",
    "We manage this feat through abstraction and reasoning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd826156-e92e-4b8d-af51-9311905a18f5",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "#### Note"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f4273af-658a-4c74-9fec-4385b9d84c3c",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Some of these strategies (e.g. building a model of the world and acting accordingly) are studied in **Reinforcement Learning**, that unfortunately we haven't looked at this term."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4c40dbb-a63d-4b5f-bc0e-1e120e5d65c3",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Extreme generalisation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91bab63a-3400-44b9-ac78-206900be21c9",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The ability to adapt to novel experiences despite a paucity of data is what Chollet calls *extreme generalisation*.\n",
    "\n",
    "Deep nets generalise only locally. They only adapt to new situations that closely match the training set. \n",
    "\n",
    "<!-- <img src=\"images/chollet/figure19.6.png\"> -->\n",
    "<img src=\"https://raw.githubusercontent.com/jchwenger/AI/main/lectures/09/images/chollet/figure19.6.png\">\n",
    "\n",
    "[DLWP](https://deeplearningwithpython.io/chapters/chapter19_future_of_ai/#local-generalization-vs-extreme-generalization), Figure 19.6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38f33217-b9f2-4995-8a7e-93697c792dce",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "#### Example: a trip to the moon"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06c26e4d-d5ec-4d13-8e55-bc19baadb78d",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Imagine training a model to launch a moon-bound rocket. The training set would have to include millions of launch trials before the model could accuratley predict the voyage.\n",
    "\n",
    "But humans, using reasoning and abstraction, develop rocket science, and we manage the task with only a few trials."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "415b6352-fa67-42d2-9e66-9a4f0d391fae",
   "metadata": {
    "colab_type": "text",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc0c1cd2-d525-4b30-b4c9-9ab0ea4d7da4",
   "metadata": {
    "colab_type": "text",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Implementing intelligence: The missing ingredients"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "346cd165-0edc-4da7-9fd2-b64990d8385a",
   "metadata": {
    "colab_type": "text",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### The two poles of abstraction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "341b960e-7848-403b-ace8-8c864c801b59",
   "metadata": {
    "colab_type": "text",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Value-centric analogy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c141dfa1-cd9d-45e9-994b-786f135cf39b",
   "metadata": {
    "colab_type": "text",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<!-- <img src=\"images/chollet/figure19.12.png\"> -->\n",
    "<img src=\"https://raw.githubusercontent.com/jchwenger/AI/main/lectures/09/images/chollet/figure19.12.png\">\n",
    "\n",
    "[DLWP](https://deeplearningwithpython.io/chapters/chapter19_future_of_ai/#value-centric-analogy), Figure 19.12"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a96223c9-2bbb-4114-aef6-7eb2ae891e37",
   "metadata": {
    "colab_type": "text",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Program-centric analogy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77d9c553-a40c-4e58-a8bd-555dea50cefb",
   "metadata": {
    "colab_type": "text",
    "jp-MarkdownHeadingCollapsed": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<!-- <img src=\"images/chollet/figure19.13.png\"> -->\n",
    "<img src=\"https://raw.githubusercontent.com/jchwenger/AI/main/lectures/09/images/chollet/figure19.13.png\">\n",
    "\n",
    "[DLWP](https://deeplearningwithpython.io/chapters/chapter19_future_of_ai/#program-centric-analogy), Figure 19.13"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88bc6b8a-b2cf-480f-b5b7-bf93cacff3dc",
   "metadata": {
    "colab_type": "text",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Cognition as a combination of both kinds of abstraction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32832ff2-b64b-4bd6-9ae6-a992010324a9",
   "metadata": {
    "colab_type": "text",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "| Value-centric abstraction | Program-centric abstraction |\n",
    "| --- | --- |\n",
    "| Relates things by distance | Relates things by exact structural match |\n",
    "| Continuous, grounded in geometry. | Discrete, grounded in topology |\n",
    "| Produces abstractions by “averaging” instances into “prototypes” | Produces abstractions by isolating isomorphic substructures across instances |\n",
    "| Underlies perception and intuition | Underlies reasoning and planning |\n",
    "| Immediate, fuzzy, approximative | Slow, exact, rigorous |\n",
    "| Requires a lot of experience to produce reliable results | Experience efficient: can operate on as few as two instances |\n",
    "\n",
    "\n",
    "[DLWP](https://deeplearningwithpython.io/chapters/chapter19_future_of_ai/#cognition-as-a-combination-of-both-kinds-of-abstraction), Table 19.1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ad0823b-249e-4218-88f0-12fae914b34f",
   "metadata": {
    "colab_type": "text",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### The missing half of the picture"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10cb757f-bf96-483f-93d6-942baa7a0d71",
   "metadata": {
    "colab_type": "text",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Deep Learning focusses almost exclusively on the first kind, \"value-centric analogies\".\n",
    "\n",
    "It might be more fruitful to view these two aspects as belonging to a **spectrum**, with humans using different strategies at different times."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b480906d-c75a-4798-98af-c51cdf369add",
   "metadata": {
    "colab_type": "text",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Models as programs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f29a2680-45ab-4116-9a7b-eab047057222",
   "metadata": {
    "colab_type": "text",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Current AI reasoning relies on hardcoding e.g. search algorithms, graph manipulation and formal logic.\n",
    "\n",
    "- **AlphaGo**, for example, the intelligence is hardcoded as a [Monte-Carlo Tree Search](https://en.wikipedia.org/wiki/Monte_Carlo_tree_search). Learning from data only occurs in specialised submodules.\n",
    "- **RNNs** are less restricted than feedforward nets becuase they apply simple geometric transformations within a feedback loop. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8e31c31-be43-436a-8dd1-7bc165ae6063",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Program synthesis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a2aa722-47ad-4c72-b234-644f95a06924",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "If the system had access to **programming primitives** such as `if`, `while`, variables, disk storage, sorting operations, data structures (lists, hash tables etc.), the hypothesis space would far exeed that of current models.\n",
    "\n",
    "**Program synthesis** searches to for simple programs automatically, and terminates when input-output pairs have been matched.\n",
    "\n",
    "But instead of modifying a hardcoded model, program synthesis generates *source code*.\n",
    "\n",
    "One could imagine a augmenting Deep Learning models with program synthesis capabilities."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0589cdc4-35bd-46be-8f46-16bd60674aab",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Beyond backpropagation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "791df5f1-4427-4cae-9a44-7089a4d58038",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Deep Learning/program synthesis hybrids will likely no longer be differentiable. So, we cannot use backpropagation\n",
    "\n",
    "But there are alternatives, such as optimisers that make little assumption about the loss function (or, at least, do not assume continuity and smoothness):\n",
    "- [genetic algorithms](https://en.wikipedia.org/wiki/Evolutionary_computation);\n",
    "- [simulated annealing](https://en.wikipedia.org/wiki/Simulated_annealing);\n",
    "- [swarm intelligence](https://en.wikipedia.org/wiki/Swarm_intelligence);\n",
    "- etc..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14bc9274-3065-475c-94f3-3b16b41ca727",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Automated ML"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0f58b90-6ca9-4751-b623-ed7d7e4ecca3",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "There is research on how **architectures themselves** can be learnt rather than handcrafted, for instance [**Neural Architecture Search** (NAS)](https://en.wikipedia.org/wiki/Neural_architecture_search) and [**Meta-Learning**](https://en.wikipedia.org/wiki/Meta-learning_(computer_science)).\n",
    "\n",
    "Hyperparameter tuning is a simple search procedure. Quite a few tuning systems already exist. Even architecture search algorithms are feasible.\n",
    "\n",
    "But learning architectures in conjunction with model weights would be more desirable. This would be more efficient because at the moment each architecture has to be trained from scratch."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63339548-256a-452e-a732-34ca09a55fb3",
   "metadata": {
    "colab_type": "text",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Lifelong learning and modular subroutine reuse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ae849ce-00bb-48ae-b95a-8fa0213050a1",
   "metadata": {
    "colab_type": "text",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "There is a lot of wasted effort in Deep Learning: every dataset/model/task requires training from scratch.\n",
    "\n",
    "But future hybrid Deep Learning/synthetic progams would require higher modular reuse.\n",
    "\n",
    "This is because many datasets are insufficiently informative – it will be necessary to use information from previously encountered datasets. \n",
    "\n",
    "(We don't relearn the language every time we read a new book...)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b29472e4-4843-44d7-b55a-7137edc98cef",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Example: translation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac6c5f81-4e06-4ff9-b97c-9655baf9571e",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The same DL model trained to translate English/German and French/Italian is better at each indivdual translation.\n",
    "\n",
    "The more you add languages, the better it becomes, due to information overlap.\n",
    "\n",
    "The same goes for vision, training an image segmetation model in conjunction with a an image classification model yields a model that is better at both tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5f36603-ff52-4094-9c9a-c21672b3f1e3",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Foundation models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cafa5b8-7c5c-4c6d-b8ba-a38d17ea1f09",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "We already use **pretained models** – i.e. a fixed model with weights trained an a large database – in computer vision and NLP, and pretraining procedures are expanding fast.\n",
    "\n",
    "The rise of very large models used as a basis for multiple tasks leads to the concept of [**Foundation models**](https://en.wikipedia.org/wiki/Foundation_models) (a large model acquiring general knowledge that can then be finetuned).\n",
    "\n",
    "The rise of Transformers is really that story (GPT-3 being perhaps the most famous foundational model now)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
