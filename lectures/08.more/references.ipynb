{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "794f709e-8b82-4d35-b67c-e43c90becb11",
   "metadata": {},
   "source": [
    "# References | More Generative Deep Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f9c72a6-bb07-4f21-896d-bcac914d2926",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "448e8a76-0b5d-4879-9887-d8191be06600",
   "metadata": {},
   "source": [
    "## Deep Dream"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8638e088-ec7d-4e5a-b7d9-b1ea697e1366",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 501
    },
    "id": "WCezMCEAhnq7",
    "outputId": "a9d28000-07bc-4ceb-d4da-340322e77da9",
    "scrolled": true
   },
   "source": [
    "An online tool for DeepDream: [deepdreamgenerator.com](https://deepdreamgenerator.com/).\n",
    "\n",
    "[Deep Dream (Google) - Computerphile](https://www.youtube.com/watch?v=BsSmBPmPeYQ)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f7be4ee-7a64-4e64-a675-8c69506949b5",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2e817c3-fe88-41bc-935e-cb9f43f32144",
   "metadata": {},
   "source": [
    "## Style Transfer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c9c1502-e1f2-4096-bdd6-3950bb142e36",
   "metadata": {
    "id": "wQac1gc4j6R2"
   },
   "source": [
    "### Tutorials"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15a29ebd-39a9-4a13-b5b5-90ee997ae68a",
   "metadata": {
    "id": "wQac1gc4j6R2"
   },
   "source": [
    "Have a look at the [official TensorFlow tutorial](https://www.tensorflow.org/tutorials/generative/style_transfer), it contains useful additional information!\n",
    "\n",
    "There are various differences in the implementation that make the two not a direct comparison (for instance looking at the numbers used for the various weights).\n",
    "\n",
    "However, understanding those differences and being able to integrate the two approaches into one is a *very* good exercise!\n",
    "\n",
    "Also, have a look at Andrew Ng's videos below!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24913a42-63af-4286-b7e4-117bf5cb9c31",
   "metadata": {
    "id": "wQac1gc4j6R2"
   },
   "source": [
    "### References"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b08827ed-301d-442a-8839-3dbbb8ef1d00",
   "metadata": {
    "id": "wQac1gc4j6R2"
   },
   "source": [
    "[Gatis et al., \"A Neural Algorithm of Artistic Style\"](https://arxiv.org/abs/1508.06576)\n",
    "\n",
    "Andrew Ng's videos on Neural Style Transfer (as part of [this playlist](https://www.youtube.com/watch?v=R39tWYYKNcI&list=PLkDaE6sCZn6Gl29AoE31iwdVwSG-KnDzF&index=37)):"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21bafa00-8912-41fe-a6ce-0e5eddf07b65",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 501
    },
    "id": "ctyubQRvj6R3",
    "outputId": "85ec38cf-e3e9-4472-fc7c-ea0d33fedd10"
   },
   "source": [
    "[Andrew Ng, C4W4L06 What is neural style transfer?](https://www.youtube.com/watch?v=R39tWYYKNcI)  \n",
    "[Andrew Ng, C4W4L07 What are deep CNs learning?](https://www.youtube.com/watch?v=ChoV5h7tw5A)  \n",
    "[Andrew Ng, C4W4L08 Cost Function](https://www.youtube.com/watch?v=xY-DMAJpIP4)  \n",
    "[Andrew Ng, C4W4L09 Content Cost Function](https://www.youtube.com/watch?v=b1I5X3UfEYI)  \n",
    "[Andrew Ng, C4W4L10 Style Cost Function](https://www.youtube.com/watch?v=QgkLfjfGul8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1726732-b745-4f4b-9cf3-235252736e3a",
   "metadata": {},
   "source": [
    "### John O Whittaker, Gram Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49da5092-99b7-448b-bc9e-c83d7decfe1a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 501
    },
    "id": "CzDBPP9hj6R1",
    "outputId": "a9987ce2-bece-4008-b857-6a24f549c303"
   },
   "source": [
    "[Lesson 20: Deep Learning Foundations to Stable Diffusion, style transfer starts at 12'39](https://www.youtube.com/watch?v=PdNHkTLU2oQ&start=3366)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81fe4ae0-7a32-4578-84c6-0bbc6a423de6",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "542e4575-a9bf-4d68-937c-5a9bbb53b07e",
   "metadata": {},
   "source": [
    "## GANs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9611706d-3a8c-41b2-9a96-44c1b66b2327",
   "metadata": {
    "id": "lSgIL-Y8pta8"
   },
   "source": [
    "### Tutorials"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99df16f7-19f0-40bb-9d72-dc3b2298456c",
   "metadata": {
    "id": "lSgIL-Y8pta8"
   },
   "source": [
    "[Soumith Chintala, \"How to Train a GAN? Tips and tricks to make GANs work\"](https://github.com/soumith/ganhacks)  \n",
    "[TensorFlow DCGAN tutorial](https://www.tensorflow.org/tutorials/generative/dcgan)  \n",
    "The TensorFlow website also has [one tutorial on CycleGAN](https://www.tensorflow.org/tutorials/generative/cyclegan) and one on [Pix2Pix](https://www.tensorflow.org/tutorials/generative/pix2pix), two GAN variants.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b896b641-f46c-4332-a411-0343e16033c1",
   "metadata": {
    "id": "lSgIL-Y8pta8"
   },
   "source": [
    "### Zoos: list of all GAN variants"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c3540f8a-934a-4fac-84ce-8b92116a43b6",
   "metadata": {
    "id": "lSgIL-Y8pta8"
   },
   "source": [
    "When it comes to GANs, the explosion has been so enormous it is rather difficult (impossible?) to keep up:\n",
    "\n",
    "[Avinash Hindupur, \"The GAN Zoo\"](https://github.com/hindupuravinash/the-gan-zoo)  \n",
    "[Jihye Back, \"GAN-Zoos\"](https://happy-jihye.github.io/gan/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7de11a6d-e19e-4490-807a-094cfbb9c639",
   "metadata": {
    "id": "lSgIL-Y8pta8"
   },
   "source": [
    "### References"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a9b987b9-5f82-4bc3-bc60-4f54ad33f5e5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 501
    },
    "id": "PQwNDgtMpta6",
    "outputId": "4acb83b8-fc61-41c4-c968-0e5e337ab649"
   },
   "source": [
    "[Goodfellow et al. \"Generative Adversarial Networks\"](https://arxiv.org/abs/1406.2661)  \n",
    "[Radford et al, \"Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks\"](https://arxiv.org/abs/1511.06434)  \n",
    "If you want to know more about where this idea of [minimax](https://en.wikipedia.org/wiki/Minimax) comes from, I can recommend the [Yale Game Theory lecture series](https://www.youtube.com/watch?v=nM3rTU927io&list=PL6EF60E1027E1A10B).  \n",
    "See also [this page](https://cs.stanford.edu/people/eroberts/courses/soco/projects/1998-99/game-theory/Minimax.html).\n",
    "\n",
    "[Sebastian Rashka, transposed convolutions](https://www.youtube.com/watch?v=ilkSwsggSNM)  \n",
    "[NIPS 2016 Workshop on Adversarial Training - Soumith Chintala - How to train a GAN](https://www.youtube.com/watch?v=myGAju4L7O8)  \n",
    "[Stanford CS230: Deep Learning | Autumn 2018 | Lecture 4 - Adversarial Attacks / GANs](https://www.youtube.com/watch?v=ANszao6YQuM)  \n",
    "[Introduction to GANs, NIPS 2016 | Ian Goodfellow, OpenAI](https://www.youtube.com/watch?v=9JpdAg6uMXs)  \n",
    "[Ian Goodfellow: Generative Adversarial Networks (NIPS 2016 tutorial)](https://www.youtube.com/watch?v=HGYYEUSm-0Q)  \n",
    "[[Classic] Generative Adversarial Networks (Paper Explained)](https://www.youtube.com/watch?v=eyxmSmjmNS0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee247cde-1806-49cd-b4c6-6cb7bcb3f981",
   "metadata": {
    "id": "RfxBm7eIpta9"
   },
   "source": [
    "### Notable experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eacf839-380c-4fc0-ad34-44c50df8a9f4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 501
    },
    "id": "vuK2r0wdpta9",
    "outputId": "e5ace4da-0cb5-4fba-ceb3-a7a38cd3970b"
   },
   "source": [
    "[Synthesizing High-Resolution Images with StyleGAN2](https://www.youtube.com/watch?v=9QuDh3W3lOY)  \n",
    "[CycleGAN horse zebra 0'7](https://www.youtube.com/watch?v=9reHvktowLY)  \n",
    "[Mario Klingemann: StyleGAN2 - mapping music to facial expressions in real time](https://www.youtube.com/watch?v=A6bo_mIOto0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
