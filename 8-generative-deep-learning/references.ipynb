{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e77737f0-7a70-4b18-aa48-62ff4e9367f9",
   "metadata": {},
   "source": [
    "# References | 12. Generative Deep Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e99a0c1-04e2-41ff-a09b-4ea3b550ce2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import YouTubeVideo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01c6df4a-c577-4707-a819-f72935c535f6",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Text Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e717461-6084-4217-a8e9-dd3e6435e1e1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 501
    },
    "id": "gZO34IitCfw2",
    "outputId": "a06e68c7-bcfa-44d3-d21f-c33760260365"
   },
   "outputs": [],
   "source": [
    "YouTubeVideo('LY7x2Ihqjmc', width=853, height=480) #  Sunspring | A Sci-Fi Short Film Starring Thomas Middleditch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8628187-f1e5-49ed-97b9-db8b56ecfca8",
   "metadata": {
    "id": "oTQ6A8m4CfxV"
   },
   "source": [
    "#### Tutorials:\n",
    "\n",
    "[\"Text generation with a miniature GPT\"](https://keras.io/examples/generative/text_generation_with_miniature_gpt/): pretty much the same as here, with some interesting variations (the Transformer architecture is closer to what's used for ChatGPT).  \n",
    "[\"Text generation with an RNN\"](https://www.tensorflow.org/text/tutorials/text_generation) using an RNN to train an auto-regressive char-level language model (some nice tricks using `tf.data.Dataset`).\n",
    "\n",
    "#### Reference\n",
    "\n",
    "One of the most famous blog posts in deep learning, the inspiration for the above tutorial: [Andrej Karpathy, \"The Unreasonable Effectiveness of Recurrent Neural Networks\"](https://karpathy.github.io/2015/05/21/rnn-effectiveness/).   \n",
    "[Holtzman et al, \"The Curious Case of Neural Text Degeneration\"](https://arxiv.org/abs/1904.09751)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee3c36b5-a8a5-46ad-87ac-723f53e667be",
   "metadata": {
    "id": "o9m8M4mbv39w"
   },
   "source": [
    "\n",
    "### The rise of large language models (LLMs)\n",
    "\n",
    "Truly remarkable results emerge with very large models. Several companies have all built such models to try and make a business out of it. They have APIs with a free tier that allow you to test these capabilities:\n",
    "\n",
    "- [OpenAI's ChatGPT](https://openai.com/blog/chatgpt/)  \n",
    "- [OpenAI's GPT-4](https://openai.com/api/)\n",
    "- [Cohere](https://cohere.ai/)\n",
    "- [Anthropic](https://www.anthropic.com)\n",
    "- [GooseAI](https://goose.ai/) (open-source)\n",
    "- [Huggingface Open LLM Leaderboard](https://huggingface.co/spaces/HuggingFaceH4/open_llm_leaderboard) (open-source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "056d3a77-e35d-41ba-888e-53f992ec7502",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 501
    },
    "id": "g0YtreH9Cfwv",
    "outputId": "ed59545a-92bc-403c-afe7-e08543c46f84"
   },
   "outputs": [],
   "source": [
    "YouTubeVideo('Dmm4UG-6jxA', width=853, height=480) # MIT 6.S191: Deep Generative Modeling\n",
    "                                                   # 3G5hWM6jqPk for the 2023\n",
    "                                                   # QcLlc9lj2hk for the 2022 edition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18c98d83-35c1-48d4-9c37-b03925a7b37b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 501
    },
    "id": "VUBrNDtcCfwx",
    "outputId": "ebf74a8f-90f5-444d-948e-ab07b55f65d3"
   },
   "outputs": [],
   "source": [
    "YouTubeVideo('5WoItGTWV54', width=853, height=480) # Stanford CS 231N, Lecture 13 | Generative Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06654523-0417-42b8-b917-e7ef103c43f4",
   "metadata": {},
   "source": [
    "### Even more sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85bc4189-0a27-411a-b38a-75b66cd62588",
   "metadata": {
    "id": "ipbRGxxNCfxD"
   },
   "source": [
    "- [min p sampling](https://arxiv.org/abs/2407.01082) ([video](https://www.youtube.com/watch?v=LTf_SJOQH4s)): take the top probability, multiply it by a value (e.g. `0.2`, 20% of that), and use the result as a threshold (any token with less probability than that is discarded)\n",
    "- [top a sampling](https://github.com/BlinkDL/RWKV-LM/tree/4cb363e5aa31978d801a47bc89d28e927ab6912e?tab=readme-ov-file#the-top-a-sampling-method): same idea as *min p*, except the threshold is computed using $\\alpha * \\text{top-prob}^\\beta$, with $\\text{top-prob}$ being the top probability among our tokens, $\\alpha\\ (= 0.2)$ and $\\beta\\ (=2)$ as hyperparameters\n",
    "- [locally typical sampling](https://arxiv.org/abs/2202.00666) ([video](https://www.youtube.com/watch?v=_EDr3ryrT_Y&pp=ygUYdHlwaWNhbCBzYW1wbGluZyBraWxjaGVy) & [interview](https://www.youtube.com/watch?v=AvHLJqtmQkE)): sample only from tokens with an expected information content close to the conditional entropy of the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "379790a0-dae8-4c3c-99a7-7dbf9085819e",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Style Transfer"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0e6cceba-05da-4e33-88bc-e907f95f9aeb",
   "metadata": {
    "id": "wQac1gc4j6R2"
   },
   "source": [
    "### Tutorials\n",
    "\n",
    "Have a look at the [official TensorFlow tutorial](https://www.tensorflow.org/tutorials/generative/style_transfer), it contains useful additional information!\n",
    "\n",
    "There are various differences in the implementation that make the two not a direct comparison (for instance looking at the numbers used for the various weights).\n",
    "\n",
    "However, understanding those differences and being able to integrate the two approaches into one is a *very* good exercise!\n",
    "\n",
    "Also, have a look at Andrew Ng's videos below!\n",
    "\n",
    "### References\n",
    "\n",
    "[Gatis et al., \"A Neural Algorithm of Artistic Style\"](https://arxiv.org/abs/1508.06576)\n",
    "\n",
    "Andrew Ng's videos on Neural Style Transfer (as part of [this playlist](https://www.youtube.com/watch?v=R39tWYYKNcI&list=PLkDaE6sCZn6Gl29AoE31iwdVwSG-KnDzF&index=37)):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd42ff86-db03-497f-9980-fffeb19b66ef",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 501
    },
    "id": "ctyubQRvj6R3",
    "outputId": "85ec38cf-e3e9-4472-fc7c-ea0d33fedd10"
   },
   "outputs": [],
   "source": [
    "YouTubeVideo('R39tWYYKNcI', width=853, height=480) # Andrew Ng, C4W4L06 What is neural style transfer?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c016cf24-b517-4e62-994a-5e835bdf2c15",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 501
    },
    "id": "L9_xNVLjj6R3",
    "outputId": "caeed3ee-0a70-4978-e265-8d7425df65c6"
   },
   "outputs": [],
   "source": [
    "YouTubeVideo('ChoV5h7tw5A', width=853, height=480) # Andrew Ng, C4W4L07 What are deep CNs learning?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b353a359-0990-44c3-b7da-4902ee543b94",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 501
    },
    "id": "g4pKbr5Sj6R3",
    "outputId": "eb154ab5-2b4f-4192-f46f-187ac306365a"
   },
   "outputs": [],
   "source": [
    "YouTubeVideo('xY-DMAJpIP4', width=853, height=480) # Andrew Ng, C4W4L08 Cost Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c5ae4f6-826b-4843-844b-156e2132ad03",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 501
    },
    "id": "RtqCMEL3j6R3",
    "outputId": "c77a1e7e-0a6e-4732-8af7-b133ac940ffe"
   },
   "outputs": [],
   "source": [
    "YouTubeVideo('b1I5X3UfEYI', width=853, height=480) # Andrew Ng, C4W4L09 Content Cost Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4839ba44-43b6-4ca1-bc12-b8d1ca379ffd",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 501
    },
    "id": "M26r8xuij6R3",
    "outputId": "71ff4daa-aa0d-4e08-cb56-0ba8b7bc5ab0"
   },
   "outputs": [],
   "source": [
    "YouTubeVideo('QgkLfjfGul8', width=853, height=480) # Andrew Ng, C4W4L10 Style Cost Function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46aa9708-2b75-45f4-b2fd-b887f0217399",
   "metadata": {},
   "source": [
    "### John O Whittaker, Gram Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d56d503-437a-4117-9af2-551a59e35cea",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 501
    },
    "id": "CzDBPP9hj6R1",
    "outputId": "a9987ce2-bece-4008-b857-6a24f549c303"
   },
   "outputs": [],
   "source": [
    "YouTubeVideo(\"PdNHkTLU2oQ\", width=853, height=480, start=3366) # style transfer starts at 1239"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64f5c1c2-d371-4028-a1d0-5776ecef8ef1",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Deep Dream"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bd95a37-b0e8-49a1-b82f-50c8940b3d51",
   "metadata": {
    "id": "GUMV5aALhnq7"
   },
   "source": [
    "An online tool for DeepDream: [deepdreamgenerator.com](https://deepdreamgenerator.com/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1168c4bb-fe99-40ce-b588-4bcf7c615b2c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 501
    },
    "id": "WCezMCEAhnq7",
    "outputId": "a9d28000-07bc-4ceb-d4da-340322e77da9",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "YouTubeVideo('BsSmBPmPeYQ', width=853, height=480) # Deep Dream (Google) - Computerphile"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0577aa90-615a-47c6-afcd-f079fcfb88bb",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Variational Autoencoders"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bf73aed-0faa-44e9-9eee-abbe1f970e5b",
   "metadata": {},
   "source": [
    "### Latent space, KL divergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81211888-357c-4cb8-ace6-450d3c6eeed2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 501
    },
    "id": "4xoTl-kGmPRf",
    "outputId": "0ebe6877-b4f0-42fd-f5aa-404289690c8e"
   },
   "outputs": [],
   "source": [
    "YouTubeVideo(\"sV2FOdGqlX0\", width=853, height=480) #  Variational Autoencoder (VAE) Latent Space Visualization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "679c345a-8d70-4c6d-83d8-01d8957c279f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 501
    },
    "id": "fdHwWC1hmPRh",
    "outputId": "ab7208c8-c5d6-43c7-9fb5-e09bd82516ed"
   },
   "outputs": [],
   "source": [
    "YouTubeVideo('ErfnhcEV1O8', width=853, height=480) # A Short Introduction to Entropy, Cross-Entropy and KL-Divergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5972278-f3c5-4af8-b8c6-ff1625416acc",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 501
    },
    "id": "QWCDXwypmPRh",
    "outputId": "478689ff-062e-4058-9783-91d01723efd8",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "YouTubeVideo('SxGYPqCgJWM', width=853, height=480) #  Intuitively Understanding the KL Divergence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd6ebeef-a6c1-4e06-a6a7-b27e9db801a9",
   "metadata": {},
   "source": [
    "### Talks & courses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1a4c799-c605-4d78-828d-11b9aad26331",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 501
    },
    "id": "QWCDXwypmPRh",
    "outputId": "478689ff-062e-4058-9783-91d01723efd8",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "YouTubeVideo('rjZL7aguLAs', width=853, height=480) # ICLR14: D Kingma: Auto-Encoding Variational Bayes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32ba74b5-fb28-4a32-9763-d893faad89aa",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 501
    },
    "id": "QWCDXwypmPRh",
    "outputId": "478689ff-062e-4058-9783-91d01723efd8",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "YouTubeVideo('MAGBUh77bNg', width=853, height=480) # Stanford CS236: Deep Generative Models I 2023 I Lecture 5 - VAEs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63f4acb6-1ec5-4033-951c-504b1e9671bb",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 501
    },
    "id": "QWCDXwypmPRh",
    "outputId": "478689ff-062e-4058-9783-91d01723efd8",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "YouTubeVideo('8cO61e_8oPY', width=853, height=480) # Stanford CS236: Deep Generative Models I 2023 I Lecture 6 - VAEs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2b8089a-60f9-4d99-89fc-af148c779b83",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 501
    },
    "id": "QWCDXwypmPRh",
    "outputId": "478689ff-062e-4058-9783-91d01723efd8",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "YouTubeVideo('NlIqjtbjjRE', width=853, height=480) # L4 Latent Variable Models and Variational AutoEncoders -- CS294-158 SP24 Deep Unsupervised Learning "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8987d2a-36ca-4acf-8155-14940adae1a0",
   "metadata": {
    "id": "SyDJlERVmPRi"
   },
   "source": [
    "---\n",
    "\n",
    "### References\n",
    "\n",
    "[TensorFlow tutorial](https://www.tensorflow.org/tutorials/generative/cvae)\n",
    "\n",
    "[Kingma and Welling, \"Auto-Encoding Variational Bayes\"](https://arxiv.org/abs/1312.6114)  \n",
    "[Kingma and Welling, \"An Introduction to Variational Autoencoders\"](https://arxiv.org/abs/1906.02691)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4b30a2b-b646-4c72-88c3-98d68ef81f2f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 501
    },
    "id": "5C69SBUTmPRi",
    "outputId": "bd14035a-00ef-4d92-f798-58f6ad782d11"
   },
   "outputs": [],
   "source": [
    "YouTubeVideo('9zKuYvjFFS8', width=853, height=480) # Arxiv insight, Variational Autoencoders"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39ede083-e77e-4dd6-8264-d3d105522d7b",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## GANs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6a97fb3-2bba-4224-a263-4b946cf12de6",
   "metadata": {
    "id": "lSgIL-Y8pta8"
   },
   "source": [
    "### Tutorials\n",
    "\n",
    "- [Soumith Chintala, \"How to Train a GAN? Tips and tricks to make GANs work\"](https://github.com/soumith/ganhacks)\n",
    "- [TensorFlow DCGAN tutorial](https://www.tensorflow.org/tutorials/generative/dcgan)\n",
    "- The TensorFlow website also has [one tutorial on CycleGAN](https://www.tensorflow.org/tutorials/generative/cyclegan) and one on [Pix2Pix](https://www.tensorflow.org/tutorials/generative/pix2pix), two GAN variants.\n",
    "\n",
    "### Zoos: list of all GAN variants\n",
    "\n",
    "When it comes to GANs, the explosion has been so enormous it is rather difficult (impossible?) to keep up:\n",
    "\n",
    "- [Avinash Hindupur, \"The GAN Zoo\"](https://github.com/hindupuravinash/the-gan-zoo)\n",
    "- [Jihye Back, \"GAN-Zoos\"](https://happy-jihye.github.io/gan/)\n",
    "\n",
    "### References\n",
    "\n",
    "[Goodfellow et al. \"Generative Adversarial Networks\"](https://arxiv.org/abs/1406.2661)\n",
    "\n",
    "[Radford et al, \"Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks\"](https://arxiv.org/abs/1511.06434)\n",
    "\n",
    "If you want to know more about where this idea of [minimax](https://en.wikipedia.org/wiki/Minimax) comes from, I can recommend the [Yale Game Theory lecture series](https://www.youtube.com/watch?v=nM3rTU927io&list=PL6EF60E1027E1A10B).\n",
    "\n",
    "See also [this page](https://cs.stanford.edu/people/eroberts/courses/soco/projects/1998-99/game-theory/Minimax.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ab30ca7-fe3c-4c14-820d-d54871e0b889",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 501
    },
    "id": "PQwNDgtMpta6",
    "outputId": "4acb83b8-fc61-41c4-c968-0e5e337ab649"
   },
   "outputs": [],
   "source": [
    "YouTubeVideo('ilkSwsggSNM', width=853, height=480) # Sebastian Rashka, transposed convolutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb286d7d-bf43-4e46-a1bf-ed3cd4e8eb5b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 501
    },
    "id": "-j2kbWpApta4",
    "outputId": "dcb23e5a-1676-4d68-d0ae-3395767ff6ca"
   },
   "outputs": [],
   "source": [
    "YouTubeVideo('myGAju4L7O8', width=853, height=480) #  NIPS 2016 Workshop on Adversarial Training - Soumith Chintala - How to train a GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de3fb595-6613-4e0f-8104-8c83acea4baa",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 501
    },
    "id": "dwP6BbPTpta9",
    "outputId": "21919865-8515-4080-d5f2-81fcfd217a06",
    "tags": []
   },
   "outputs": [],
   "source": [
    "YouTubeVideo('ANszao6YQuM', width=853, height=480) # Stanford CS230: Deep Learning | Autumn 2018 | Lecture 4 - Adversarial Attacks / GANs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e92517be-2f18-48b1-a368-1e6050d1cc49",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 501
    },
    "id": "d5SGou6Mpta9",
    "outputId": "d2a0aa0e-c313-468f-91f2-6fa50f64fefb"
   },
   "outputs": [],
   "source": [
    "YouTubeVideo('9JpdAg6uMXs', width=853, height=480) # Introduction to GANs, NIPS 2016 | Ian Goodfellow, OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b24b0313-96fe-49c0-9c17-de06fa95bac8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 501
    },
    "id": "7oYhZxd1pta9",
    "outputId": "fca5639a-d72e-4a69-ee3c-89b2b69ac661"
   },
   "outputs": [],
   "source": [
    "YouTubeVideo('HGYYEUSm-0Q', width=853, height=480) # Ian Goodfellow: Generative Adversarial Networks (NIPS 2016 tutorial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7212278-898c-4d35-9475-36a4f5cb43f2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 501
    },
    "id": "YyKkrdYSpta9",
    "outputId": "c0c3cc9f-b219-4a11-dfb2-005a6a8b0f89"
   },
   "outputs": [],
   "source": [
    "YouTubeVideo('eyxmSmjmNS0', width=853, height=480) # [Classic] Generative Adversarial Networks (Paper Explained)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be471f7d-beb8-4858-a211-d06cc479c2f2",
   "metadata": {
    "id": "RfxBm7eIpta9"
   },
   "source": [
    "### Notable experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b72f322-795f-4ad2-94e5-e16dfad85fec",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 501
    },
    "id": "vuK2r0wdpta9",
    "outputId": "e5ace4da-0cb5-4fba-ceb3-a7a38cd3970b"
   },
   "outputs": [],
   "source": [
    "YouTubeVideo('9QuDh3W3lOY', width=853, height=480) # Synthesizing High-Resolution Images with StyleGAN2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c39382e-c8dc-4004-8f5a-72ad961316d4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 501
    },
    "id": "nB9R9LCrpta9",
    "outputId": "a38cf43b-57c8-4183-cdb9-43fbd2af234e"
   },
   "outputs": [],
   "source": [
    "YouTubeVideo('9reHvktowLY', width=853, height=480) # CycleGAN horse zebra 0'7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a312d52-d320-46f4-8186-803afaa1b836",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 501
    },
    "id": "OgGTDPyTpta9",
    "outputId": "c9dda89e-0c6e-47fc-8d65-36d12c6da7c2"
   },
   "outputs": [],
   "source": [
    "YouTubeVideo('A6bo_mIOto0', width=853, height=480) # Mario Klingemann: StyleGAN2 - mapping music to facial expressions in real time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff782051-710c-4b78-834e-18be59882584",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Positional Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4441dbcc-0b63-498b-adb1-59a855b23f53",
   "metadata": {},
   "source": [
    "Strike back!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f1a1c1b-61ed-4a1d-8aba-37ebcf9b0816",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 501
    },
    "id": "OgGTDPyTpta9",
    "outputId": "c9dda89e-0c6e-47fc-8d65-36d12c6da7c2"
   },
   "outputs": [],
   "source": [
    "YouTubeVideo('1biZfFLPRSY', width=853, height=480) #  Positional embeddings in transformers EXPLAINED | Demystifying positional encodings. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62ca0f9c-533e-4272-a591-3a4f92af6bfc",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 501
    },
    "id": "OgGTDPyTpta9",
    "outputId": "c9dda89e-0c6e-47fc-8d65-36d12c6da7c2"
   },
   "outputs": [],
   "source": [
    "YouTubeVideo('T3OT8kqoqjc', width=853, height=480) # How positional encoding works in transformers? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53b91ccc-e8be-43e9-bb48-f3c97f82d16d",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Diffusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75d65df1-6645-414f-8e38-56d1d56b3f26",
   "metadata": {
    "id": "dg8CnBhTpta9"
   },
   "source": [
    "Original tutorial: [Denoising Diffusion Probabilistic Model](https://keras.io/examples/generative/ddpm/)  \n",
    "\n",
    "See also this, with an introduction to the FID score (to measure the quality of images):  [Denoising Diffusion Implicit Models](https://keras.io/examples/generative/ddim/)  \n",
    "\n",
    "Two more in Keras:\n",
    "\n",
    "[High-performance image generation using Stable Diffusion in KerasCV](https://keras.io/guides/keras_cv/generate_images_with_stable_diffusion/)  \n",
    "[A walk through latent space with Stable Diffusion](https://keras.io/examples/generative/random_walks_with_stable_diffusion/)\n",
    "\n",
    "The original paper: [Ho et al, \"Denoising Diffusion Probabilistic Models\"](https://arxiv.org/abs/2006.11239) (and for an extra-thick cream top-up, the [author's implementation](https://github.com/hojonathanho/diffusion))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36d26716-4555-492b-8bb6-7c6d2b1f8592",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 501
    },
    "id": "oa3F7e6Rpta9",
    "outputId": "a726f1f8-45ca-4386-dedc-69b4548ae49b"
   },
   "outputs": [],
   "source": [
    "YouTubeVideo('1CIpzeNxIhU', width=853, height=480) # How AI Image Generators Work (Stable Diffusion / Dall-E) - Computerphile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2340af0-4c30-434f-a740-096724cbcd27",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 501
    },
    "id": "IWSaLCN2pta-",
    "outputId": "3e23e0a8-c5d2-4b28-edfb-711f8eede70d"
   },
   "outputs": [],
   "source": [
    "YouTubeVideo('-lz30by8-sU', width=853, height=480) # Stable Diffusion in Code (AI Image Generation) - Computerphile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65b922d1-2052-4837-b963-e5a74b70accb",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 501
    },
    "id": "NFDmbhtPpta-",
    "outputId": "91e48fee-021a-444e-bd78-ba191fd66266"
   },
   "outputs": [],
   "source": [
    "YouTubeVideo('fbLgFrlTnGU', width=853, height=480) # What are Diffusion Models?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37a7e268-6be9-41b0-a5e0-9e173dfecff3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 501
    },
    "id": "2qkcTvvUpta-",
    "outputId": "3dbdf1b1-6c22-4cb2-8ba4-d7dbabdd3996"
   },
   "outputs": [],
   "source": [
    "YouTubeVideo('W-O7AZNzbzQ', width=853, height=480) # DDPM - Diffusion Models Beat GANs on Image Synthesis (Machine Learning Research Paper Explained)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b34969a6-7e5b-4eae-8a87-a79f3f08874a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 501
    },
    "id": "2qkcTvvUpta-",
    "outputId": "3dbdf1b1-6c22-4cb2-8ba4-d7dbabdd3996"
   },
   "outputs": [],
   "source": [
    "YouTubeVideo('cS6JQpEY9cs', width=853, height=480) # Tutorial on Denoising Diffusion-based Generative Modeling: Foundations and Applications "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a6646b5-28b8-49a4-870b-275d18986eaa",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 501
    },
    "id": "2qkcTvvUpta-",
    "outputId": "3dbdf1b1-6c22-4cb2-8ba4-d7dbabdd3996"
   },
   "outputs": [],
   "source": [
    "YouTubeVideo('T0Qxzf0eaio', width=853, height=480) # Miika Aittala: Elucidating the Design Space of Diffusion-Based Generative Models "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95ab32cc-8cc3-4cbd-9edd-853c1661072a",
   "metadata": {
    "id": "QneKbVLEpta-"
   },
   "source": [
    "Good resources exist in PyTorch, such as the series of videos by [Fast.ai](https://www.fast.ai/) (in PyTorch):\n",
    "- [Lesson 9: Deep Learning Foundations to Stable Diffusion, 2022](https://www.youtube.com/watch?v=_7rMfsA24Ls)\n",
    "- [Lesson 9A 2022 - Stable Diffusion deep dive](https://www.youtube.com/watch?v=0_BBRNYInx8)\n",
    "- [Lesson 9B - the math of diffusion](https://www.youtube.com/watch?v=mYpjmM7O-30)\n",
    "- [Lesson 10: Deep Learning Foundations to Stable Diffusion, 2022](https://www.youtube.com/watch?v=6StU6UtZEbU)\n",
    "\n",
    "As well as John O. Whittaker's [intro on Diffusion](https://www.youtube.com/watch?v=XTs7M6TSK9I) from his own course, [AIAIART](https://github.com/johnowhitaker/aiaiart).\n",
    "\n",
    "And the in-depth code guide: the [Annotated Diffusion Model](https://huggingface.co/blog/annotated-diffusion)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
